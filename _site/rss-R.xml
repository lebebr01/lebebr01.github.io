<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Educate-R - R</title>
		<description>Posts categorized as 'R'</description>
		<link>http://educate-r.org</link>
		<atom:link href="http://educate-r.org/feed.category.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Web Scraping to Item Response Theory - A College Football Adventure</title>
				<description>&lt;p&gt;&lt;section data-markdown&gt;
    &lt;h1 class=&quot;title&quot;&gt;Web Scraping to Item Response Theory: A College Football Adventure&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Andrew Zieffler, and Kyle Nickodem&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa &amp;amp; University of Minnesota&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Began after Tim Brewster was fired&lt;/li&gt;
&lt;li&gt;Wanted to try to predict next great coach
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Data Available&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is available at three levels

&lt;ol&gt;
&lt;li&gt;Coach&lt;/li&gt;
&lt;li&gt;Game by Game&lt;/li&gt;
&lt;li&gt;Team
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Coach&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall record&lt;/li&gt;
&lt;li&gt;Team history&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;Coordinator history
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Example Coach Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##   Year Team Win Loss Tie     Pct  PF  PA Delta        coach
## 1 2010 Iowa   8    5   0 0.61538 376 221   155 Kirk Ferentz
## 2 2011 Iowa   7    6   0 0.53846 358 310    48 Kirk Ferentz
## 3 2012 Iowa   4    8   0 0.33333 232 275   -43 Kirk Ferentz
## 4 2013 Iowa   8    5   0 0.61538 342 246    96 Kirk Ferentz
## 5 2014 Iowa   7    6   0 0.53846 367 333    34 Kirk Ferentz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Game by Game&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Final score of each game&lt;/li&gt;
&lt;li&gt;Date played&lt;/li&gt;
&lt;li&gt;Location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;No information within a game
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Example GBG Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##    Team           Official Year       Date WL          Opponent PF PA
## 1  Iowa University of Iowa 2014  8/30/2014  W     Northern Iowa 31 23
## 2  Iowa University of Iowa 2014   9/6/2014  W     Ball St. (IN) 17 13
## 3  Iowa University of Iowa 2014  9/13/2014  L          Iowa St. 17 20
## 4  Iowa University of Iowa 2014  9/20/2014  W   Pittsburgh (PA) 24 20
## 5  Iowa University of Iowa 2014  9/27/2014  W       Purdue (IN) 24 10
## 6  Iowa University of Iowa 2014 10/11/2014  W           Indiana 45 29
## 7  Iowa University of Iowa 2014 10/18/2014  L          Maryland 31 38
## 8  Iowa University of Iowa 2014  11/1/2014  W Northwestern (IL) 48  7
## 9  Iowa University of Iowa 2014  11/8/2014  L         Minnesota 14 51
## 10 Iowa University of Iowa 2014 11/15/2014  W          Illinois 30 14
## 11 Iowa University of Iowa 2014 11/22/2014  L         Wisconsin 24 26
## 12 Iowa University of Iowa 2014 11/28/2014  L          Nebraska 34 37
## 13 Iowa University of Iowa 2014   1/2/2015  L         Tennessee 28 45
##              Location
## 1       Iowa City, IA
## 2       Iowa City, IA
## 3       Iowa City, IA
## 4      Pittsburgh, PA
## 5  West Lafayette, IN
## 6       Iowa City, IA
## 7    College Park, MD
## 8       Iowa City, IA
## 9     Minneapolis, MN
## 10      Champaign, IL
## 11      Iowa City, IA
## 12      Iowa City, IA
## 13   Jacksonville, FL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Team&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall team record&lt;/li&gt;
&lt;li&gt;Team statistics&lt;/li&gt;
&lt;li&gt;Rankings&lt;/li&gt;
&lt;li&gt;Conference Affiliation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data is very similar to that of the coach level
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data were obtained from many sources

&lt;ul&gt;
&lt;li&gt;Much from &lt;a href=&quot;http://cfbdatawarehouse.com&quot;&gt;http://cfbdatawarehouse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Also used wikipedia, ESPN, and rivals
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Iowa Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa.png&quot; alt=&quot;&quot; height = &quot;500&quot; width = &quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Iowa State Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa_state.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Strengths in web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is relatively easily obtained&lt;/li&gt;
&lt;li&gt;Structured process for obtaining data&lt;/li&gt;
&lt;li&gt;Can be easily updated
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Challenges of web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;At the mercy of the website

&lt;ul&gt;
&lt;li&gt;Many sites are old&lt;/li&gt;
&lt;li&gt;Not up to date on current design standards&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data validation can be difficult and time consuming&lt;/li&gt;
&lt;li&gt;Need some basic knowledge of html
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;When is Web Scraping Worthwhile?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best when scraping many pages

&lt;ul&gt;
&lt;li&gt;Particularly when web addresses are not structured&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful when data need to be updated&lt;/li&gt;
&lt;/ul&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt;Not useful if only scraping a single page/table
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;HTML Basics&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt; HTML is structured by start tags (e.g. `&lt;table&gt;`) and end tags (e.g. `&lt;/table&gt;`) &lt;/li&gt;
&lt;li&gt; Common tags 
&lt;/li&gt;
&lt;/ul&gt;


&lt;div style=&quot;float: left; width: 75%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; - &lt;code&gt;&amp;lt;h6&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;a href=&amp;quot;http://www.google.com&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;div style=&quot;float: right; width: 25%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; &amp;amp; &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt; Highly structured pages are the easiest to scrape &lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;HTML Code Example&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ferentz_wikiside.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Tools for web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rvest&lt;/code&gt;: &lt;a href=&quot;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&quot;&gt;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;XML&lt;/code&gt;: &lt;a href=&quot;http://www.omegahat.org/RSXML/&quot;&gt;http://www.omegahat.org/RSXML/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;beautiful soup&lt;/code&gt;: &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/&quot;&gt;http://www.crummy.com/software/BeautifulSoup/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Misc

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SelectorGadget&lt;/code&gt;: &lt;a href=&quot;http://selectorgadget.com/&quot;&gt;http://selectorgadget.com/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Basics of rvest&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;read_html&lt;/code&gt; is the most basic function&lt;/li&gt;
&lt;li&gt;&lt;code&gt;html_node&lt;/code&gt; or &lt;code&gt;html_nodes&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;These functions need css selectors or xpath&lt;/li&gt;
&lt;li&gt;SelectorGadget is the easiest way to get this
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;SelectorGadget&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;SelectorGadget is a Javascript addon for web browsers&lt;/li&gt;
&lt;li&gt;Can quickly identify a css selector or xpath to select correct portion of web page&lt;/li&gt;
&lt;li&gt;Demo:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;&gt;https://en.wikipedia.org/wiki/Kirk_Ferentz&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Combine SelectorGadget with rvest&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rvest)
wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;)
wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
    html_nodes(&quot;.vcard td , .vcard th&quot;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## {xml_nodeset (6)}
## [1] &amp;lt;td colspan=&quot;2&quot; style=&quot;text-align:center&quot;&amp;gt;&amp;lt;a href=&quot;/wiki/File:Kirk_p ...
## [2] &amp;lt;th scope=&quot;row&quot;&amp;gt;Sport(s)&amp;lt;/th&amp;gt;
## [3] &amp;lt;td class=&quot;category&quot;&amp;gt;\n  &amp;lt;a href=&quot;/wiki/American_football&quot; title=&quot;Am ...
## [4] &amp;lt;th colspan=&quot;2&quot; style=&quot;text-align:center;background-color: lightgray ...
## [5] &amp;lt;th scope=&quot;row&quot;&amp;gt;Title&amp;lt;/th&amp;gt;
## [6] &amp;lt;td&amp;gt;\n  &amp;lt;a href=&quot;/wiki/Head_coach&quot; title=&quot;Head coach&quot;&amp;gt;Head coach&amp;lt;/a&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Extract text&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_text&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;\nFerentz at the 2010 Orange Bowl\n&quot;
## [2] &quot;Sport(s)&quot;                           
## [3] &quot;Football&quot;                           
## [4] &quot;Current position&quot;                   
## [5] &quot;Title&quot;                              
## [6] &quot;Head coach&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Encoding problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Two solutions to fix encoding problems

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;guess_encoding&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repair_encoding&lt;/code&gt;: fix encoding problems&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  guess_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       encoding language confidence
## 1        UTF-8                1.00
## 2 windows-1252       en       0.36
## 3 windows-1250       ro       0.18
## 4 windows-1254       tr       0.13
## 5     UTF-16BE                0.10
## 6     UTF-16LE                0.10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Fix Encoding Problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best practice to reload page with correct encoding&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;, 
                       encoding = &#39;UTF-8&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can also repair encoding after the fact&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;% 
  repair_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Extract html tags&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_tags&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_name()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;td&quot; &quot;th&quot; &quot;td&quot; &quot;th&quot; &quot;th&quot; &quot;td&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Extract html attributes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_attrs()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
##             colspan               style 
##                 &quot;2&quot; &quot;text-align:center&quot; 
## 
## [[2]]
## scope 
## &quot;row&quot; 
## 
## [[3]]
##      class 
## &quot;category&quot; 
## 
## [[4]]
##                                          colspan 
##                                              &quot;2&quot; 
##                                            style 
## &quot;text-align:center;background-color: lightgray;&quot; 
## 
## [[5]]
## scope 
## &quot;row&quot; 
## 
## [[6]]
## named character(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Extract links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function again&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard a&quot;) %&amp;gt;%
  html_attr(&#39;href&#39;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;/wiki/American_football&quot;                           
## [3] &quot;/wiki/Head_coach&quot;                                  
## [4] &quot;/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Valid Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;paste0&lt;/code&gt; function is helpful for this&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;valid_links &amp;lt;- paste0(&#39;https://www.wikipedia.org&#39;, wiki_kirk_extract)
head(valid_links)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;https://www.wikipedia.org/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;https://www.wikipedia.org/wiki/American_football&quot;                           
## [3] &quot;https://www.wikipedia.org/wiki/Head_coach&quot;                                  
## [4] &quot;https://www.wikipedia.org/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;https://www.wikipedia.org/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;https://www.wikipedia.org/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Extract Tables&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;html_table&lt;/code&gt; function is useful to scrape well formatted tables&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;record_kirk &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.wikitable&quot;) %&amp;gt;%
  .[[1]] %&amp;gt;%
  html_table(fill = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Caveats to Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Keep in mind when scraping we are using their bandwidth

&lt;ul&gt;
&lt;li&gt;Do not want to repeatedly do expensive bandwidth operations&lt;/li&gt;
&lt;li&gt;Better to scrape once, then run only to update data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some websites are copyrighted (i.e. illegal to scrape)
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Data Modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Research Questions

&lt;ol&gt;
&lt;li&gt;Who is the next great coach?&lt;/li&gt;
&lt;li&gt;What characteristics are in common for these coaches?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;IRT modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;So far we have explored the win/loss records of teams in the BCS era with item response theory (IRT)&lt;/li&gt;
&lt;li&gt;IRT is commonly used to model assessment data to estimate item parameters and person &#39;ability&#39;&lt;/li&gt;
&lt;li&gt;We recode the Win/Loss/Tie game by game results

&lt;ul&gt;
&lt;li&gt;1 = Win&lt;/li&gt;
&lt;li&gt;0 = Otherwise
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Example code with lme4&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A 1 parameter multilevel IRT model can be fitted using &lt;code&gt;glmer&lt;/code&gt; in the &lt;code&gt;lme4&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(lme4)
fm1a &amp;lt;- glmer(wingbg ~ 0 + (1|coach) + (1|Team), 
              data = yby_coach, family = binomial)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Plot Showing Team Ability&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/team_ability.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section data-markdown&gt;&lt;/p&gt;

&lt;h1&gt;Connect&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;e-mail: brandon-lebeau (at) uiowa.edu&lt;/li&gt;
&lt;li&gt;Twitter: @blebeau11; &lt;a href=&quot;https://twitter.com/blebeau11&quot;&gt;https://twitter.com/blebeau11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linkedin: &lt;a href=&quot;https://www.linkedin.com/in/lebeaubr&quot;&gt;https://www.linkedin.com/in/lebeaubr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://educate-r.org/2015/12/04/centraliowaruser/&quot;&gt;http://educate-r.org/2015/12/04/centraliowaruser/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 04 Dec 2015 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2015/12/04/centraliowaruser/</link>
				<guid isPermaLink="true">http://educate-r.org//2015/12/04/centraliowaruser/</guid>
			</item>
		
			<item>
				<title>Speed test of sequence generation for unbalanced simulation</title>
				<description>&lt;p&gt;I have a simulation package that allows for the simulation of regression models including nested data structures. You can see the package on github here: &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;simReg&lt;/a&gt;. Over the weekend I updated the package to allow for the simulation of unbalanced designs. I&#39;m hoping to put together a new vigenette soon highlighting the functionality.&lt;/p&gt;

&lt;p&gt;I am working on a simulation that uses the unbalanced functionality and while simulating longitudinal data I&#39;ve found the function is much slower than the cross sectional counterparts (and balanced designs). I&#39;ve ran some additional testing and I believe I have the speed issues narrowed down to the fact that I am generating a time variable. Essentially, I have a vector of number of observations per cluster. The function then turns this vector of lengths into a time variable starting at 0 up to the maximum number of observations minus 1 by 1. As an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;x &amp;lt;- round(runif(5, min = 3, max = 10), 0)
unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] 0 1 2 3 4 5 6 7 0 1 2 0 1 2 3 4 5 6 0 1 2 3 4 0 1 2 3 4 5 6 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From the code above, you can see that there the number of observations is generated using &lt;em&gt;runif&lt;/em&gt; which is saved to the object &lt;em&gt;x&lt;/em&gt;. Then I use a combination of lapply, unlist, and the &#39;:&#39; operator to generate the sequence. This is the same code used in my package above to generate the time variable.&lt;/p&gt;

&lt;p&gt;As such, I was interested in testing various ways to generate the sequence and do a performance comparison. I compared the following ways, the &lt;em&gt;&#39;:&#39;&lt;/em&gt; operator, &lt;em&gt;seq.int&lt;/em&gt;, &lt;em&gt;seq&lt;/em&gt;, &lt;em&gt;do.call&lt;/em&gt; with &lt;em&gt;mapply&lt;/em&gt;, and &lt;em&gt;rep.int&lt;/em&gt; for the balanced case as a comparison to how it was done before. This was all done with the great &lt;strong&gt;microbenchmark&lt;/strong&gt; package.&lt;/p&gt;

&lt;p&gt;Here are the results from the 7 comparisons:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(microbenchmark)
x &amp;lt;- round(runif(100, min = 3, max = 15), 0)
microbenchmark(
  colon = unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  seq.int = unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  seq = unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  seq.int_mapply = do.call(c, mapply(seq.int, 0, x - 1)),
  seq_mapply = do.call(c, mapply(seq, 0, x - 1)),
  colon_mapply = do.call(c, mapply(&#39;:&#39;, 0, x - 1)),
  rep.int = rep.int(1:8 - 1, times = 100), # balanced case for reference.
  times = 1000L
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##            expr      min       lq        mean    median        uq        max neval  cld
##           colon  133.429  148.618  255.474605  160.1145  235.8605  57706.598  1000 ab  
##         seq.int  180.231  203.632  270.517868  223.1330  309.9640   2671.845  1000 ab  
##             seq 2255.960 2626.685 4207.210575 2933.1590 3466.4605  88721.432  1000    d
##  seq.int_mapply  227.854  258.235  499.000451  292.7210  397.4110 105037.011  1000  b  
##      seq_mapply  953.293 1079.126 1534.250895 1203.9320 1543.2495  57174.117  1000   c 
##    colon_mapply  167.094  195.832  383.431252  220.4645  299.0845  61779.643  1000 ab  
##         rep.int    2.053    4.516    5.807329    5.7480    6.9800     30.792  1000 a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The results (in microseconds) show that this is where the significant slowdown is coming in my package implementing the unbalanced cases, although it appears that the &#39;:&#39; operator is the second best alternative. For those that have not seen the significant speed bump of the &lt;em&gt;seq.int&lt;/em&gt; and &lt;em&gt;rep.int&lt;/em&gt; over the &lt;em&gt;seq&lt;/em&gt; and &lt;em&gt;rep&lt;/em&gt; alternatives should also pay close attention (compare lines 2 and 3 above).&lt;/p&gt;

&lt;p&gt;I&#39;d be interested in alternative procedures that I am not aware of as well. Although not a big deal when running the package once, doing it 50,000 times does add up.&lt;/p&gt;

&lt;p&gt;Lastly, for those that are interested, we can show they are all equivalent methods (except for the &lt;em&gt;rep.int&lt;/em&gt; case).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;identical(
  unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  do.call(c, mapply(seq.int, 0, x - 1)),
  do.call(c, mapply(seq, 0, x - 1)),
  do.call(c, mapply(&#39;:&#39;, 0, x - 1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Tue, 31 Mar 2015 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2015/03/31/seqspeed/</link>
				<guid isPermaLink="true">http://educate-r.org//2015/03/31/seqspeed/</guid>
			</item>
		
			<item>
				<title>Remove leading 0 with ggplot2.</title>
				<description>&lt;p&gt;I recently had an occasion while working on a three variable interaction plot for a paper where I wanted to remove the leading 0&#39;s in the x-axis text labels using &lt;em&gt;ggplot2&lt;/em&gt;. This was primarily due to some space concerns I had for the x-axis labels. Unfortunately, I did not find an obvious way to do this in my first go around. After tickering a bit, I&#39;ve found a workaround. The process is walked through below.&lt;/p&gt;

&lt;p&gt;First, some simulated data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Sim some data
simdata &amp;lt;- data.frame(x = runif(2400, min = .032, max = .210),
                      y = c(rnorm(2000, mean = 0, sd = .1), 
                            rnorm(400, mean = 1, sd = .25)),
                      group = c(sample(1:2, 1600, replace = TRUE),
                                rep(1, 400), 
                                rep(2, 400)),
                      facet = rep(1:3, each = 800))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As shown below, initially there is no group differences, but there are facet differences. Exploring the interaction between the grouping variables shows there is a two variable interaction. Note: This example is not identical to the three variable interaction I originally described above, but assume here that the x variable is also important.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, group, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##          1          2 
## 0.00342121 0.33040069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, facet, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             1             2             3 
## -0.0009751953  0.0025336609  0.5028529069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, interaction(group, facet), mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           1.1           2.1           1.2           2.2           1.3 
##  0.0031464214 -0.0048761903  0.0056148873 -0.0005785326  0.0014837970 
##           2.3 
##  1.0042220169
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example in the paper, I aggregated the unique x values to the third decimal place. That is done with the following &lt;em&gt;dplyr&lt;/em&gt; code. Note: The data did not need to be aggregated, but it is a bit easier to work with when plotting later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# round value to .001 and aggregate
simdata$x_rd &amp;lt;- round(simdata$x, 3)

# aggregate
library(dplyr)
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))
simdata_agg 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [962 x 4]
## Groups: x_rd, group
## 
##     x_rd group facet            y
## 1  0.032     1     2 -0.088397852
## 2  0.032     2     2  0.228654211
## 3  0.033     1     1 -0.001843538
## 4  0.033     1     2 -0.021662299
## 5  0.033     1     3 -0.110077646
## 6  0.033     2     1  0.080429131
## 7  0.033     2     3  0.915228939
## 8  0.034     1     1  0.025164086
## 9  0.034     1     2 -0.046522430
## 10 0.034     1     3  0.037889712
## ..   ...   ...   ...          ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the data is aggregated, it can be directly plotted with &lt;em&gt;ggplot2&lt;/em&gt;. This is the base plot that contains the leading 0&#39;s by default and treats the x variable as continuous (which it really is continuous).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(ggplot2)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_rd, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_continuous(&quot;x&quot;, limits = c(0, .25), 
                     breaks = seq(0, .25, .05))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotwith0-1.png&quot; alt=&quot;&quot; /&gt;
The plot above is a good start, but I was worried about the x-axis labels being too close together and ultimately being difficult to read. I decided I wanted to omit the leading 0&#39;s to omit some space. This was useful in my scenario as the variable on the x-axis could only take on values between 0 and 1, therefore the leading 0 is not important.&lt;/p&gt;

&lt;p&gt;One way to remove the leading 0 is to convert the continuous variable into a character variable and use a simple regular expression (with &lt;em&gt;gsub&lt;/em&gt;) to remove the 0 at the beginning of the character string. Below is the code to do that and also the resulting plot. The key point of the plotting code below is the use of the &lt;em&gt;breaks&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;. Without this all the unique character values will be plotted, not good.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.1&#39;, &#39;.15&#39;, &#39;.2&#39;, &#39;.25&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotno0-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot above has a few flaws. First, there are values at the edge of each facet. This could be fixed with the &lt;em&gt;expand&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;, but I still wanted to include the value of .00 on the x-axis. Secondly, the x-axis text labels are not uniformly formatted which is not ideal (e.g. .1 should be .10).&lt;/p&gt;

&lt;p&gt;To fix this, some made up data needs to be added to the data frame. Some care needs to be done here as well as a value of .00 can not just be added to the x variable plotted. This would place a non-uniform gap between .00 and .05 (not shown, but try it for yourself by adapting the code below). Therefore, all values between 0 and .031 need to be manually added to the data frame to keep the spacing uniform. Finally, to not plot the made up values, I created a transparency variable called alpha. This variable was used to set the alpha values to 0 for the made up values and 1 for the real values. &lt;em&gt;scale_alpha_discrete&lt;/em&gt; was used to specify the range of alpha values, this is important otherwise the made up numbers will show up as a light gray. The final code to manually add the new data is shown below. Anyone have a less workaround procedure?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Reset aggregation vector
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))

# Add values
simdata_agg &amp;lt;- rbind(data.frame(x_rd = seq(0, .031, .001),
                                group = rep(1, 32),
                                facet = rep(1, 32),
                                y = rep(0, 32)),
                     simdata_agg)

# Create a new variable to use for transparent points
simdata_agg$alpha &amp;lt;- ifelse(simdata_agg$x_rd &amp;lt; .032, 0, 1)

# Create x_char variable again
simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)

# Needed formatting
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;&#39;, &#39;.00&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.2&#39;, &#39;.20&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.1&#39;, &#39;.10&#39;,
                             simdata_agg$x_char)

# Final plot
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(aes(alpha = factor(alpha)), size = 3) + 
  facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.10&#39;, &#39;.15&#39;, &#39;.20&#39;),
                   expand = c(.05, .05)) + 
  scale_alpha_discrete(guide = FALSE, range = c(0, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/addmadeupvalues-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
				<pubDate>Mon, 23 Mar 2015 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2015/03/23/removelead0/</link>
				<guid isPermaLink="true">http://educate-r.org//2015/03/23/removelead0/</guid>
			</item>
		
			<item>
				<title>Structured simulation of regression models - simReg package.</title>
				<description>&lt;p&gt;I&#39;d like to introduce a package that simulates regression models. This includes both single level and multilevel (i.e. hierarchical or linear mixed) models up to two levels of nesting. The package produces a unified framework to simulate all types of continuous regression models. In the future, I&#39;d like to add the ability to simulate generalized linear models. This package is an extension of the functions I used to simulate data for my dissertation.&lt;/p&gt;

&lt;p&gt;The package is currently on github &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;https://github.com/lebebr01/simReg&lt;/a&gt;. Therefore, you can currently install the package by using the &lt;em&gt;devtools&lt;/em&gt; package like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(&quot;lebebr01/simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The primary function of interest in this package is &lt;em&gt;sim.reg&lt;/em&gt;. To show the use of this function, here is a simple example simulating a single level regression mode. Note, this example is pulled directly from the &lt;strong&gt;Intro&lt;/strong&gt; vignette.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simReg)
set.seed(100)
fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed.param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov.param &amp;lt;- list(mean = c(0, 0, 0), sd = c(4, 3, 3), var.type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
n &amp;lt;- 150
errorVar &amp;lt;- 3
err.dist &amp;lt;- &quot;norm&quot;
temp.single &amp;lt;- sim.reg(fixed = fixed, fixed.param = fixed.param, cov.param = cov.param,
n = n, errorVar = errorVar, err.dist = err.dist, data.str = &quot;single&quot;)
head(temp.single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.     act     diff numCourse act.numCourse    Fbeta      err
## 1            1 -2.0088  3.10406    -5.566       11.1815 -0.05022 -3.35921
## 2            1  0.5261  4.96051    -3.056       -1.6077 -4.84527 -5.75176
## 3            1 -0.3157 -0.05384    -3.135        0.9897 -8.31073  1.63173
## 4            1  3.5471 -0.07261    -1.954       -6.9306 -4.58382  0.06435
## 5            1  0.4679  0.75074     1.148        0.5372  9.71476 -0.44783
## 6            1  1.2745 -1.01137     3.096        3.9455 24.81272  0.59651
##   sim.data ID
## 1   -3.409  1
## 2  -10.597  2
## 3   -6.679  3
## 4   -4.519  4
## 5    9.267  5
## 6   25.409  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the above code, the package uses a single sided equation to represent the fixed effects. Other arguments include the values for those fixed effects (fixed.param), the scale for the covariates (cov.param), the sample size (n), the error variance (errorVar), and the error distribution (err.dist). These are all put into the function &lt;em&gt;sim.reg&lt;/em&gt; with the additional argument &lt;em&gt;data.str&lt;/em&gt; to tell the function that we indeed want a single level regression and you get the following output. The data frame that is returned gives the values for the design matrix, the fixed portion of the model (Fbeta), and the random error term (err). The value of most interest if conducting a simulation would be the actually simulated value (sim.data).&lt;/p&gt;

&lt;h3&gt;Nested Example&lt;/h3&gt;

&lt;p&gt;A slightly more complicated example is shown below where longitudinal data are simulated.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time + diff
fixed.param &amp;lt;- c(4, 2, 6, 2.3, 7)
random.param &amp;lt;- c(7, 4, 2)
cov.param &amp;lt;- list(mean = c(0, 0), sd = c(1.5, 4), var.type = c(&quot;lvl1&quot;, &quot;lvl2&quot;))
n &amp;lt;- 150
p &amp;lt;- 30
errorVar &amp;lt;- 4
randCor &amp;lt;- 0
rand.dist &amp;lt;- &quot;norm&quot;
err.dist &amp;lt;- &quot;norm&quot;
serCor &amp;lt;- &quot;ID&quot;
serCorVal &amp;lt;- NULL
data.str &amp;lt;- &quot;long&quot;
temp.long &amp;lt;- sim.reg(fixed, random, fixed.param, random.param, cov.param,
n, p, errorVar, randCor, rand.dist, err.dist, serCor, serCorVal, data.str)
head(temp.long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time     diff    act time.act    b0      b1    b2   Fbeta
## 1            1    0 -0.05455  1.608    0.000 5.118 -0.1118 0.251   7.371
## 2            1    1 -2.23677 -1.349   -1.349 5.118 -0.1118 0.251 -19.968
## 3            1    2  0.50321 -6.028  -12.056 5.118 -0.1118 0.251 -87.237
## 4            1    3  1.25027  8.436   25.308 5.118 -0.1118 0.251 214.063
## 5            1    4  2.05871  3.917   15.667 5.118 -0.1118 0.251 143.031
## 6            1    5 -1.87968  7.598   37.990 5.118 -0.1118 0.251 286.125
##   randEff     err sim.data withinID clustID
## 1   5.104  3.2637    15.74        1       1
## 2   4.444  0.9355   -14.59        2       1
## 3   5.020 -3.1693   -85.39        3       1
## 4   5.096  4.1523   223.31        4       1
## 5   5.187 -3.1716   145.05        5       1
## 6   4.086 -0.2605   289.95        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the arguments should look familiar to above, but a few are new. Most notably these are a one sided equation for the random effects (random), their variances (random.param), the number of observations within a cluster (p), the correlation among the random effects (randCor), the simulated distribution of the random effects (rand.dist), the serial correlation model for within cluster residuals (serCor), the values for the serial correlation models (serCorVal). Note now since this represents longitudinal data, the &lt;em&gt;data.str&lt;/em&gt; argument is now specified as &#39;long&#39;.&lt;/p&gt;

&lt;h3&gt;Other features&lt;/h3&gt;

&lt;p&gt;The package also simulates cross sectional multilevel models, covariates that are either a factor, ordinal, or categorical, and the basics for power simulation are there.&lt;/p&gt;

&lt;p&gt;For further information, see the vignette by doing the following after installing the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;vignette(&quot;Intro&quot;, package = &quot;simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bugs, comments, or feature requests can be submitted on the github site &lt;a href=&quot;https://github.com/lebebr01/simReg/issues&quot;&gt;https://github.com/lebebr01/simReg/issues&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Wed, 01 Oct 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/10/01/simReg/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/10/01/simReg/</guid>
			</item>
		
			<item>
				<title>Google location data -- Where I've been.</title>
				<description>&lt;p&gt;I was emailed by a friend that was looking into their google location data and had asked if I had ever used a json file before in R. I said I had not, but I knew there were packages to do such things. The things I sent were things he had already tried, so what did I decide to do? I went ahead and downloaded my own google location data.&lt;/p&gt;

&lt;p&gt;If you use google services (particularly have an android phone) you can get your google location information here buried in google&#39;s settings page: &lt;a href=&quot;https://www.google.com/settings/datatools&quot;&gt;Google Data Page&lt;/a&gt;. From there you can click on create new archive at the bottom of the rightmost column under &quot;Download your data&quot;. If you&#39;d like to replicate the map below, you just need the location data, therefore I unselected all of the options except for location. Then there is some thinking on google&#39;s servers and they give you a download file (either .zip, .tbz, or .tgz) from which you can download. Mine did not take long to prepare, if they have more location information on you it may take longer.&lt;/p&gt;

&lt;p&gt;Below is a map of all the locations I&#39;ve been. I rounded the latitude and longitude values to two decimals (and had to add the decimals) to create less exact location values. This step could obviously be omitted. You&#39;ll notice in the ggplot2 code that I set the alpha equal to .01, this allowed the locations where I&#39;ve been longer to be darker. You could get more fancy with this, especially if you are able to figure out the code google uses for their timestamp. Just looked like mumbo jumbo to me. There is also accuracy, velocity, heading, altitude, and activity data.&lt;/p&gt;

&lt;p&gt;Kind of a cool process. The map shows places I&#39;ve been the last year or so (does not include San Francisco from AERA two years ago) including living in Fayetteville, Iowa City, Saint Paul. It also shows a few places I was for interviews last year including travel through some airports (Dallas, Houston, Charlotte, Chicago) and even shows my honeymoon to the panhandle of Florida. It also made me realize how much more I need to explore to the west (and east to some extent).&lt;/p&gt;

&lt;p&gt;Below is the code I used to load, manipulate, and plot my google location data. To replicate you would need to download your own google location data. Has anyone else made sense of all this data?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/myjson.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rjson)
json_file &amp;lt;- &quot;path/to/your/json/file&quot;
json_data &amp;lt;- fromJSON(file = json_file)
latlong &amp;lt;- data.frame(do.call(&quot;rbind&quot;, json_data[[2]]))
latlong2 &amp;lt;- subset(latlong, select = c(latitudeE7, longitudeE7))
latlong2$latR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$latitudeE7), 1, 2), 
                                   &quot;.&quot;, substr(as.character(latlong2$latitudeE7), 3, 4)))
latlong2$longR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$longitudeE7), 1, 3), 
                                    &quot;.&quot;, substr(as.character(latlong2$longitudeE7), 4, 5)))

library(maps)
library(ggplot2)

states &amp;lt;- map_data(&quot;state&quot;)

p &amp;lt;- ggplot(states) + 
  geom_polygon(aes(x = long, y = lat, group = group), 
               fill = &quot;white&quot;, color = &quot;black&quot;) + 
  theme_bw() + 
  theme(axis.text = element_blank(), line = element_blank(), 
        rect = element_blank(), axis.title = element_blank())
p + geom_point(data = latlong2, aes(x = longR, y = latR), 
               alpha = .01, color = &quot;red&quot;, size = 3)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Fri, 26 Sep 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/09/26/googlelocations/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/09/26/googlelocations/</guid>
			</item>
		
			<item>
				<title>Offense or defense improve likelihood of becoming bowl eligible?</title>
				<description>&lt;p&gt;I saw a post recently about the likelihood of a baseball team winning based on how many runs, hits, and other baseball statistics. I liked the idea and thought of applying that to college football. Particularly, I&#39;m interested in knowing whether scoring more points or having a stout defense improves the likelihood of becoming bowl eligible.&lt;/p&gt;

&lt;p&gt;Using some data scraped from the &lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;cfbDatawarehouse&lt;/a&gt; to figure out how likely a team would be bowl eligible based on the number of points they score. Below are the results of my exploration looking at both the points scores metric and the points against metric (also there is a quick interactive rCharts version of the plot down further). Seems to me that scoring more points leads to more assured success in the college game, perhaps that is why offensive recruits seem to be more sought after. This would also be interesting to create by decade to see if trends have shifted over the years.&lt;/p&gt;

&lt;p&gt;Enjoy, plots (and code for plots) shown below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;p &amp;lt;- ggplot(coaches, aes(x = PF)) + theme_bw() 
p + stat_smooth(data = ovrBE, aes(x = avg, y = bpct, linetype = group), 
                se = FALSE, size = 1.5, method = &quot;loess&quot;) + 
  geom_point(data = ovrBE, aes(x=avg, y = bpct, color = group), size = 2) + 
  scale_x_continuous(&quot;Points&quot;, limits = c(0, 500), breaks = c(0, 100, 200, 300, 400, 500)) + 
  scale_color_brewer(palette = &quot;Dark2&quot;) + 
  ylab(&quot;Bowl Eligibility Likelihood&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/points.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)

h1 &amp;lt;- hPlot(x = &quot;avg&quot;, y = &quot;bpct&quot;, group = &quot;group&quot;, data = ovrBE)
h1$yAxis(title = list(text = &quot;Bowl Eligibility Likelihood&quot;), min = 0, max = 1, tickInterval = .1)
h1$xAxis(title = list(text = &quot;Points&quot;),
         min = 0, max = 500, tickInterval = 100)
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Group&quot;))
h1$plotOptions(series = list(lineWidth = 2))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;script type=&#39;text/javascript&#39; src=//code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts-more.js&quot;&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 400px;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Bowl Eligibility Likelihood&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:              1,
&quot;tickInterval&quot;:            0.1 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
           34.5,
         0.848 
],
[
           62.5,
         0.889 
],
[
           71.5,
          0.85 
],
[
           77.5,
         0.881 
],
[
             83,
         0.846 
],
[
             88,
         0.789 
],
[
             92,
         0.702 
],
[
             96,
         0.789 
],
[
           99.5,
         0.745 
],
[
          102.5,
         0.708 
],
[
            105,
         0.625 
],
[
            108,
         0.753 
],
[
          111.5,
         0.754 
],
[
          114.5,
         0.704 
],
[
            117,
         0.732 
],
[
          119.5,
         0.697 
],
[
            122,
         0.649 
],
[
            124,
         0.627 
],
[
          126.5,
         0.643 
],
[
            129,
         0.635 
],
[
            131,
         0.732 
],
[
          133.5,
         0.657 
],
[
            136,
         0.721 
],
[
            138,
         0.532 
],
[
            140,
         0.593 
],
[
            142,
         0.617 
],
[
            144,
         0.531 
],
[
            146,
         0.582 
],
[
          147.5,
         0.576 
],
[
            149,
         0.646 
],
[
            151,
         0.542 
],
[
            153,
         0.692 
],
[
            155,
         0.619 
],
[
            157,
         0.677 
],
[
            159,
         0.582 
],
[
          160.5,
         0.553 
],
[
            162,
         0.573 
],
[
            164,
         0.611 
],
[
          165.5,
         0.725 
],
[
            167,
         0.585 
],
[
            169,
         0.597 
],
[
          170.5,
         0.676 
],
[
            172,
           0.5 
],
[
          173.5,
         0.619 
],
[
            175,
         0.508 
],
[
            177,
         0.514 
],
[
            179,
         0.533 
],
[
            181,
         0.549 
],
[
          182.5,
         0.479 
],
[
            184,
         0.635 
],
[
          185.5,
         0.571 
],
[
            187,
         0.531 
],
[
          188.5,
         0.564 
],
[
            190,
         0.594 
],
[
            192,
         0.557 
],
[
          193.5,
         0.556 
],
[
            195,
         0.593 
],
[
          196.5,
         0.703 
],
[
            198,
         0.562 
],
[
          199.5,
         0.578 
],
[
            201,
         0.508 
],
[
            203,
         0.623 
],
[
            205,
         0.657 
],
[
            207,
         0.536 
],
[
          208.5,
         0.487 
],
[
          209.5,
          0.55 
],
[
            211,
         0.588 
],
[
          212.5,
          0.49 
],
[
          213.5,
         0.462 
],
[
            215,
         0.479 
],
[
            217,
         0.533 
],
[
            219,
         0.704 
],
[
          220.5,
         0.562 
],
[
            222,
         0.468 
],
[
            224,
         0.574 
],
[
          225.5,
         0.568 
],
[
          226.5,
          0.64 
],
[
            228,
         0.593 
],
[
          229.5,
         0.629 
],
[
            231,
         0.531 
],
[
            233,
         0.478 
],
[
            235,
         0.464 
],
[
          236.5,
         0.469 
],
[
            238,
         0.539 
],
[
            240,
         0.547 
],
[
          241.5,
         0.423 
],
[
            243,
         0.561 
],
[
          244.5,
         0.353 
],
[
            246,
         0.603 
],
[
            248,
         0.429 
],
[
            250,
          0.54 
],
[
            252,
         0.472 
],
[
            254,
         0.387 
],
[
            256,
         0.609 
],
[
          257.5,
         0.472 
],
[
            259,
         0.478 
],
[
            261,
         0.426 
],
[
            263,
         0.485 
],
[
            265,
          0.47 
],
[
          266.5,
         0.361 
],
[
            268,
         0.453 
],
[
          270.5,
         0.386 
],
[
            273,
         0.475 
],
[
            275,
         0.407 
],
[
          276.5,
         0.622 
],
[
            278,
           0.5 
],
[
            280,
         0.481 
],
[
            282,
         0.589 
],
[
          283.5,
         0.378 
],
[
            285,
         0.549 
],
[
            287,
          0.46 
],
[
            289,
         0.486 
],
[
            291,
         0.379 
],
[
          293.5,
          0.43 
],
[
          295.5,
         0.364 
],
[
            297,
         0.453 
],
[
          299.5,
         0.353 
],
[
            302,
         0.447 
],
[
          304.5,
         0.489 
],
[
            307,
         0.358 
],
[
          309.5,
           0.5 
],
[
            312,
         0.351 
],
[
          314.5,
         0.426 
],
[
          317.5,
           0.4 
],
[
            321,
           0.4 
],
[
          324.5,
         0.333 
],
[
          327.5,
         0.385 
],
[
          330.5,
         0.246 
],
[
            334,
         0.328 
],
[
          337.5,
         0.227 
],
[
          340.5,
         0.357 
],
[
          343.5,
         0.396 
],
[
            347,
         0.297 
],
[
            351,
         0.262 
],
[
            355,
          0.31 
],
[
            359,
         0.308 
],
[
            363,
         0.308 
],
[
            367,
         0.348 
],
[
          371.5,
         0.291 
],
[
          376.5,
         0.246 
],
[
            382,
         0.309 
],
[
          387.5,
         0.255 
],
[
            394,
         0.259 
],
[
          402.5,
         0.206 
],
[
            412,
         0.177 
],
[
          421.5,
         0.232 
],
[
            431,
         0.164 
],
[
            448,
         0.136 
],
[
          477.5,
         0.183 
] 
],
&quot;name&quot;: &quot;Points Against&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
},
{
 &quot;data&quot;: [
 [
           34.5,
             0 
],
[
           62.5,
             0 
],
[
           71.5,
             0 
],
[
           77.5,
             0 
],
[
             83,
         0.015 
],
[
             88,
         0.018 
],
[
             92,
         0.016 
],
[
             96,
         0.017 
],
[
           99.5,
             0 
],
[
          102.5,
         0.048 
],
[
            105,
             0 
],
[
            108,
          0.05 
],
[
          111.5,
         0.127 
],
[
          114.5,
         0.102 
],
[
            117,
         0.125 
],
[
          119.5,
         0.125 
],
[
            122,
         0.115 
],
[
            124,
         0.055 
],
[
          126.5,
         0.159 
],
[
            129,
         0.149 
],
[
            131,
         0.183 
],
[
          133.5,
         0.088 
],
[
            136,
         0.147 
],
[
            138,
          0.18 
],
[
            140,
         0.158 
],
[
            142,
         0.096 
],
[
            144,
         0.098 
],
[
            146,
         0.211 
],
[
          147.5,
         0.197 
],
[
            149,
         0.143 
],
[
            151,
         0.164 
],
[
            153,
         0.167 
],
[
            155,
         0.189 
],
[
            157,
         0.305 
],
[
            159,
         0.433 
],
[
          160.5,
         0.262 
],
[
            162,
         0.361 
],
[
            164,
         0.149 
],
[
          165.5,
         0.276 
],
[
            167,
         0.324 
],
[
            169,
         0.391 
],
[
          170.5,
         0.324 
],
[
            172,
         0.315 
],
[
          173.5,
         0.296 
],
[
            175,
           0.4 
],
[
            177,
          0.39 
],
[
            179,
         0.259 
],
[
            181,
         0.323 
],
[
          182.5,
         0.397 
],
[
            184,
         0.364 
],
[
          185.5,
         0.314 
],
[
            187,
         0.321 
],
[
          188.5,
         0.343 
],
[
            190,
         0.403 
],
[
            192,
         0.406 
],
[
          193.5,
         0.478 
],
[
            195,
         0.446 
],
[
          196.5,
         0.378 
],
[
            198,
         0.381 
],
[
          199.5,
         0.328 
],
[
            201,
         0.339 
],
[
            203,
         0.475 
],
[
            205,
          0.44 
],
[
            207,
         0.407 
],
[
          208.5,
         0.493 
],
[
          209.5,
         0.514 
],
[
            211,
         0.382 
],
[
          212.5,
         0.579 
],
[
          213.5,
         0.429 
],
[
            215,
         0.367 
],
[
            217,
         0.418 
],
[
            219,
         0.344 
],
[
          220.5,
           0.5 
],
[
            222,
         0.446 
],
[
            224,
         0.362 
],
[
          225.5,
         0.353 
],
[
          226.5,
         0.531 
],
[
            228,
         0.488 
],
[
          229.5,
         0.429 
],
[
            231,
         0.562 
],
[
            233,
         0.559 
],
[
            235,
         0.706 
],
[
          236.5,
         0.548 
],
[
            238,
         0.475 
],
[
            240,
         0.561 
],
[
          241.5,
         0.687 
],
[
            243,
         0.673 
],
[
          244.5,
         0.587 
],
[
            246,
         0.621 
],
[
            248,
         0.623 
],
[
            250,
         0.596 
],
[
            252,
          0.69 
],
[
            254,
         0.547 
],
[
            256,
         0.705 
],
[
          257.5,
         0.647 
],
[
            259,
         0.729 
],
[
            261,
         0.633 
],
[
            263,
         0.719 
],
[
            265,
         0.644 
],
[
          266.5,
         0.787 
],
[
            268,
         0.693 
],
[
          270.5,
         0.672 
],
[
            273,
         0.772 
],
[
            275,
           0.8 
],
[
          276.5,
         0.604 
],
[
            278,
         0.746 
],
[
            280,
         0.706 
],
[
            282,
          0.75 
],
[
          283.5,
         0.708 
],
[
            285,
         0.845 
],
[
            287,
           0.7 
],
[
            289,
         0.889 
],
[
            291,
         0.714 
],
[
          293.5,
         0.908 
],
[
          295.5,
         0.796 
],
[
            297,
          0.75 
],
[
          299.5,
         0.811 
],
[
            302,
         0.806 
],
[
          304.5,
         0.839 
],
[
            307,
         0.929 
],
[
          309.5,
         0.905 
],
[
            312,
         0.889 
],
[
          314.5,
         0.827 
],
[
          317.5,
         0.789 
],
[
            321,
         0.873 
],
[
          324.5,
         0.883 
],
[
          327.5,
         0.954 
],
[
          330.5,
         0.898 
],
[
            334,
         0.905 
],
[
          337.5,
         0.909 
],
[
          340.5,
         0.981 
],
[
          343.5,
             1 
],
[
            347,
         0.984 
],
[
            351,
         0.962 
],
[
            355,
         0.957 
],
[
            359,
         0.931 
],
[
            363,
          0.98 
],
[
            367,
          0.97 
],
[
          371.5,
          0.93 
],
[
          376.5,
             1 
],
[
            382,
         0.984 
],
[
          387.5,
         0.984 
],
[
            394,
         0.981 
],
[
          402.5,
         0.982 
],
[
            412,
             1 
],
[
          421.5,
         0.984 
],
[
            431,
             1 
],
[
            448,
             1 
],
[
          477.5,
             1 
] 
],
&quot;name&quot;: &quot;Points Scored&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Points&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:            500,
&quot;tickInterval&quot;:            100 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Group&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              2 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot; 
} 
});
        });
    })(jQuery);
&lt;/script&gt;



</description>
				<pubDate>Fri, 05 Sep 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/09/05/winpct/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/09/05/winpct/</guid>
			</item>
		
			<item>
				<title>Dodged bar charts, why not a line graph?</title>
				<description>&lt;p&gt;I often see graphs that are poorly implemented in that they do not achieve their goal.  One such type of graph that I see are dodged bar charts.  Here is an example of a dodged bar chart summarizing the number of all star players by team (focusing specifically on the AL central division) and year from the &lt;em&gt;Lahman&lt;/em&gt; r package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(Lahman)
library(dplyr)
library(ggplot2)
library(RColorBrewer)

AllstarFull$selected &amp;lt;- 1

numAS &amp;lt;- AllstarFull  %&amp;gt;% 
  filter(yearID &amp;gt; 2006, lgID == &#39;AL&#39;, teamID %in% c(&#39;MIN&#39;, &#39;CLE&#39;, &#39;DET&#39;, &#39;CHA&#39;, &#39;KCA&#39;)) %&amp;gt;%
  group_by(teamID, yearID) %&amp;gt;%
  summarise(number = sum(selected))

b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bar.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: If you are curious from the above graph, there appears to be two typos in the teamIDs, where CHA should be CHW (Chicago White Sox) and KCA should be KCR (Kansas City Royals).&lt;/p&gt;

&lt;p&gt;The plot above can be good for a few things, predominantly for comparison within a team. It is more difficult to compare between teams (although not impossible).  One way to possibly improve the plot would be to add the number either above each bar or inside of each bar.  This can be done in &lt;em&gt;ggplot2&lt;/em&gt; with the &lt;em&gt;geom_text&lt;/em&gt; function.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) + 
  geom_text(aes(label = number), position = position_dodge(width = 0.9), 
            vjust = 1.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bartext.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A better alternative to a dodged bar chart in my opinion would be a simple line graph.  The line graph simplifies the graph to only include one variable on the x-axis and uses colors or shapes to differentiate the teams. See below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;l &amp;lt;- ggplot(numAS, aes(x = yearID, y = number, color = teamID, shape = teamID))
l + geom_point(size = 4) + geom_line(size = 1) +
  scale_y_continuous(limits = c(0, 7), expand = c(0,0)) + 
  scale_color_brewer(&quot;Team&quot;, palette = &quot;Dark2&quot;) + scale_shape_discrete(&quot;Team&quot;) + 
  xlab(&quot;Year&quot;) + theme_bw()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/line.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This presentation makes it much easier to compare teams within a single year and also see how the teams have changed over time. The ability to see differences also increases as the variability in the variable increases. In my opinion this is a much simpler graphic and usually is a better option to serve the purpose for the graphic. As always though, the best graphic is one that conveys the message in the simplest, easiest to understand form. You could improve this by making it interactive with &lt;em&gt;rCharts&lt;/em&gt;.  See my post on &lt;em&gt;rCharts&lt;/em&gt; &lt;a href=&quot;/2014/02/15/rcharts/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/2014/03/03/rChartsslidy/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Tue, 05 Aug 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/08/05/trendgraphics/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/08/05/trendgraphics/</guid>
			</item>
		
			<item>
				<title>Format Markdown Documents in R</title>
				<description>&lt;p&gt;Have you ever used a markdown file to create an html file?  Have you ever wanted to quickly format the subsequent html file to add some color or other aspects?  If your answer is yes to both of those questions, this package may be of interest to you.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;&lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;&lt;/strong&gt; package aims to develop a flexible approach to add formatting to an html document by injecting CSS into the file.  To do this, tags are created within the markdown document telling the R routine where to look for these tags.  If you are familiar with the Twitterverse, this package will be equally comfortable.  The tags take the form of the hashtags on Twitter.  As an example, #bgblue, would be a command to change the background to blue.&lt;/p&gt;

&lt;p&gt;The next thing needed by the package is to tell how much of the word, sentence, or header that should be affected by the tag.  To do this, add braces before the tag and include all the content you want to be affected by the tag.  For example, {#bggold this example will have a blue background}.&lt;/p&gt;

&lt;p&gt;Once any tags you want to include are in the markdown document, then the document can be converted into a html file using programs such as &lt;em&gt;knitr&lt;/em&gt;, &lt;em&gt;pandoc&lt;/em&gt;, the RStudio &quot;knit HTML&quot; button (or any others).  Once the resulting html file is compiled, then run the html file through the &lt;strong&gt;highlightHTML&lt;/strong&gt; package and the html file is searched for the tags, the tags are changed to CSS ids, and by default the CSS tags will be inserted automatically back into the document.&lt;/p&gt;

&lt;h3&gt;Minimal Example&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;A markdown document that looks like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;markdown&quot;&gt;# Test of {#colgold highlightHTML} package

Can highlight {#bgblack multiple words}.

Even tables:

| Color Name | Number     |  
|------------|------------|  
| Blue       | 5  #bgblue |  
| Green      | 35         |  
| Orange     | 100        |  
| Red        | 200 #bgred |  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You would then convert the markdown above into a html file (I hit the knit HTML button in RStudio for this file), then run the following commands in R (assuming the highlightHTML package is not installed):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;)
library(highlightHTML)

tags &amp;lt;- c(&quot;#bgred {background-color: red;}&quot;, &quot;#bgblue {background-color: blue;}&quot;,
          &quot;#colgold {color: gold;}&quot;, &quot;#bgblack {background-color: black; color: white;}&quot;)
highlightHTML(input = &quot;path/to/infile.html&quot;, output = &quot;path/to/outfile.html&quot;, 
              updateCSS = TRUE, tags = tags, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will process the html file, look for tags, change the tags to CSS ids, inject the CSS into the document, and lastly open the output file in the browser to see how it looks.  The example above would look like the following after the above commands:
&lt;img src=&quot;http://educate-r.org/figs/mwe.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also go to this link to see the post-processed file: &lt;a href=&quot;/mwe.html&quot;&gt;educate-r.org/mwe.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Upcoming Features&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Currently the package assumes that you know CSS and can supply your own tags.  In the future I&#39;d like to relax this and allow for some basic tags that work without needing to supply the CSS.  I&#39;m hoping to allow background color and text color changes to be made without needing to specify the CSS.  For example, when specifying #bgblue in the markdown file, the R program knows that you want the background color (bg) to be blue.&lt;/p&gt;

&lt;p&gt;Try it out and let me know of new features or bugs as you work through the package.&lt;/p&gt;
</description>
				<pubDate>Wed, 30 Jul 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/07/30/highlightHTML/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/07/30/highlightHTML/</guid>
			</item>
		
			<item>
				<title>R gui Revisited</title>
				<description>&lt;p&gt;A couple months ago I wrote about switching my class from using SPSS to one that uses R with a gui frontend (&lt;a href=&quot;http://educate-r.org/2014/02/03/Rgui/&quot;&gt;original post&lt;/a&gt;).  Since the semester has wrapped up, below are my thoughts on how the course went with respect to the students using R.&lt;/p&gt;

&lt;h4&gt;Things that went well&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Many students by the end were starting to understand the power of R (even through a gui structure).  Most were able to create new variables, run statistical analyses, produce basic graphs or figures, and even understand a few basic commands. They also enjoyed that the language and program were free and they could bring their laptops to class when we were going to talk about doing something new in R.&lt;/p&gt;

&lt;p&gt;I also did not hear any stories of a gui system crashing (which was one complaint of &lt;em&gt;Deducer&lt;/em&gt; in the comments of my last post).  I had students using either &lt;em&gt;Deducer&lt;/em&gt; or &lt;em&gt;Rcmdr&lt;/em&gt;, but whenever possible steered them toward &lt;em&gt;Deducer&lt;/em&gt; as it is a bit more user friendly (in my opinion) and uses &lt;em&gt;ggplot2&lt;/em&gt; by default for graphics.  Although &lt;em&gt;Deducer&lt;/em&gt; did crash on me once while demonstrating something during class, I did not hear any students complain about it.&lt;/p&gt;

&lt;p&gt;During the last two weeks of the course when more assignments surrounding basic inferential methods were due, students were becoming much more confident and better able to navigate the R gui menus.  I do also think that the students did appreciate the simpleness of the R output, only giving you what you ask for (as compared to SPSS that gives you extremely more than you ask for). One part of any gui system is to figure out the menu structure and understand the basic language of the menu.  Once I was able to point students to the correct menus, give them correct names for statistical procedures, and also point out specific R terminology they were much more comfortable doing things on their own (and even on occasion trying new things on their own).&lt;/p&gt;

&lt;h4&gt;Things that went poorly&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Using both &lt;em&gt;Deducer&lt;/em&gt; and &lt;em&gt;Rcmdr&lt;/em&gt; in the class.  I did not want to do this initially, but was forced to do it as I was unsure initially why some students were getting an error (it is based on the Java version installed).  I should have spent more time trying to transition students to &lt;em&gt;Deducer&lt;/em&gt; after figuring out the error, however did not want to have them learn a new system after starting to learn &lt;em&gt;Rcmdr&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Another sticky spot was that I did not have students learn &lt;em&gt;Markdown&lt;/em&gt;, therefore students were copying and pasting output into Word. If anyone has tried this in the past, it usually does not format the best.  In the future (definitely for a PhD level course) I would have students learn &lt;em&gt;Markdown&lt;/em&gt; as it would likely not take more than an hour.&lt;/p&gt;

&lt;p&gt;Students using &lt;em&gt;Rcmdr&lt;/em&gt; had difficulty created dichotomous variables from a continuous variable.  With &lt;em&gt;Rcmdr&lt;/em&gt;, one needs to know some basic R commands (like &lt;em&gt;ifelse&lt;/em&gt;) in order to create dichotomous variables.  This is not something that I spent much time going over in class and was a definite stumbling block for many students.&lt;/p&gt;

&lt;p&gt;An unfortunate aspect of any course where students need to learn software (or just any type of material in general) is that some students do not feel the software is something they are going to use down the road.  As a result, a handful of students seemed to be a bit more obstinate regarding the use of R (and my guess would have been a similar reaction to using SPSS).&lt;/p&gt;

&lt;p&gt;Lastly, I did not have assignments that focused specifically on learning R.  If I ever teach a course of this level again (which may not occur at my new job at the University of Iowa) I would definitely have more regular small assignments to accomplish more data manipulation tasks, such as creating a new variable, turn a variable into a factor, etc.&lt;/p&gt;

&lt;h4&gt;Summary&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;In general I was pleased with using R and more specifically using a R gui for the the course.  The scope of the class was not to teach students a statistical language and for many of these students this was likely their last research/statistics course. This gave me one shot to try to get them familiar enough with the program to be an option for them in the future.  I do feel that the students became familiar enough with R during the course to be able to use it for basic data manipulation and analysis in the future, but are still tied to the gui system.&lt;/p&gt;

&lt;p&gt;With that being said, if I ever teach a similar course in the future, I would likely create a shiny app that allows students to interact in the browser instead of using the R gui. The scope of the course is focused more on interpretation of the output rather than learning the statistical package to get the output, so the shiny app would work well (I&#39;m imagining a Tinkerplots-esque look and feel). I would also recommend for anyone who has students and a course at a similar level and you choose to use a gui system for R, to use &lt;em&gt;Deducer&lt;/em&gt;.  Once the initial setup bottlenecks are worked out it is much easier for the students to learn and use (and is more similar to SPSS if they use that program in the future).&lt;/p&gt;
</description>
				<pubDate>Tue, 27 May 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/05/27/rguirevisit/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/05/27/rguirevisit/</guid>
			</item>
		
			<item>
				<title>AERA Preview</title>
				<description>&lt;p&gt;The American Educational Research Association (AERA) annual conference is this weekend in Philadelphia.  I was lucky to have a paper accepted into the conference.  I am presenting a meta analysis that I have been working on for the past two years or so titled: Model misspecification and assumption violations with the linear mixed model: A meta analysis.&lt;/p&gt;

&lt;p&gt;In this paper, I have compiled numerous monte carlo studies perform a quantitative synthesis of the literature.  I have focused primarily on longitudinal linear mixed models as that was what my dissertation topic, and practically speaking, I already had many monte carlo studies in hand making the task a bit simpler.&lt;/p&gt;

&lt;p&gt;Here is a sneak peak of some of the results from my paper in the form of an interactive chart using the &lt;em&gt;rChart&lt;/em&gt; package to get started.  Here is my r code to generate the initial chart:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)
h1 &amp;lt;- hPlot(x = &quot;fitSerCor2&quot;, y = &quot;avgt1e&quot;, group = &quot;missRE&quot;, data = intmean)
h1$yAxis(title = list(text = &quot;Empirical Type I Error Rate&quot;), min = 0.00, max = 0.2, tickInterval = 0.05)
h1$xAxis(title = list(text = &quot;Fitted Serial Correlation Structure&quot;),
         categories = c(&quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot;))
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Miss RE&quot;))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As in one of my prior posts about &lt;em&gt;rCharts&lt;/em&gt; I manually added a few features to the Javascript manually.  I find that easier than bundling lists upon lists to achieve the desired result.  Below is the final image:&lt;/p&gt;

&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 600px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Empirical Type I Error Rate&quot;,
   style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
   }
},
labels: {
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            0.2,
&quot;tickInterval&quot;:           0.05 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.0519
],
 [
 &quot;AR1&quot;,
0.0635
],
[
 &quot;MA1&quot;,
0.0639
],
[
 &quot;MA2&quot;,
0.0665
], 
[
 &quot;ARMA&quot;,
0.0656
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#e41a1c&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;0&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.1837
],
 [
 &quot;AR1&quot;,
0.0864
],
[
 &quot;MA1&quot;,
0.1155
],
[
 &quot;MA2&quot;,
0.0999
], 
[
 &quot;ARMA&quot;,
0.0896
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#377eb8&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;1&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted Serial Correlation Structure&quot;,
 style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Miss RE&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;,
  zoomType: &quot;y&quot;,
   &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;p&gt;If anyone is attending AERA this year and wants to listen to my presentation as well as others dealing with Methodological Considerations in Modeling Latent Growth (the title of the session) stop by the Convention Center on Sunday, April 6th from 4:05 to 5:35 pm in room 117.  Even if you do not want to hear about modeling latent growth, but would rather talk about r, perhaps we can meetup somewhere else.&lt;/p&gt;
</description>
				<pubDate>Wed, 02 Apr 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/04/02/aerapreview/</link>
				<guid isPermaLink="true">http://educate-r.org//2014/04/02/aerapreview/</guid>
			</item>
		
	</channel>
</rss>
