<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Brandon LeBeau</title>
 <link href="http://lebebr01.github.io/atom.xml" rel="self"/>
 <link href="http://lebebr01.github.io/"/>
 <updated>2017-05-23T15:09:42-05:00</updated>
 <id>http://lebebr01.github.io/</id>
 <author>
   <name>Brandon LeBeau</name>
   <email>lebebr01@gmail.com</email>
 </author>

 
 <entry>
   <title>simglm submission to CRAN this week</title>
   <link href="http://lebebr01.github.io/2017/05/23/simglmcran.html"/>
   <updated>2017-05-23T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2017/05/23/simglmcran</id>
   <content type="html">&lt;p&gt;This is a quick note looking for any further feedback on the simglm package prior to CRAN submission later this week. The goal is to submit Thursday or Friday this week. The last few documentation finishing touches are happening now working toward a version 0.5.0 release on CRAN.&lt;/p&gt;

&lt;p&gt;For those who have not seen this package yet, the aim is to simulate regression models (single level and multilevel models) as well as employ empirical power analyses based on Monte Carlo simulation. The package is relatively flexible in user control of inputs to generate data.&lt;/p&gt;

&lt;p&gt;To install the package and also build the vignettes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&quot;lebebr01/simglm&quot;, build_vignettes = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then to generate a simple single level data set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simglm)

fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed_param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;), 
                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;),
                  cov_param = list(list(mean = 0, sd = 4),
                                   list(mean = 0, sd = 3),
                                   list(mean = 0, sd = 3)))
n &amp;lt;- 150
error_var &amp;lt;- 3
with_err_gen = &#39;rnorm&#39;
temp_single &amp;lt;- sim_reg(fixed = fixed, fixed_param = fixed_param, 
                       cov_param = cov_param,
                       n = n, error_var = error_var, 
                       with_err_gen = with_err_gen, 
                       data_str = &quot;single&quot;)
head(temp_single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.         act       diff   numCourse act.numCourse     Fbeta
## 1            1 -2.11697901 -0.1490870 -0.90292680  1.9114770938 -5.954293
## 2            1  0.01298227 -0.1310381 -0.06197237 -0.0008045421  1.702379
## 3            1  0.44564723  0.5913073 -0.59650183 -0.2658293887  1.754481
## 4            1 -0.03528805 -0.5113031 -0.05915731  0.0020875460  1.144669
## 5            1  1.77940941  0.5097288  0.54804919  0.9752038827 13.495946
## 6            1 -1.42185444  0.4145870  1.08424301 -1.5416357400 -2.561252
##          err  sim_data ID
## 1 -0.9567737 -6.911066  1
## 2  1.3386926  3.041071  2
## 3  0.3470914  2.101572  3
## 4  0.9178861  2.062555  4
## 5  0.8016335 14.297580  5
## 6  0.2499601 -2.311292  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then one can extend this to conduct of power analysis. The benefit of this approach is that you are able to generate data that hopefully more closely resembles data that is to be collected and can also evaluate assumption violations, sample size differences, and other conditions directly into the power analysis similar to a Monte Carlo simulation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed_param &amp;lt;- c(0.5, 1.1, 0.6, 0.9, 1.1)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;), 
                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;),
                  opts = list(list(mean = 0, sd = 2),
                              list(mean = 0, sd = 2),
                              list(mean = 0, sd = 1)))
n &amp;lt;- NULL
error_var &amp;lt;- NULL
with_err_gen &amp;lt;- &#39;rnorm&#39;
pow_param &amp;lt;- c(&#39;(Intercept)&#39;, &#39;act&#39;, &#39;diff&#39;, &#39;numCourse&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;t&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 10
terms_vary &amp;lt;- list(n = c(20, 40, 60, 80, 100), error_var = c(5, 10, 20),
                   fixed_param = list(c(0.5, 1.1, 0.6, 0.9, 1.1), 
                                      c(0.6, 1.1, 0.6, 0.9, 1.1)),
                cov_param = list(list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;),
                                       mean = c(0, 0, 0), sd = c(2, 2, 1), 
                                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;)),
                                  list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;),
                                       mean = c(0.5, 0, 0), sd = c(2, 2, 1), 
                                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
                                  )
                   )
power_out &amp;lt;- sim_pow(fixed = fixed, fixed_param = fixed_param, 
                     cov_param = cov_param,
                     n = n, error_var = error_var, with_err_gen = with_err_gen, 
                     data_str = &quot;single&quot;, pow_param = pow_param, alpha = alpha,
                     pow_dist = pow_dist, pow_tail = pow_tail, 
                     replicates = replicates, terms_vary = terms_vary)
head(power_out)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [6 x 11]
## Groups: var, n, error_var, fixed_param [3]
## 
##           var     n error_var         fixed_param
##        &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;              &amp;lt;fctr&amp;gt;
## 1 (Intercept)    20         5 0.5,1.1,0.6,0.9,1.1
## 2 (Intercept)    20         5 0.5,1.1,0.6,0.9,1.1
## 3 (Intercept)    20         5 0.6,1.1,0.6,0.9,1.1
## 4 (Intercept)    20         5 0.6,1.1,0.6,0.9,1.1
## 5 (Intercept)    20        10 0.5,1.1,0.6,0.9,1.1
## 6 (Intercept)    20        10 0.5,1.1,0.6,0.9,1.1
## # ... with 7 more variables: cov_param &amp;lt;fctr&amp;gt;, avg_test_stat &amp;lt;dbl&amp;gt;,
## #   sd_test_stat &amp;lt;dbl&amp;gt;, power &amp;lt;dbl&amp;gt;, num_reject &amp;lt;dbl&amp;gt;, num_repl &amp;lt;dbl&amp;gt;,
## #   data &amp;lt;list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Questions and feedback are welcomed by filing an issue on GitHub here: &lt;a href=&quot;https://github.com/lebebr01/simglm/issues&quot;&gt;https://github.com/lebebr01/simglm/issues&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Make Power Fun (Again?)</title>
   <link href="http://lebebr01.github.io/2017/02/24/csp2017.html"/>
   <updated>2017-02-24T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2017/02/24/csp2017</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Make Power Fun (Again?)&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;(G)LMMs&lt;/li&gt;
&lt;li&gt;Power&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Shiny Demo - Broken!
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linear Mixed Model (LMM)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/equations.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is the ability to statistically detect a true effect (i.e. non-zero population effect).&lt;/li&gt;
&lt;li&gt;For simple models (e.g. t-tests, regression) there are closed form equations for generating power.

&lt;ul&gt;
&lt;li&gt;R has routines for these: &lt;code&gt;power.t.test, power.anova.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gpower3
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Example&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;n &amp;lt;- seq(4, 1000, 2)
power &amp;lt;- sapply(seq_along(n), function(i) 
  power.t.test(n = n[i], delta = .15, sd = 1, type = &#39;two.sample&#39;)$power)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/power_plot-1.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power for (G)LMM&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power for more complex models is not as straightforward;

&lt;ul&gt;
&lt;li&gt;particularly with messy real world data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There is software for GLMM models to generate power:

&lt;ul&gt;
&lt;li&gt;Optimal Design: &lt;a href=&quot;http://hlmsoft.net/od/&quot;&gt;http://hlmsoft.net/od/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLPowSim: &lt;a href=&quot;http://www.bristol.ac.uk/cmm/software/mlpowsim/&quot;&gt;http://www.bristol.ac.uk/cmm/software/mlpowsim/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Snijders, &lt;em&gt;Power and Sample Size in Multilevel Linear Models&lt;/em&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is hard&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In practice, power is hard.&lt;/li&gt;
&lt;li&gt;Need to make many assumptions on data that has not been collected.

&lt;ul&gt;
&lt;li&gt;Therefore, data assumptions made for power computations will likely differ from collected sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A power analysis needs to be flexible, exploratory, and well thought out.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is Fun?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Three common reasons to do power analysis:

&lt;ol&gt;
&lt;li&gt;Power evidence for grant/planning&lt;/li&gt;
&lt;li&gt;Post Hoc to explore insignificant results&lt;/li&gt;
&lt;li&gt;Monte Carlo studies
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; Overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; aims to simulate (G)LMMs with up to three levels of nesting (aim to add more later).&lt;/li&gt;
&lt;li&gt;Flexible data generation allows:

&lt;ul&gt;
&lt;li&gt;any number of covariates and discrete covariates&lt;/li&gt;
&lt;li&gt;change distribution of continuous covariates&lt;/li&gt;
&lt;li&gt;change random distribution&lt;/li&gt;
&lt;li&gt;unbalanced data&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;li&gt;serial correlation
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power with &lt;code&gt;simglm&lt;/code&gt;&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power with &lt;code&gt;simglm&lt;/code&gt; takes on a Monte Carlo approach

&lt;ul&gt;
&lt;li&gt;This can provide a more thorough analysis/understanding of power.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Always outputs a data frame

&lt;ul&gt;
&lt;li&gt;Useful for plotting&lt;/li&gt;
&lt;li&gt;Data manipulation&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Serves as a wrapper around data generation process.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Analysis with &lt;code&gt;simglm&lt;/code&gt;&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Factorial Design:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Idenfity factors that influences power&lt;/li&gt;
&lt;li&gt;Determine number of replications&lt;/li&gt;
&lt;li&gt;Explore results&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Future Development&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add ability for data generation and power model to differ
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simple Example&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Suppose we wished to generate data for a simple logistic regression.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simglm)

fixed &amp;lt;- ~ 1 + act + diff
fixed_param &amp;lt;- c(0.1, 0.5, 0.3)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;),
                  var_type = c(&quot;single&quot;, &quot;single&quot;),
                  opts = list(list(mean = 0, sd = 2),
                              list(mean = 0, sd = 4)))
n &amp;lt;- 50
temp_single &amp;lt;- sim_glm(fixed = fixed, fixed_param = fixed_param, 
                      cov_param = cov_param, 
                      n = n, data_str = &quot;single&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(temp_single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.         act       diff       Fbeta  logistic sim_data ID
## 1            1 -0.02913722 -0.4430546 -0.04748497 0.4881310        1  1
## 2            1  0.66199364  2.1443743  1.07430910 0.7454155        1  2
## 3            1  1.44621026 -1.1909231  0.46582819 0.6143959        0  3
## 4            1 -0.26011629  3.4395304  1.00180096 0.7314125        0  4
## 5            1 -0.09984213  0.8485436  0.30464201 0.5755769        1  5
## 6            1 -2.72704127  3.3246515 -0.26612517 0.4338586        0  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simple Power Analysis&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Suppose we wish to use the same generating model for a power analysis&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;pow_param &amp;lt;- c(&#39;(Intercept)&#39;, &#39;act&#39;, &#39;diff&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;z&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 100

power_out &amp;lt;- sim_pow_glm(fixed = fixed, fixed_param = fixed_param, 
                         cov_param = cov_param, 
                         n = n, data_str = &quot;single&quot;, 
                         pow_param = pow_param, alpha = alpha,
                         pow_dist = pow_dist, pow_tail = pow_tail, 
                         replicates = replicates)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 6
##           var avg_test_stat sd_test_stat power num_reject num_repl
##        &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)      0.878713    0.6709319  0.01          1      100
## 2         act      2.342617    0.5777646  0.34         34      100
## 3        diff      2.609432    0.5506204  0.56         56      100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Varying Arguments&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Now suppose we wish to vary the following arguments:

&lt;ul&gt;
&lt;li&gt;Vary n - 50 vs 150&lt;/li&gt;
&lt;li&gt;vary effect size on diff - .3 vs .45&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;terms_vary &amp;lt;- list(n = c(50, 150),
                   fixed_param = list(c(0.1, 0.5, 0.3), 
                                      c(0.1, 0.5, 0.45)))

power_out &amp;lt;- sim_pow_glm(fixed = fixed, fixed_param = fixed_param, 
                         cov_param = cov_param, 
                         n = n, data_str = &quot;single&quot;, 
                         pow_param = pow_param, alpha = alpha,
                         pow_dist = pow_dist, pow_tail = pow_tail, 
                         replicates = replicates, 
                         terms_vary = terms_vary)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [12 x 8]
## Groups: var, n [?]
## 
##            var     n  fixed_param avg_test_stat sd_test_stat power
##         &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;       &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  (Intercept)    50  0.1,0.5,0.3     0.7778328    0.5863240  0.00
## 2  (Intercept)    50 0.1,0.5,0.45     0.8364212    0.6377631  0.01
## 3  (Intercept)   150  0.1,0.5,0.3     0.8629973    0.5814426  0.00
## 4  (Intercept)   150 0.1,0.5,0.45     0.9183353    0.6879182  0.01
## 5          act    50  0.1,0.5,0.3     2.4246997    0.6222346  0.44
## 6          act    50 0.1,0.5,0.45     2.2247451    0.6688308  0.34
## 7          act   150  0.1,0.5,0.3     4.3196568    0.6233962  0.99
## 8          act   150 0.1,0.5,0.45     3.9515646    0.6332452  0.97
## 9         diff    50  0.1,0.5,0.3     2.7887204    0.4892985  0.73
## 10        diff    50 0.1,0.5,0.45     3.0747886    0.3988745  0.89
## 11        diff   150  0.1,0.5,0.3     4.7892881    0.5025082  1.00
## 12        diff   150 0.1,0.5,0.45     5.6060130    0.2823105  1.00
## # ... with 2 more variables: num_reject &amp;lt;dbl&amp;gt;, num_repl &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Move to Mixed Models&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;It is simple to move from single level to multilevel or mixed models.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time
fixed_param &amp;lt;- c(0, 0.2, 0.1, 0.3, 0.05)
random_param &amp;lt;- list(random_var = c(3, 2), rand_gen = &quot;rnorm&quot;)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;),
                  var_type = c(&quot;lvl1&quot;, &quot;lvl2&quot;),
                  opts = list(list(mean = 0, sd = 3),
                              list(mean = 0, sd = 2)))
n &amp;lt;- 50
p &amp;lt;- 6
data_str &amp;lt;- &quot;long&quot;

temp_long &amp;lt;- sim_glm(fixed = fixed, random = random, fixed_param = fixed_param,
                     random_param = random_param, cov_param = cov_param,
                     n = n, p = p, k = NULL, data_str = data_str)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(temp_long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time        diff        act   time.act        b0        b1
## 1            1    0 -6.76572749 -0.3932853  0.0000000 -1.947485 -2.295427
## 2            1    1  0.15530420 -0.3932853 -0.3932853 -1.947485 -2.295427
## 3            1    2  0.07605058 -0.3932853 -0.7865707 -1.947485 -2.295427
## 4            1    3 -1.11192544 -0.3932853 -1.1798560 -1.947485 -2.295427
## 5            1    4 -4.17141062 -0.3932853 -1.5731413 -1.947485 -2.295427
## 6            1    5  4.77024867 -0.3932853 -1.9664267 -1.947485 -2.295427
##         Fbeta    randEff   logistic         prob sim_data withinID clustID
## 1 -0.79455835  -1.947485  -2.742044 6.053757e-02        0        1       1
## 2  0.07788055  -4.242913  -4.165032 1.529175e-02        0        2       1
## 3  0.25029093  -6.538340  -6.288049 1.854935e-03        0        3       1
## 4  0.31182906  -8.833767  -8.521938 1.990136e-04        0        4       1
## 5  0.18621627 -11.129195 -10.942978 1.768142e-05        0        5       1
## 6  1.26071793 -13.424622 -12.163904 5.215325e-06        0        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Doing Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is also easily extended.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;pow_param &amp;lt;- c(&#39;time&#39;, &#39;diff&#39;, &#39;act&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;z&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 20

power_out &amp;lt;- sim_pow_glm(fixed = fixed, random = random, 
                     fixed_param = fixed_param, 
                     random_param = random_param, cov_param = cov_param, 
                     k = NULL, n = n, p = p,
                     data_str = data_str, unbal = FALSE, pow_param = pow_param, 
                     alpha = alpha, pow_dist = pow_dist, pow_tail = pow_tail,
                     replicates = replicates)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 6
##      var avg_test_stat sd_test_stat power num_reject num_repl
##   &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1    act      12.06197     46.70227  0.20          4       20
## 2   diff      11.89673     45.13827  0.25          5       20
## 3   time      18.78877     79.36869  0.05          1       20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Vary Arguments&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Perhaps our effect size estimate is conservative.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;terms_vary &amp;lt;- list(fixed_param = list(c(0, 0.2, 0.1, 0.3, 0.05), 
                                      c(0, 0.2, 0.3, 0.3, 0.05)))

power_out &amp;lt;- sim_pow_glm(fixed = fixed, random = random, 
                     fixed_param = fixed_param, 
                     random_param = random_param, cov_param = cov_param, 
                     k = NULL, n = n, p = p,
                     data_str = data_str, unbal = FALSE, pow_param = pow_param, 
                     alpha = alpha, pow_dist = pow_dist, pow_tail = pow_tail,
                     replicates = replicates, 
                     terms_vary = terms_vary)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [6 x 7]
## Groups: var [?]
## 
##      var        fixed_param avg_test_stat sd_test_stat power num_reject
##   &amp;lt;fctr&amp;gt;             &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1    act 0,0.2,0.1,0.3,0.05     1.1914255    0.8114762  0.10          2
## 2    act 0,0.2,0.3,0.3,0.05    22.9059014   96.3531136  0.15          3
## 3   diff 0,0.2,0.1,0.3,0.05     1.3071639    0.8681348  0.05          1
## 4   diff 0,0.2,0.3,0.3,0.05    17.4774138   62.2814403  0.95         19
## 5   time 0,0.2,0.1,0.3,0.05     0.9281452    0.7670600  0.05          1
## 6   time 0,0.2,0.3,0.3,0.05    12.1678311   49.9607401  0.05          1
## # ... with 1 more variables: num_repl &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Shiny App&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Note: This app currently looks nice, but is utterly broken!&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(&#39;simglm&#39;, username = &#39;lebebr01&#39;, subdir = &#39;inst/shiny_examples/demo&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
library(simglm)
run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Must have following packages installed: &lt;code&gt;simglm, shiny, shinydashboard, ggplot2, lme4, DT&lt;/code&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; timeline&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Aim to have this package submitted to CRAN by the end of March.&lt;/li&gt;
&lt;li&gt;Fix Shiny application.&lt;/li&gt;
&lt;li&gt;For now look for the package on GitHub &lt;a href=&quot;http://github.com/lebebr01/simglm&quot;&gt;http://github.com/lebebr01/simglm&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2017/02/24/csp2017.html&quot;&gt;http://educate-r.org/2017/02/24/csp2017.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01/simglm&quot;&gt;http://github.com/lebebr01/simglm&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Use CSS to format markdown or HTML files</title>
   <link href="http://lebebr01.github.io/2017/01/03/highlighthtml.html"/>
   <updated>2017-01-03T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2017/01/03/highlighthtml</id>
   <content type="html">&lt;p&gt;Markdown (and Rmarkdown) are great ways to quickly develop material without worrying about the formatting. The documents can then be compiled using the &lt;code&gt;knitr&lt;/code&gt; or &lt;code&gt;rmarkdown&lt;/code&gt; packages to output formats such as HTML, latex, or even word. The main drawback of this approach is that formatting of documents is limited to italics, bold, or strikethrough. Markdown does have support for inline HTML, therefore you can add your own formatting inline using CSS or other HTML attributes, however this moves away from the quick markdown flavor.&lt;/p&gt;

&lt;p&gt;To help solve this problem, many R packages are useful for formatting tables, either through conditional formatting or otherwise. The most interesting to me is the &lt;a href=&quot;https://renkun.me/formattable/&quot;&gt;formattable&lt;/a&gt; package. Other options include the &lt;a href=&quot;http://davidgohel.github.io/ReporteRs/&quot;&gt;ReporteRs&lt;/a&gt; and &lt;a href=&quot;https://cran.r-project.org/web/packages/condformat/index.html&quot;&gt;condformat&lt;/a&gt; packages. These packages however focus on table formatting. An option I started working on a few years ago, &lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;, is a relatively simple package that will help inject CSS automatically into an HTML document to take care of formatting of text and tables.&lt;/p&gt;

&lt;p&gt;Since this package uses CSS for the formatting, knowledge of CSS is required to create the tags to be injected. This has the advantage of allowing users a lot of flexibility with the look they wish to achieve, however, it will be more difficult for users if they do not know CSS. Below is a short demo of functions of interest.&lt;/p&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;The package was published on CRAN a few days ago and can be installed using &lt;code&gt;install.packages&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;install.packages(&#39;highlightHTML&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get the most out of the package, &lt;code&gt;rmarkdown&lt;/code&gt; and &lt;code&gt;knitr&lt;/code&gt; are useful to have installed as well, although not required.&lt;/p&gt;

&lt;h2&gt;Simple Example&lt;/h2&gt;

&lt;p&gt;Suppose you have a table like the following:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number       &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt;  5           &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt;  35          &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt;  100         &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt;  200         &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;You could then add some conditional formatting by adding the following tags to the table.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number       &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt;  5  #bgblue  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt;  35          &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt;  100         &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt;  200 #bgred  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;The addition of the &lt;em&gt;#bgblue&lt;/em&gt; and &lt;em&gt;#bgred&lt;/em&gt; indicates which cells will be changed. After turning the markdown document into an html file, this package can now be used to post-process the html file. The post-processing will add an id value for each cell with the &lt;em&gt;#bgblue&lt;/em&gt; or &lt;em&gt;#bgred&lt;/em&gt; and remove those from the table.&lt;/p&gt;

&lt;p&gt;The function to use for the post-processing is &lt;code&gt;highlight_html&lt;/code&gt; and requires three arguments, the input file, the output file, and the CSS tags themselves. This will look something like the following using an example file from the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(highlightHTML)
file &amp;lt;- system.file(&#39;examples&#39;, &#39;bgtable.html&#39;, 
                    package = &#39;highlightHTML&#39;)
tags &amp;lt;- c(&quot;#bgred {background-color: #FF0000;}&quot;, 
  &quot;#bgblue {background-color: #0000FF;}&quot;)
highlight_html(input = file, 
               output = tempfile(fileext = &quot;.html&quot;), 
               tags = tags,
               update_css = TRUE, 
               browse = TRUE,
               print = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will return an HTML file that automatically injects the CSS tags shown above. The new HTML file will add background color to the HTML file as such:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;figs/highlight_table.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Formatting Text&lt;/h2&gt;

&lt;p&gt;The package also allows for the formatting of text with CSS as well. The following is markdown text that will be formatted:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;markdown&quot;&gt;Can highlight {#bgblack multiple words}.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key is the use of braces following by the CSS id to add to the HTML file. Example usage can be shown with an example file that comes with the package and generated with the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;file &amp;lt;- system.file(&#39;examples&#39;, &#39;bgtext.html&#39;, package = &#39;highlightHTML&#39;)

# Change background color and text color with CSS
tags &amp;lt;- c(&quot;#bgblack {background-color: black; color: white;}&quot;, 
  &quot;#bgblue {background-color: #0000FF; color: white;}&quot;,
  &quot;#colgreen {color: green;}&quot;)

# Post-process HTML file
highlight_html(input = file, output = tempfile(fileext = &quot;.html&quot;),
               tags = tags, update_css = TRUE, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The HTML file would look as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;figs/highlight_text.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Markdown to HTML Directly&lt;/h2&gt;

&lt;p&gt;Finally, with help of the &lt;code&gt;rmarkdown&lt;/code&gt; package, files can be rendered directly from markdown to an HTML file. Below is an example of this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;file &amp;lt;- system.file(&#39;examples&#39;, &#39;mwe.md&#39;, package = &#39;highlightHTML&#39;)
tags &amp;lt;- c(&quot;#bgred {background-color: #FF0000; color: white;}&quot;,
   &quot;#bgblue {background-color: #0000FF; color: white;}&quot;,
   &quot;#bgblack {background-color: #000000; color: white;}&quot;,
   &quot;#colgold {color: #FFD700;}&quot;)
highlight_html(input = file, output = tempfile(fileext = &#39;.html&#39;),
  tags = tags, update_css = TRUE, browse = TRUE, render = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;The package has a few additional features including the ability to inject tags directly into R tables, see  for an example of this. To come are a few basic CSS tags that will be built into the package using specific CSS ids. Bug reports are appreciated and can be logged on GitHub &lt;a href=&quot;https://github.com/lebebr01/highlightHTML/issues&quot;&gt;https://github.com/lebebr01/highlightHTML/issues&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction of the pdfsearch package</title>
   <link href="http://lebebr01.github.io/2016/12/02/intro_pdfsearch.html"/>
   <updated>2016-12-02T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2016/12/02/intro_pdfsearch</id>
   <content type="html">&lt;p&gt;I&#39;m happy to introduce an add-on package, &lt;code&gt;pdfsearch&lt;/code&gt;, that adds the ability to do keyword searches on pdf files. This add-on package uses the excellent &lt;code&gt;pdftools&lt;/code&gt; package from the &lt;a href=&quot;https://ropensci.org/&quot;&gt;ropensci&lt;/a&gt; project to read in pdf files and perform keyword searches based character strings of interest.&lt;/p&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;The package is currently only hosted on &lt;a href=&quot;https://github.com/lebebr01/pdfsearch&quot;&gt;github&lt;/a&gt; and can be installed with the devtools library.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/pdfsearch&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Basic Example&lt;/h2&gt;

&lt;p&gt;Doing a simple keyword search on a single pdf file uses the &lt;code&gt;keyword_search&lt;/code&gt; function. The following is a simple example using a pdf from &lt;a href=&quot;https://arxiv.org/&quot;&gt;arXiv&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(pdfsearch)

file &amp;lt;- system.file(&#39;pdf&#39;, &#39;1501.00450.pdf&#39;, package = &#39;pdfsearch&#39;)

key_res &amp;lt;- keyword_search(file, 
                          keyword = c(&#39;repeated measures&#39;, &#39;mixed effects&#39;),
                          path = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the following example, the function &lt;code&gt;keyword_search&lt;/code&gt; takes two required arguments, the path to the pdf file and the keyword(s) to search for in the pdf. The optional argument shown above, &lt;code&gt;path&lt;/code&gt; tells the function to read in the raw pdf using the &lt;code&gt;pdftools&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;data.frame(key_res)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##              keyword page_num line_num
## 1  repeated measures        1       24
## 2  repeated measures        2       57
## 3  repeated measures        2      108
## 4  repeated measures        2      110
## 5  repeated measures        2      125
## 6  repeated measures        6      444
## 7  repeated measures        6      445
## 8  repeated measures        6      474
## 9  repeated measures        6      485
## 10 repeated measures        9      708
##                                                                                                                                 line_text
## 1  cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical
## 2             fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the
## 3             repeated measures design in different stages of treatment        in this section we assume all users appear in all periods,
## 4               ing the repeated measures analysis, reporting a &amp;lt;U+0093&amp;gt;per week&amp;lt;U+0094&amp;gt;       to metrics that are defined as simple average and assume
## 5               In fact, the crossover design is a type of repeated measures     designs considered can be examined in the same framework
## 6          values and the absence in a specific time window can still          It is common to analyze data from repeated measures design
## 7              provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,
## 8                                      \022             \023                      As an example, one possible model for repeated measures
## 9          a similar example; also see (Van der Vaart 2000) for a text         possible. In repeated measures data, users might appear in
## 10                 framework of repeated measures design. Experimenters should          &amp;lt;U+0095&amp;gt; Wash-out and decide: If we have little informa-
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(key_res$line_text, n = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &quot;cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical&quot;
## 
## [[2]]
## [1] &quot;fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output includes the keyword, the page number it is located, the line number the keyword was found, and the line of text. By default, only the line matching the keyword is returned. If the context of the result is desired, there is an optional argument &lt;code&gt;surround_lines&lt;/code&gt; that can include the lines around the line of the matching keyword.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;key_res &amp;lt;- keyword_search(file, 
                          keyword = c(&#39;repeated measures&#39;, &#39;mixed effects&#39;),
                          path = TRUE, 
                          surround_lines = 2)
head(key_res$line_text, n = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &quot;to be evaluated, and the speed new feature iterations. We             Running under powered experiments have many perils. Not&quot;         
## [2] &quot;introduce more sophisticated experimental designs, specifi-           only would we miss potentially beneficial effects, we may also&quot;  
## [3] &quot;cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical&quot;
## [4] &quot;design and related variants, to increase KPI sensitivity with         power increases with larger effect size, and smaller variances.&quot; 
## [5] &quot;the same traffic size and duration of experiment. In this pa-         Let us look at these aspects in turn.&quot;                           
## 
## [[2]]
## [1] &quot;benefits (see Kohavi et al. 2012, Section 3.4). This poses&quot;                                                                     
## [2] &quot;a limitation to any online experimentation platform, where       within-subject variation. We also discuss practical consid-&quot;   
## [3] &quot;fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the&quot;    
## [4] &quot;rewards.                                                         crossover design to study the carry over effect, including the&quot;
## [5] &quot;&amp;lt;U+0093&amp;gt;re-randomized&amp;lt;U+0094&amp;gt; design (row 5 in table 1).&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Directory Search&lt;/h2&gt;

&lt;p&gt;This package also has the ability to loop over a directory of pdf files in a single run. To do this, the &lt;code&gt;keyword_directory&lt;/code&gt; function is of interest. Much of the arguments are the same, except a directory is specified instead of a single path to the location of the pdf files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# find directory
directory &amp;lt;- system.file(&#39;pdf&#39;, package = &#39;pdfsearch&#39;)

# do search over two files
head(keyword_directory(directory, 
       keyword = c(&#39;repeated measures&#39;, &#39;measurement error&#39;),
       surround_lines = 1, full_names = TRUE), n = 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    ID       pdf_name           keyword page_num line_num
## 1   1 1501.00450.pdf repeated measures        1       24
## 2   1 1501.00450.pdf repeated measures        2       57
## 3   1 1501.00450.pdf repeated measures        2      108
## 4   1 1501.00450.pdf repeated measures        2      110
## 5   1 1501.00450.pdf repeated measures        2      125
## 6   1 1501.00450.pdf repeated measures        6      444
## 7   1 1501.00450.pdf repeated measures        6      445
## 8   1 1501.00450.pdf repeated measures        6      474
## 9   1 1501.00450.pdf repeated measures        6      485
## 10  1 1501.00450.pdf repeated measures        9      708
## 11  2 1610.00147.pdf measurement error        1        5
## 12  2 1610.00147.pdf measurement error        1       19
##                                                                                                                                                                                                                                                                                                                                                                                                              line_text
## 1  introduce more sophisticated experimental designs, specifi-           only would we miss potentially beneficial effects, we may also, cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical, design and related variants, to increase KPI sensitivity with         power increases with larger effect size, and smaller variances.
## 2                           a limitation to any online experimentation platform, where       within-subject variation. We also discuss practical consid-, fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the, rewards.                                                         crossover design to study the carry over effect, including the
## 3                                 In this paper we extend the idea further by employing the        weeks. To facilitate our illustration, in all the derivation, repeated measures design in different stages of treatment        in this section we assume all users appear in all periods,, assignment. The traditional A/B test can be analyzed us-         i.e. no missing measurement. We also restrict ourselves
## 4                                       assignment. The traditional A/B test can be analyzed us-         i.e. no missing measurement. We also restrict ourselves, ing the repeated measures analysis, reporting a &amp;lt;U+0093&amp;gt;per week&amp;lt;U+0094&amp;gt;       to metrics that are defined as simple average and assume, treatment effect, as show in row 3 &amp;lt;U+0093&amp;gt;parallel&amp;lt;U+0094&amp;gt; design in ta-      treatment and control have the same sample size. We fur-
## 5                                                                     each user serves as his/her own control in the measurement.      fixed effects in the model in this section. This way, various, In fact, the crossover design is a type of repeated measures     designs considered can be examined in the same framework, design commonly used in biomedical research to control for       and easily compared.
## 6                                                       to realize infrequent users are more likely to have missing         5.1 Review of Existing Methods, values and the absence in a specific time window can still          It is common to analyze data from repeated measures design, provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,
## 7                        values and the absence in a specific time window can still          It is common to analyze data from repeated measures design, provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,, might be other factors causing user to be missing that are          under certain assumptions, such as normality, sphericity (ho-
## 8                                                                                                                                                                                                                    0 0, \022             \023                      As an example, one possible model for repeated measures, Xi Xi0                             using lme4&amp;lt;U+0092&amp;gt;s formula syntax (Bates et al. 2012a;b) is
## 9                      the delta-method; see Deng et al. (2013, Appendix B) for            Random effect makes modeling within-subject variability, a similar example; also see (Van der Vaart 2000) for a text         possible. In repeated measures data, users might appear in, book treatment of the delta-method.                                 multiple periods, represented as multiple rows in the dataset.
## 10                                         At the design stage, we face a few choices under the same               measure it directly and should be used here., framework of repeated measures design. Experimenters should          &amp;lt;U+0095&amp;gt; Wash-out and decide: If we have little informa-, use domain knowledge and past experiments to inform the                 tion to judge carry over effect, we can run the first
## 11                                                                                                                                                                                                                                         Abstract, Often in surveys, key items are subject to measurement errors. Given just the, data, it can be difficult to determine the distribution of this error process, and
## 12                                                                                                                                                                                               National Survey of College Graduates. We also present a process for assessing, the sensitivity of various analyses to different choices for the measurement error, models. Supplemental material is available online.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two relavent arguments for the &lt;code&gt;keyword_directory&lt;/code&gt; function are &lt;code&gt;full_names&lt;/code&gt; and &lt;code&gt;recursive&lt;/code&gt;. These functions ask whether the full path for the pdf files in the directory will be used and whether subfolders within the directory will also be searched.&lt;/p&gt;

&lt;h2&gt;Uses for pdfsearch&lt;/h2&gt;

&lt;p&gt;This package may be extremely useful when conducting research syntheses or meta analyses, particularly when screening articles for inclusion into the research synthesis or meta analysis. This aim is hopeful to be explored later in more depth.&lt;/p&gt;

&lt;h3&gt;Limitations&lt;/h3&gt;

&lt;p&gt;The limitations of the package and the quality of text matches will depend on the pdfs being searched. For example, words that wrap across lines (i.e. hyphenated words) will not be included in the matches as entire words are currently being searched to be matched.&lt;/p&gt;

&lt;h2&gt;Moving Forward&lt;/h2&gt;

&lt;p&gt;The package will be submitted to CRAN next week, however, any bugs or problems can be submitted to the github site &lt;a href=&quot;https://github.com/lebebr01/pdfsearch/issues&quot;&gt;https://github.com/lebebr01/pdfsearch/issues&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Extending accessibility of open-source statistical software to the masses A shiny case study</title>
   <link href="http://lebebr01.github.io/2016/10/07/canam.html"/>
   <updated>2016-10-07T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/10/07/canam</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Extending accessibility of open-source statistical software to the masses: A shiny case study&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is an open source statistical programming language.

&lt;ul&gt;
&lt;li&gt;Pros:

&lt;ul&gt;
&lt;li&gt;Common statistical procedures are found in R&lt;/li&gt;
&lt;li&gt;Can extend functionality with packages/functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons:

&lt;ul&gt;
&lt;li&gt;Need to be comfortable with code
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Flexibility of R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is powerful and flexible due to the many user written packages.&lt;/li&gt;
&lt;li&gt;However, to capture this flexibility:

&lt;ul&gt;
&lt;li&gt;users need to be comfortable with programming&lt;/li&gt;
&lt;li&gt;users need to find the package&lt;/li&gt;
&lt;li&gt;users need to understand package specific syntax
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R package documentation and examples&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise&quot;&gt;https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Blog posts&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.rstudio.org/2014/01/17/introducing-dplyr/&quot;&gt;https://blog.rstudio.org/2014/01/17/introducing-dplyr/&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Vignettes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html&quot;&gt;https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of these types of documentations&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;They still rely on user understanding and reading R code.&lt;/li&gt;
&lt;li&gt;Not interactive, although the user can copy and paste code into an R session.&lt;/li&gt;
&lt;li&gt;This type of documentation will not capture the nontraditional useR.&lt;/li&gt;
&lt;li&gt;Shiny is the path to the nontraditional useR.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;What is Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Shiny is an open-source framework for creating applications viewed in a web browser with R.&lt;/li&gt;
&lt;li&gt;Shiny Examples:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/movie-explorer.html&quot;&gt;http://shiny.rstudio.com/gallery/movie-explorer.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gallery.shinyapps.io/drinkr/&quot;&gt;https://gallery.shinyapps.io/drinkr/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wordbank.stanford.edu/analyses?name=item_trajectories&quot;&gt;http://wordbank.stanford.edu/analyses?name=item_trajectories&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Advantages of Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;User needs no R knowledge&lt;/li&gt;
&lt;li&gt;App is viewed in the browser so able to use

&lt;ul&gt;
&lt;li&gt;Javascript&lt;/li&gt;
&lt;li&gt;HTML&lt;/li&gt;
&lt;li&gt;CSS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiple hosting options&lt;/li&gt;
&lt;li&gt;Flexible Output
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Disadvantages of Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Need a R developer to create the app.

&lt;ul&gt;
&lt;li&gt;More difficult as the code is somewhat different compared to traditional R code.&lt;/li&gt;
&lt;li&gt;Shiny uses reactive programming.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Components of Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;User Interface (ui.r)

&lt;ul&gt;
&lt;li&gt;What the user sees and interacts with&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;R Analysis (server.r)

&lt;ul&gt;
&lt;li&gt;The R code running behind the scenes
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;User Interface&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Simple user interface example from RStudio

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyUI(
  fluidPage(    
    titlePanel(&quot;Telephones by region&quot;),
    sidebarLayout(      
      sidebarPanel(
        selectInput(&quot;region&quot;, &quot;Region:&quot;, 
                    choices = colnames(WorldPhones)),
        hr(),
        helpText(&quot;Data from AT&amp;amp;T (1961) The World&#39;s Telephones.&quot;)
      ),

      mainPanel(
        plotOutput(&quot;phonePlot&quot;)  
      )
    )
  )
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Server File&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The server file for RStudio example

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyServer(function(input, output) {

  output$phonePlot &amp;lt;- renderPlot({

    barplot(WorldPhones[ , input$region] * 1000, 
            main = input$region,
            ylab = &quot;Number of Telephones&quot;,
            xlab = &quot;Year&quot;)
  })
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Case Study&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;pdfsearch

&lt;ul&gt;
&lt;li&gt;Note, you may need &lt;em&gt;rtools&lt;/em&gt; to install this package.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This following commands will run the pdfsearch shiny application locally.

&lt;ul&gt;
&lt;li&gt;Note, the following packages are required: shiny, shinydashboard, pdfsearch, DT
&lt;a href=&quot;https://github.com/lebebr01/pdfsearch&quot;&gt;https://github.com/lebebr01/pdfsearch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;install.packages(&#39;devtools&#39;)
devtools::install_github(&#39;lebebr01/pdfsearch&#39;)
pdfsearch::run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Case Study 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;simglm

&lt;ul&gt;
&lt;li&gt;Note, need the following packages: shiny, shinydashboard, DT, simglm, ggplot2, lme4, highcharter
&lt;a href=&quot;https://github.com/lebebr01/simglm&quot;&gt;https://github.com/lebebr01/simglm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
simglm::run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Shiny can give useRs an interactive framework to try out an R package.&lt;/li&gt;
&lt;li&gt;Benefits include

&lt;ul&gt;
&lt;li&gt;interactivity&lt;/li&gt;
&lt;li&gt;no errors (for well developed Shiny applications)&lt;/li&gt;
&lt;li&gt;no need to learn R or package specific syntax&lt;/li&gt;
&lt;li&gt;only need a browser, no need to have R install locally when hosted on a server.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/10/07/canam.html&quot;&gt;http://educate-r.org/2016/10/07/canam.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01&quot;&gt;http://github.com/lebebr01&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Estimating NCAA Football Coaches’ Abilities An Application of Item Response Theory</title>
   <link href="http://lebebr01.github.io/2016/07/31/jsm2016.html"/>
   <updated>2016-07-31T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/07/31/jsm2016</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Estimating NCAA Football Coaches’ Abilities An Application of Item Response Theory&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Andrew Zieffler, and Kyle Nickodem&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa &amp;amp; University of Minnesota&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Began after Tim Brewster was fired at the University of Minnesota.

&lt;ul&gt;
&lt;li&gt;Now they have a new coach again!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wanted to try to predict next great coach.&lt;/li&gt;
&lt;li&gt;Proceeded to explore data available to answer this question.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data came from a few sources:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;http://www.cfbdatawarehouse.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wikipedia
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Goals&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Predict the &#39;ability&#39; of the coaches.&lt;/li&gt;
&lt;li&gt;Find other variables that explain variation in the &#39;ability&#39; of the coaches.&lt;/li&gt;
&lt;li&gt;Predict the next &#39;great&#39; coach.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/cfbmodel.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Model 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Not a traditional IRT model as the game ID is not included.

&lt;ul&gt;
&lt;li&gt;The model does allow for a coaches ability to vary with years.&lt;/li&gt;
&lt;li&gt;The team effect is constant.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This model was fitted using R: &lt;code&gt;lme4&lt;/code&gt; and &lt;code&gt;rstan&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Results shown throughout are from &lt;code&gt;lme4&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&#39;Modern&#39; era data, 1998 onward and coaches with at least 6 games per year.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Team Effect&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/teameffect.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Ability Estimates&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ISU.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa State made good hire?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ISU_good_hire.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Fire Tim Brewster?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/UMN.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Does a coach overperform compared to average team ability?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Value-added like logic.&lt;/li&gt;
&lt;li&gt;If coaches over/under perform compared to a team average

&lt;ul&gt;
&lt;li&gt;are they more likely to be retained?&lt;/li&gt;
&lt;li&gt;if fired, are they a good fit for another team?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How quickly does team expectation change?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;6 Coaches on the Hot Seat&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Hot_seat_coach_plot.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Which of these 6 should be fired?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Hot_seat_relative_plot.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Back to Minnesota&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Minnesota-Coaches-2.png&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
    &lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Next Steps&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Add covariates to model shown above

&lt;ul&gt;
&lt;li&gt;or use the ability estimates obtained above as an outcome.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Explore moving average for team expectation.&lt;/li&gt;
&lt;li&gt;Explore good vs bad coaching hires.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Connect&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;e-mail: brandon-lebeau (at) uiowa.edu&lt;/li&gt;
&lt;li&gt;Twitter: @blebeau11; &lt;a href=&quot;https://twitter.com/blebeau11&quot;&gt;https://twitter.com/blebeau11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://educate-r.org/2016/07/31/jsm2016.html&quot;&gt;http://educate-r.org/2016/07/31/jsm2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Simulation and power analysis of generalized linear mixed models</title>
   <link href="http://lebebr01.github.io/2016/06/29/user2016.html"/>
   <updated>2016-06-29T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/06/29/user2016</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Simulation and power analysis of generalized linear mixed models&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;(G)LMMs&lt;/li&gt;
&lt;li&gt;Power&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Demo Shiny App!
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linear Mixed Model (LMM)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/equations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is the ability to statistically detect a true effect (i.e. non-zero population effect).&lt;/li&gt;
&lt;li&gt;For simple models (e.g. t-tests, regression) there are closed form equations for generating power.

&lt;ul&gt;
&lt;li&gt;R has routines for these: &lt;code&gt;power.t.test, power.anova.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gpower3
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Example&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;n &amp;lt;- seq(4, 1000, 2)
power &amp;lt;- sapply(seq_along(n), function(i) 
  power.t.test(n = n[i], delta = .15, sd = 1, type = &#39;two.sample&#39;)$power)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/power_plot-1.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power for (G)LMM&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power for more complex models is not as straightforward;

&lt;ul&gt;
&lt;li&gt;particularly with messy real world data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There is software for the GLMM models to generate power:

&lt;ul&gt;
&lt;li&gt;Optimal Design: &lt;a href=&quot;http://hlmsoft.net/od/&quot;&gt;http://hlmsoft.net/od/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLPowSim: &lt;a href=&quot;http://www.bristol.ac.uk/cmm/software/mlpowsim/&quot;&gt;http://www.bristol.ac.uk/cmm/software/mlpowsim/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Snijders, &lt;em&gt;Power and Sample Size in Multilevel Linear Models&lt;/em&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is hard&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In practice, power is hard.&lt;/li&gt;
&lt;li&gt;Need to make many assumptions on data that has not been collected.

&lt;ul&gt;
&lt;li&gt;Therefore, data assumptions made for power computations will likely differ from collected sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A power analysis needs to be flexible, exploratory, and well thought out.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; Overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; aims to simulate (G)LMMs with up to three levels of nesting (aim to add more later).&lt;/li&gt;
&lt;li&gt;Flexible data generation allows:

&lt;ul&gt;
&lt;li&gt;any number of covariates and discrete covariates&lt;/li&gt;
&lt;li&gt;change random distribution&lt;/li&gt;
&lt;li&gt;unbalanced data&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;li&gt;serial correlation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Also has routines to generate power.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Demo Shiny App&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(&#39;simglm&#39;, username = &#39;lebebr01&#39;, subdir = &#39;inst/shiny_examples/demo&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
library(simglm)
run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Must have following packages installed: &lt;code&gt;simglm, shiny, shinydashboard, ggplot2, lme4, DT&lt;/code&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/06/29/user2016.html&quot;&gt;http://educate-r.org/2016/06/29/user2016.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01&quot;&gt;http://github.com/lebebr01&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Assessing the validity of item response theory models when calibrating field test items</title>
   <link href="http://lebebr01.github.io/2016/04/09/ncme2016.html"/>
   <updated>2016-04-09T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/04/09/ncme2016</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Assessing the validity of item response theory models when calibrating field test items&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Validity for IRT Models&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Validity is important for any assessment and the argument should begin with psychometrics.&lt;/li&gt;
&lt;li&gt;How the psychometrics is performed directly impacts properties of the assessment that are assessed later for evidence of validity.

&lt;ul&gt;
&lt;li&gt;Are scores reported below chance level?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The validity of the psychometrics is particularly important for field test data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT Model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/irt.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Field Testing&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Field testing (FT) is essential to new assessment development or form building.

&lt;ul&gt;
&lt;li&gt;A way to gather information to make informed decisions about which items become operational.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Limitations:

&lt;ul&gt;
&lt;li&gt;Many items are tried that do not become operational.

&lt;ul&gt;
&lt;li&gt;This spreads a fixed pool of individuals (respondents) across many field test items.&lt;/li&gt;
&lt;li&gt;Ultimately, sample size can be significantly smaller compared to operational assessments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Issues with distractors.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Threats to Validity in FT&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Generalizeability

&lt;ul&gt;
&lt;li&gt;Is the FT sample representative of the desired population?&lt;/li&gt;
&lt;li&gt;Over-fitting with 3PL model?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Uncertainty in estimates

&lt;ul&gt;
&lt;li&gt;Sample size and lower asymptote estimation&lt;/li&gt;
&lt;li&gt;Interconnected parameter estimates
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Generalizeability&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;We assume respondents are randomly sampled from some population.

&lt;ul&gt;
&lt;li&gt;Are item responses truly randomly sampled from the population of interest?

&lt;ul&gt;
&lt;li&gt;Selection or Measurement bias&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If not, estimates are extremely sample dependent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3PL model may provide better fit, but is this at the cost of overfitting?

&lt;ul&gt;
&lt;li&gt;Fit should not be the only consideration when deciding on an IRT model for FT data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Sample size (1000 commonly cited for 3PL model):

&lt;ul&gt;
&lt;li&gt;Tends to be smaller in field test designs.&lt;/li&gt;
&lt;li&gt;Even with small samples, can achieve convergence with 3PL model with help of priors, ridge, etc.

&lt;ul&gt;
&lt;li&gt;Are our estimates now biased?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Estimating Lower Asymptote (pseudo-guessing):

&lt;ul&gt;
&lt;li&gt;Difficulty in estimating this term ($c_{j}$) has direct impact on estimation of the other two terms.

&lt;ul&gt;
&lt;li&gt;This leads to a cascading vortex of problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The pseudo-guessing is commonly a nuisance parameter, why allow a nuisance parameter to drastically affect estimation of other terms?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Methodology&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Individual response strings were resampled in a two stage framework:

&lt;ul&gt;
&lt;li&gt;First, individuals who took the field test were resampled with replacement within each field test booklet.&lt;/li&gt;
&lt;li&gt;Second, individuals who only took operational items were resampled with replacement to fill out the remaining observations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After resampling, items were calibrated with Bilog-MG.&lt;/li&gt;
&lt;li&gt;This process was replicated 5000 times to generate bootstrapped item parameters.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math57.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math572pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread653pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread652pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;ICC Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;For individual items, the variation in the ICCs for a 3PL model can be large.

&lt;ul&gt;
&lt;li&gt;This may lower usefulness of estimates in helping to select operational (best) items.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How can these 3PL curves be expected to generalize beyond this sample with so much variability?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;b and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_bc_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ac_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and b est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ab_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The pseudo-guessing estimates are:

&lt;ul&gt;
&lt;li&gt;negatively related to the estimates of the b and a.&lt;/li&gt;
&lt;li&gt;positively related to the uncertainty in the b parameter, likely the parameter of most interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In turn, increasing the uncertainty in the b parameter:

&lt;ul&gt;
&lt;li&gt;further increases the uncertainty in the a parameter.&lt;/li&gt;
&lt;li&gt;is also negatively related to estimates of the a parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thus, creating the cascading vortex of problems.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Item parameters estimated from FT data should not be treated as truth.

&lt;ul&gt;
&lt;li&gt;Variation in these parameter estimates needs to be considered.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fit should not be the only concern when selecting an IRT model, uncertainty, generalizeability, and usefulness should also be considered.&lt;/li&gt;
&lt;li&gt;Estimates are much more stable when using the 2PL model.

&lt;ul&gt;
&lt;li&gt;Thus providing a stronger foundation with which to start the validity argument for an assessment.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/09/ncme2016.html&quot;&gt;http://educate-r.org/2016/04/09/ncme2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Informative vs uninformative prior distributions with characteristic curve linking methods</title>
   <link href="http://lebebr01.github.io/2016/04/08/aera2016.html"/>
   <updated>2016-04-08T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/04/08/aera2016</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Informative vs uninformative prior distributions with characteristic curve linking methods&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Keyu Chen, Wei Cheng Liu, and Aaron McVay&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;With item response theory (IRT), the ability scale is arbitrarily defined (commonly mean of 0 and sd of 1).&lt;/li&gt;
&lt;li&gt;Linking is useful to help place individual ability and IRT item parameters on the same scale.

&lt;ul&gt;
&lt;li&gt;Particularly when two forms are administered to non-equivalent groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Four linking methods are common:

&lt;ul&gt;
&lt;li&gt;Mean/Mean&lt;/li&gt;
&lt;li&gt;Mean/Sigma&lt;/li&gt;
&lt;li&gt;Haebara&lt;/li&gt;
&lt;li&gt;Stocking Lord
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Transformation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/link.PNG&quot; alt=&quot;&quot; height = &quot;400&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Designs&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Random Groups&lt;/li&gt;
&lt;li&gt;Single group with counterbalancing&lt;/li&gt;
&lt;li&gt;Common-item nonequivalent group design&lt;/li&gt;
&lt;li&gt;More details in Kolen &amp;amp; Brennan (2014).
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Common-item NEG Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/commonitem.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Prior Weights&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The proficiency points and weights can be specified to reflect the ability distribution of the original scale.&lt;/li&gt;
&lt;li&gt;In addition, proficiency points and weights can be specified to reflect the ability distribution of the new scale.&lt;/li&gt;
&lt;li&gt;More details are provided in Kim &amp;amp; Lee (2006).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;strong&gt;Research Questions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;To what extent does the prior distribution have an impact on the estimation of the transformation constants?&lt;/li&gt;
&lt;li&gt;To what extent does the relationship from #1 generalize across the simulation conditions?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/simulation_conditions.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The A and B transformation constants were also simulated as a part of the design.

&lt;ul&gt;
&lt;li&gt;This was done in an attempt to increase generalizeability of study results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both were simulated from a random uniform distribution.

&lt;ul&gt;
&lt;li&gt;A ranged from 0.5 to 1.5 rounded to nearest .05 (21 possibilities)&lt;/li&gt;
&lt;li&gt;B ranged from -2 to 2 rounded to nearest 0.10 (41 possibilities)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1000 replications
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Procedures&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A population of 55 items were simulated as Form X from a normal ability distribution.&lt;/li&gt;
&lt;li&gt;Form Y consisted of common items from Form X (transformed based on A and B parameters).

&lt;ul&gt;
&lt;li&gt;Additional items were simulated to fill out Form Y.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Form Y was calibrated with Bilog-MG using a 3PL IRT model.&lt;/li&gt;
&lt;li&gt;Transformation constants were computed from calibrated Form Y item parameters and population Form X item parameters.

&lt;ul&gt;
&lt;li&gt;An R package, plink, was used.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Study Outcomes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Bias in the transformation constants (A and B) were explored descriptively and inferentially:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bias.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation recovery&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/heatmap_b.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results&lt;/h1&gt;

&lt;table style=&quot;font-size: 26pt;&quot;&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;Variable&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta A&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta B&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.699&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.149&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.045&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.008&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.387&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results A Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/a_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results B Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/b_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Prior distribution used for linking the two forms does not have a large impact on the estimation of the A and B constants.&lt;/li&gt;
&lt;li&gt;Even correctly specifying the shape of the ability distribution through the weights does not help with non-normal ability distributions.&lt;/li&gt;
&lt;li&gt;The ability distribution shape has the most impact on accurate estimation of the A and B constants.

&lt;ul&gt;
&lt;li&gt;Normalizing transformations of the ability distribution may be helpful to limit bias when estimating these linking constants.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/08/aera2016.html&quot;&gt;http://educate-r.org/2016/04/08/aera2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>AERA Poster 2016 Monte Carlo</title>
   <link href="http://lebebr01.github.io/2016/04/06/aeraposter.html"/>
   <updated>2016-04-06T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2016/04/06/aeraposter</id>
   <content type="html">&lt;p&gt;I have a poster session at AERA &lt;a href=&quot;http://www.aera.net/&quot;&gt;http://www.aera.net/&lt;/a&gt; on Monday, April 11. This paper explores design characteristics of Monte Carlo studies to include key simulation conditions as a part of the simulation design. The main advantage, it is argued, of this approach is a gain in generalizeability while still maintaining strong internal validity.&lt;/p&gt;

&lt;p&gt;A pdf of the final poster can be found here: &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=sanBSLasqc90VykOI%2fZhinG5hX%2b8HrkK7wnsL1a6hxw%3d&amp;amp;docid=08c154563ec1243359598b5a5ee3fee90&quot;&gt;Link to Poster&lt;/a&gt; and &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=70eHPGH0%2fiYPNo%2bA9aGxsDiE6pZ30PirRS5Gk7DgHeM%3d&amp;amp;docid=011ba7819f0c741d8ab0ee91ee6bf7449&quot;&gt;Initial Proposal&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Interactively building test forms from an IRT perspective An application of R and Shiny</title>
   <link href="http://lebebr01.github.io/2016/02/18/cspshiny.html"/>
   <updated>2016-02-18T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2016/02/18/cspshiny</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Interactively building test forms from an IRT perspective: An application of R and Shiny&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/flowchart.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is an open source statistical programming language.

&lt;ul&gt;
&lt;li&gt;Pros:

&lt;ul&gt;
&lt;li&gt;Common statistical procedures are found in R&lt;/li&gt;
&lt;li&gt;Can extend functionality with packages/functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons:

&lt;ul&gt;
&lt;li&gt;Need to be comfortable with code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Rlogo.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Reproducible Research&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Reproducible research has become popular.

&lt;ul&gt;
&lt;li&gt;Commonly a document that contains both analysis and text.&lt;/li&gt;
&lt;li&gt;This can be done with &lt;code&gt;Rmarkdown&lt;/code&gt; and &lt;code&gt;knitr.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/rmarkdown.PNG&quot; alt=&quot;&quot;/&gt;
&lt;img src=&quot;http://educate-r.org/figs/knitr.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative/Interactive Data Analysis&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;This type of analysis requires some input from the user.

&lt;ul&gt;
&lt;li&gt;Data analysts may use &lt;code&gt;R&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Shiny&lt;/code&gt; is a great option for code novices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/shiny.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative Task Examples&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Building Assessments&lt;/li&gt;
&lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
&lt;li&gt;Exploring Missing Data Patterns&lt;/li&gt;
&lt;li&gt;Model Selection/Building
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative Analysis Structure&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/useless_meeting.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;What is Shiny?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Shiny&lt;/code&gt; is an interactive web application framework for R.

&lt;ul&gt;
&lt;li&gt;Example: &lt;a href=&quot;http://shiny.rstudio.com/gallery/movie-explorer.html&quot;&gt;http://shiny.rstudio.com/gallery/movie-explorer.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/shiny_example.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Components of Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;User Interface (ui.r)

&lt;ul&gt;
&lt;li&gt;What the user sees and interacts with&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;R Analysis (server.r)

&lt;ul&gt;
&lt;li&gt;The R code running behind the scenes
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;User Interface&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Simple user interface example from RStudio

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyUI(

  fluidPage(    

    titlePanel(&quot;Telephones by region&quot;),

    sidebarLayout(      

      sidebarPanel(
        selectInput(&quot;region&quot;, &quot;Region:&quot;, 
                    choices = colnames(WorldPhones)),
        hr(),
        helpText(&quot;Data from AT&amp;amp;T (1961) The World&#39;s Telephones.&quot;)
      ),

      mainPanel(
        plotOutput(&quot;phonePlot&quot;)  
      )

    )
  )
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Server File&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The server file for RStudio example

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyServer(function(input, output) {

  output$phonePlot &amp;lt;- renderPlot({

    barplot(WorldPhones[ , input$region] * 1000, 
            main = input$region,
            ylab = &quot;Number of Telephones&quot;,
            xlab = &quot;Year&quot;)
  })
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Interactivity is Key&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/interactivity.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Tools for Interactivity&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Interactive Graphics

&lt;ul&gt;
&lt;li&gt;Using JavaScript - D3 graphics (&lt;code&gt;rCharts&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Interactive static graphics - Garrett&#39;s presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Interactive Tables

&lt;ul&gt;
&lt;li&gt;Using DT R package
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Reporting from Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Using &lt;code&gt;Rmarkdown&lt;/code&gt; and &lt;code&gt;knitr&lt;/code&gt; to create customizable reproducible reports

&lt;ul&gt;
&lt;li&gt;Example: generate report button&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generate final data files

&lt;ul&gt;
&lt;li&gt;Example: download data button
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Strengths of Using Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;The app can be written solely using R code

&lt;ul&gt;
&lt;li&gt;Can use CSS, JavaScript, or HTML as needed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User does not need to know any R&lt;/li&gt;
&lt;li&gt;Many hosting options&lt;/li&gt;
&lt;li&gt;Application can be as simple or complex as needed (both visually and functionally)&lt;/li&gt;
&lt;li&gt;Flexible output
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of Using Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;May take more time to develop initially&lt;/li&gt;
&lt;li&gt;Need some R familiarity for development
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background for Demo&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In educational assessment, we need to create new test forms

&lt;ul&gt;
&lt;li&gt;Exposure concerns&lt;/li&gt;
&lt;li&gt;Add new content&lt;/li&gt;
&lt;li&gt;Altering test landscape&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building test forms is an iterative process that involves gathering information from:

&lt;ul&gt;
&lt;li&gt;Item analyses&lt;/li&gt;
&lt;li&gt;Test blueprints&lt;/li&gt;
&lt;li&gt;Item response theory (IRT)
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8
## [1,]      1      1      1      1      1      1      1      1
## [2,]      0      1      0      0      1      0      1      0
## [3,]      1      1      1      0      1      0      1      0
## [4,]      0      1      0      1      1      0      1      0
## [5,]      0      1      1      1      1      0      1      1
## [6,]      1      1      0      0      1      0      1      0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Logistic Curve&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/logistic-1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Demo&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/lebebr01/BuildForm&quot;&gt;https://github.com/lebebr01/BuildForm&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Basic Theme
shiny::runGitHub(&#39;lebebr01/BuildForm&#39;, subdir = &#39;R&#39;, ref = &#39;basic&#39;)

# shinydashboard
shiny::runGitHub(&#39;lebebr01/BuildForm&#39;, subdir = &#39;R&#39;, ref = &#39;testmodule&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Benefits of Shiny for Iterative Data Analysis&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Free valuable data analyst/scientist resources.&lt;/li&gt;
&lt;li&gt;Improve data literacy in the organization.&lt;/li&gt;
&lt;li&gt;Highly customizable

&lt;ul&gt;
&lt;li&gt;Analysis (server.r)&lt;/li&gt;
&lt;li&gt;User interface (ui.r)&lt;/li&gt;
&lt;li&gt;Reporting
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of Shiny for Iterative Data Analysis&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Need to train users

&lt;ul&gt;
&lt;li&gt;Analysis&lt;/li&gt;
&lt;li&gt;Navigating web application&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge of JavaScript, CSS, or HTML useful.
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Guidelines for Building Shiny Apps&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Understand reactive coding.&lt;/li&gt;
&lt;li&gt;Modularize your code - define functions for repetitive code chunks.&lt;/li&gt;
&lt;li&gt;Define scope early.

&lt;ul&gt;
&lt;li&gt;Define output.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clean up UI last.
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Summary&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/flowchart.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Shiny Resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/&quot;&gt;http://shiny.rstudio.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/articles/&quot;&gt;http://shiny.rstudio.com/articles/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/&quot;&gt;http://shiny.rstudio.com/gallery/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.rstudio.com/products/shiny/shiny-user-showcase/&quot;&gt;https://www.rstudio.com/products/shiny/shiny-user-showcase/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/02/18/cspshiny/&quot;&gt;http://educate-r.org/2016/02/18/cspshiny/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Web Scraping to Item Response Theory - A College Football Adventure</title>
   <link href="http://lebebr01.github.io/2015/12/04/centraliowaruser.html"/>
   <updated>2015-12-04T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2015/12/04/centraliowaruser</id>
   <content type="html">&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Web Scraping to Item Response Theory: A College Football Adventure&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Andrew Zieffler, and Kyle Nickodem&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa &amp;amp; University of Minnesota&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Began after Tim Brewster was fired&lt;/li&gt;
&lt;li&gt;Wanted to try to predict next great coach
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data Available&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is available at three levels

&lt;ol&gt;
&lt;li&gt;Coach&lt;/li&gt;
&lt;li&gt;Game by Game&lt;/li&gt;
&lt;li&gt;Team
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Coach&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall record&lt;/li&gt;
&lt;li&gt;Team history&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;Coordinator history
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example Coach Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##   Year Team Win Loss Tie     Pct  PF  PA Delta        coach
## 1 2010 Iowa   8    5   0 0.61538 376 221   155 Kirk Ferentz
## 2 2011 Iowa   7    6   0 0.53846 358 310    48 Kirk Ferentz
## 3 2012 Iowa   4    8   0 0.33333 232 275   -43 Kirk Ferentz
## 4 2013 Iowa   8    5   0 0.61538 342 246    96 Kirk Ferentz
## 5 2014 Iowa   7    6   0 0.53846 367 333    34 Kirk Ferentz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Game by Game&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Final score of each game&lt;/li&gt;
&lt;li&gt;Date played&lt;/li&gt;
&lt;li&gt;Location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;No information within a game
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example GBG Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##    Team           Official Year       Date WL          Opponent PF PA
## 1  Iowa University of Iowa 2014  8/30/2014  W     Northern Iowa 31 23
## 2  Iowa University of Iowa 2014   9/6/2014  W     Ball St. (IN) 17 13
## 3  Iowa University of Iowa 2014  9/13/2014  L          Iowa St. 17 20
## 4  Iowa University of Iowa 2014  9/20/2014  W   Pittsburgh (PA) 24 20
## 5  Iowa University of Iowa 2014  9/27/2014  W       Purdue (IN) 24 10
## 6  Iowa University of Iowa 2014 10/11/2014  W           Indiana 45 29
## 7  Iowa University of Iowa 2014 10/18/2014  L          Maryland 31 38
## 8  Iowa University of Iowa 2014  11/1/2014  W Northwestern (IL) 48  7
## 9  Iowa University of Iowa 2014  11/8/2014  L         Minnesota 14 51
## 10 Iowa University of Iowa 2014 11/15/2014  W          Illinois 30 14
## 11 Iowa University of Iowa 2014 11/22/2014  L         Wisconsin 24 26
## 12 Iowa University of Iowa 2014 11/28/2014  L          Nebraska 34 37
## 13 Iowa University of Iowa 2014   1/2/2015  L         Tennessee 28 45
##              Location
## 1       Iowa City, IA
## 2       Iowa City, IA
## 3       Iowa City, IA
## 4      Pittsburgh, PA
## 5  West Lafayette, IN
## 6       Iowa City, IA
## 7    College Park, MD
## 8       Iowa City, IA
## 9     Minneapolis, MN
## 10      Champaign, IL
## 11      Iowa City, IA
## 12      Iowa City, IA
## 13   Jacksonville, FL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Team&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall team record&lt;/li&gt;
&lt;li&gt;Team statistics&lt;/li&gt;
&lt;li&gt;Rankings&lt;/li&gt;
&lt;li&gt;Conference Affiliation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data is very similar to that of the coach level
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data were obtained from many sources

&lt;ul&gt;
&lt;li&gt;Much from &lt;a href=&quot;http://cfbdatawarehouse.com&quot;&gt;http://cfbdatawarehouse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Also used wikipedia, ESPN, and rivals
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa.png&quot; alt=&quot;&quot; height = &quot;500&quot; width = &quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa State Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa_state.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Strengths in web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is relatively easily obtained&lt;/li&gt;
&lt;li&gt;Structured process for obtaining data&lt;/li&gt;
&lt;li&gt;Can be easily updated
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Challenges of web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;At the mercy of the website

&lt;ul&gt;
&lt;li&gt;Many sites are old&lt;/li&gt;
&lt;li&gt;Not up to date on current design standards&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data validation can be difficult and time consuming&lt;/li&gt;
&lt;li&gt;Need some basic knowledge of html
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;When is Web Scraping Worthwhile?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best when scraping many pages

&lt;ul&gt;
&lt;li&gt;Particularly when web addresses are not structured&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful when data need to be updated&lt;/li&gt;
&lt;/ul&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt;Not useful if only scraping a single page/table
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;HTML Basics&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt; HTML is structured by start tags (e.g. &lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;) and end tags (e.g. &lt;code&gt;&amp;lt;&amp;frasl;table&amp;gt;&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt; Common tags 
&lt;/li&gt;
&lt;/ul&gt;


&lt;div style=&quot;float: left; width: 75%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; - &lt;code&gt;&amp;lt;h6&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;a href=&amp;quot;http://www.google.com&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;div style=&quot;float: right; width: 25%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; &amp;amp; &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt; Highly structured pages are the easiest to scrape &lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;HTML Code Example&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ferentz_wikiside.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Tools for web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rvest&lt;/code&gt;: &lt;a href=&quot;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&quot;&gt;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;XML&lt;/code&gt;: &lt;a href=&quot;http://www.omegahat.org/RSXML/&quot;&gt;http://www.omegahat.org/RSXML/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;beautiful soup&lt;/code&gt;: &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/&quot;&gt;http://www.crummy.com/software/BeautifulSoup/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Misc

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SelectorGadget&lt;/code&gt;: &lt;a href=&quot;http://selectorgadget.com/&quot;&gt;http://selectorgadget.com/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Basics of rvest&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;read_html&lt;/code&gt; is the most basic function&lt;/li&gt;
&lt;li&gt;&lt;code&gt;html_node&lt;/code&gt; or &lt;code&gt;html_nodes&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;These functions need css selectors or xpath&lt;/li&gt;
&lt;li&gt;SelectorGadget is the easiest way to get this
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;SelectorGadget&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;SelectorGadget is a Javascript addon for web browsers&lt;/li&gt;
&lt;li&gt;Can quickly identify a css selector or xpath to select correct portion of web page&lt;/li&gt;
&lt;li&gt;Demo:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;&gt;https://en.wikipedia.org/wiki/Kirk_Ferentz&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Combine SelectorGadget with rvest&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rvest)
wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;)
wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
    html_nodes(&quot;.vcard td , .vcard th&quot;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## {xml_nodeset (6)}
## [1] &amp;lt;td colspan=&quot;2&quot; style=&quot;text-align:center&quot;&amp;gt;&amp;lt;a href=&quot;/wiki/File:Kirk_p ...
## [2] &amp;lt;th scope=&quot;row&quot;&amp;gt;Sport(s)&amp;lt;/th&amp;gt;
## [3] &amp;lt;td class=&quot;category&quot;&amp;gt;\n  &amp;lt;a href=&quot;/wiki/American_football&quot; title=&quot;Am ...
## [4] &amp;lt;th colspan=&quot;2&quot; style=&quot;text-align:center;background-color: lightgray ...
## [5] &amp;lt;th scope=&quot;row&quot;&amp;gt;Title&amp;lt;/th&amp;gt;
## [6] &amp;lt;td&amp;gt;\n  &amp;lt;a href=&quot;/wiki/Head_coach&quot; title=&quot;Head coach&quot;&amp;gt;Head coach&amp;lt;/a&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract text&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_text&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;\nFerentz at the 2010 Orange Bowl\n&quot;
## [2] &quot;Sport(s)&quot;                           
## [3] &quot;Football&quot;                           
## [4] &quot;Current position&quot;                   
## [5] &quot;Title&quot;                              
## [6] &quot;Head coach&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Encoding problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Two solutions to fix encoding problems

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;guess_encoding&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repair_encoding&lt;/code&gt;: fix encoding problems&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  guess_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       encoding language confidence
## 1        UTF-8                1.00
## 2 windows-1252       en       0.36
## 3 windows-1250       ro       0.18
## 4 windows-1254       tr       0.13
## 5     UTF-16BE                0.10
## 6     UTF-16LE                0.10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Fix Encoding Problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best practice to reload page with correct encoding&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;, 
                       encoding = &#39;UTF-8&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can also repair encoding after the fact&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;% 
  repair_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract html tags&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_name&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_name()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;td&quot; &quot;th&quot; &quot;td&quot; &quot;th&quot; &quot;th&quot; &quot;td&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract html attributes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_attrs()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
##             colspan               style 
##                 &quot;2&quot; &quot;text-align:center&quot; 
## 
## [[2]]
## scope 
## &quot;row&quot; 
## 
## [[3]]
##      class 
## &quot;category&quot; 
## 
## [[4]]
##                                          colspan 
##                                              &quot;2&quot; 
##                                            style 
## &quot;text-align:center;background-color: lightgray;&quot; 
## 
## [[5]]
## scope 
## &quot;row&quot; 
## 
## [[6]]
## named character(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function again&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard a&quot;) %&amp;gt;%
  html_attr(&#39;href&#39;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;/wiki/American_football&quot;                           
## [3] &quot;/wiki/Head_coach&quot;                                  
## [4] &quot;/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Valid Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;paste0&lt;/code&gt; function is helpful for this&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;valid_links &amp;lt;- paste0(&#39;https://www.wikipedia.org&#39;, wiki_kirk_extract)
head(valid_links)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;https://www.wikipedia.org/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;https://www.wikipedia.org/wiki/American_football&quot;                           
## [3] &quot;https://www.wikipedia.org/wiki/Head_coach&quot;                                  
## [4] &quot;https://www.wikipedia.org/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;https://www.wikipedia.org/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;https://www.wikipedia.org/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract Tables&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;html_table&lt;/code&gt; function is useful to scrape well formatted tables&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;record_kirk &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.wikitable&quot;) %&amp;gt;%
  .[[1]] %&amp;gt;%
  html_table(fill = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Caveats to Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Keep in mind when scraping we are using their bandwidth

&lt;ul&gt;
&lt;li&gt;Do not want to repeatedly do expensive bandwidth operations&lt;/li&gt;
&lt;li&gt;Better to scrape once, then run only to update data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some websites are copyrighted (i.e. illegal to scrape)
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data Modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Research Questions

&lt;ol&gt;
&lt;li&gt;Who is the next great coach?&lt;/li&gt;
&lt;li&gt;What characteristics are in common for these coaches?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;So far we have explored the win/loss records of teams in the BCS era with item response theory (IRT)&lt;/li&gt;
&lt;li&gt;IRT is commonly used to model assessment data to estimate item parameters and person &#39;ability&#39;&lt;/li&gt;
&lt;li&gt;We recode the Win/Loss/Tie game by game results

&lt;ul&gt;
&lt;li&gt;1 = Win&lt;/li&gt;
&lt;li&gt;0 = Otherwise
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example code with lme4&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A 1 parameter multilevel IRT model can be fitted using &lt;code&gt;glmer&lt;/code&gt; in the &lt;code&gt;lme4&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(lme4)
fm1a &amp;lt;- glmer(wingbg ~ 0 + (1|coach) + (1|Team), 
              data = yby_coach, family = binomial)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Plot Showing Team Ability&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/team_ability.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Connect&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;e-mail: brandon-lebeau (at) uiowa.edu&lt;/li&gt;
&lt;li&gt;Twitter: @blebeau11; &lt;a href=&quot;https://twitter.com/blebeau11&quot;&gt;https://twitter.com/blebeau11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linkedin: &lt;a href=&quot;https://www.linkedin.com/in/lebeaubr&quot;&gt;https://www.linkedin.com/in/lebeaubr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://educate-r.org/2015/12/04/centraliowaruser/&quot;&gt;http://educate-r.org/2015/12/04/centraliowaruser/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Speed test of sequence generation for unbalanced simulation</title>
   <link href="http://lebebr01.github.io/2015/03/31/seqspeed.html"/>
   <updated>2015-03-31T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2015/03/31/seqspeed</id>
   <content type="html">&lt;p&gt;I have a simulation package that allows for the simulation of regression models including nested data structures. You can see the package on github here: &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;simReg&lt;/a&gt;. Over the weekend I updated the package to allow for the simulation of unbalanced designs. I&#39;m hoping to put together a new vigenette soon highlighting the functionality.&lt;/p&gt;

&lt;p&gt;I am working on a simulation that uses the unbalanced functionality and while simulating longitudinal data I&#39;ve found the function is much slower than the cross sectional counterparts (and balanced designs). I&#39;ve ran some additional testing and I believe I have the speed issues narrowed down to the fact that I am generating a time variable. Essentially, I have a vector of number of observations per cluster. The function then turns this vector of lengths into a time variable starting at 0 up to the maximum number of observations minus 1 by 1. As an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;x &amp;lt;- round(runif(5, min = 3, max = 10), 0)
unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] 0 1 2 3 4 5 6 7 0 1 2 0 1 2 3 4 5 6 0 1 2 3 4 0 1 2 3 4 5 6 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From the code above, you can see that there the number of observations is generated using &lt;em&gt;runif&lt;/em&gt; which is saved to the object &lt;em&gt;x&lt;/em&gt;. Then I use a combination of lapply, unlist, and the &#39;:&#39; operator to generate the sequence. This is the same code used in my package above to generate the time variable.&lt;/p&gt;

&lt;p&gt;As such, I was interested in testing various ways to generate the sequence and do a performance comparison. I compared the following ways, the &lt;em&gt;&#39;:&#39;&lt;/em&gt; operator, &lt;em&gt;seq.int&lt;/em&gt;, &lt;em&gt;seq&lt;/em&gt;, &lt;em&gt;do.call&lt;/em&gt; with &lt;em&gt;mapply&lt;/em&gt;, and &lt;em&gt;rep.int&lt;/em&gt; for the balanced case as a comparison to how it was done before. This was all done with the great &lt;strong&gt;microbenchmark&lt;/strong&gt; package.&lt;/p&gt;

&lt;p&gt;Here are the results from the 7 comparisons:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(microbenchmark)
x &amp;lt;- round(runif(100, min = 3, max = 15), 0)
microbenchmark(
  colon = unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  seq.int = unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  seq = unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  seq.int_mapply = do.call(c, mapply(seq.int, 0, x - 1)),
  seq_mapply = do.call(c, mapply(seq, 0, x - 1)),
  colon_mapply = do.call(c, mapply(&#39;:&#39;, 0, x - 1)),
  rep.int = rep.int(1:8 - 1, times = 100), # balanced case for reference.
  times = 1000L
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##            expr      min       lq        mean    median        uq        max neval  cld
##           colon  133.429  148.618  255.474605  160.1145  235.8605  57706.598  1000 ab  
##         seq.int  180.231  203.632  270.517868  223.1330  309.9640   2671.845  1000 ab  
##             seq 2255.960 2626.685 4207.210575 2933.1590 3466.4605  88721.432  1000    d
##  seq.int_mapply  227.854  258.235  499.000451  292.7210  397.4110 105037.011  1000  b  
##      seq_mapply  953.293 1079.126 1534.250895 1203.9320 1543.2495  57174.117  1000   c 
##    colon_mapply  167.094  195.832  383.431252  220.4645  299.0845  61779.643  1000 ab  
##         rep.int    2.053    4.516    5.807329    5.7480    6.9800     30.792  1000 a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The results (in microseconds) show that this is where the significant slowdown is coming in my package implementing the unbalanced cases, although it appears that the &#39;:&#39; operator is the second best alternative. For those that have not seen the significant speed bump of the &lt;em&gt;seq.int&lt;/em&gt; and &lt;em&gt;rep.int&lt;/em&gt; over the &lt;em&gt;seq&lt;/em&gt; and &lt;em&gt;rep&lt;/em&gt; alternatives should also pay close attention (compare lines 2 and 3 above).&lt;/p&gt;

&lt;p&gt;I&#39;d be interested in alternative procedures that I am not aware of as well. Although not a big deal when running the package once, doing it 50,000 times does add up.&lt;/p&gt;

&lt;p&gt;Lastly, for those that are interested, we can show they are all equivalent methods (except for the &lt;em&gt;rep.int&lt;/em&gt; case).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;identical(
  unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  do.call(c, mapply(seq.int, 0, x - 1)),
  do.call(c, mapply(seq, 0, x - 1)),
  do.call(c, mapply(&#39;:&#39;, 0, x - 1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Remove leading 0 with ggplot2.</title>
   <link href="http://lebebr01.github.io/2015/03/23/removelead0.html"/>
   <updated>2015-03-23T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2015/03/23/removelead0</id>
   <content type="html">&lt;p&gt;I recently had an occasion while working on a three variable interaction plot for a paper where I wanted to remove the leading 0&#39;s in the x-axis text labels using &lt;em&gt;ggplot2&lt;/em&gt;. This was primarily due to some space concerns I had for the x-axis labels. Unfortunately, I did not find an obvious way to do this in my first go around. After tickering a bit, I&#39;ve found a workaround. The process is walked through below.&lt;/p&gt;

&lt;p&gt;First, some simulated data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Sim some data
simdata &amp;lt;- data.frame(x = runif(2400, min = .032, max = .210),
                      y = c(rnorm(2000, mean = 0, sd = .1), 
                            rnorm(400, mean = 1, sd = .25)),
                      group = c(sample(1:2, 1600, replace = TRUE),
                                rep(1, 400), 
                                rep(2, 400)),
                      facet = rep(1:3, each = 800))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As shown below, initially there is no group differences, but there are facet differences. Exploring the interaction between the grouping variables shows there is a two variable interaction. Note: This example is not identical to the three variable interaction I originally described above, but assume here that the x variable is also important.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, group, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##          1          2 
## 0.00342121 0.33040069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, facet, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             1             2             3 
## -0.0009751953  0.0025336609  0.5028529069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, interaction(group, facet), mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           1.1           2.1           1.2           2.2           1.3 
##  0.0031464214 -0.0048761903  0.0056148873 -0.0005785326  0.0014837970 
##           2.3 
##  1.0042220169
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example in the paper, I aggregated the unique x values to the third decimal place. That is done with the following &lt;em&gt;dplyr&lt;/em&gt; code. Note: The data did not need to be aggregated, but it is a bit easier to work with when plotting later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# round value to .001 and aggregate
simdata$x_rd &amp;lt;- round(simdata$x, 3)

# aggregate
library(dplyr)
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))
simdata_agg 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [962 x 4]
## Groups: x_rd, group
## 
##     x_rd group facet            y
## 1  0.032     1     2 -0.088397852
## 2  0.032     2     2  0.228654211
## 3  0.033     1     1 -0.001843538
## 4  0.033     1     2 -0.021662299
## 5  0.033     1     3 -0.110077646
## 6  0.033     2     1  0.080429131
## 7  0.033     2     3  0.915228939
## 8  0.034     1     1  0.025164086
## 9  0.034     1     2 -0.046522430
## 10 0.034     1     3  0.037889712
## ..   ...   ...   ...          ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the data is aggregated, it can be directly plotted with &lt;em&gt;ggplot2&lt;/em&gt;. This is the base plot that contains the leading 0&#39;s by default and treats the x variable as continuous (which it really is continuous).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(ggplot2)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_rd, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_continuous(&quot;x&quot;, limits = c(0, .25), 
                     breaks = seq(0, .25, .05))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotwith0-1.png&quot; alt=&quot;&quot; /&gt;
The plot above is a good start, but I was worried about the x-axis labels being too close together and ultimately being difficult to read. I decided I wanted to omit the leading 0&#39;s to omit some space. This was useful in my scenario as the variable on the x-axis could only take on values between 0 and 1, therefore the leading 0 is not important.&lt;/p&gt;

&lt;p&gt;One way to remove the leading 0 is to convert the continuous variable into a character variable and use a simple regular expression (with &lt;em&gt;gsub&lt;/em&gt;) to remove the 0 at the beginning of the character string. Below is the code to do that and also the resulting plot. The key point of the plotting code below is the use of the &lt;em&gt;breaks&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;. Without this all the unique character values will be plotted, not good.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.1&#39;, &#39;.15&#39;, &#39;.2&#39;, &#39;.25&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotno0-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot above has a few flaws. First, there are values at the edge of each facet. This could be fixed with the &lt;em&gt;expand&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;, but I still wanted to include the value of .00 on the x-axis. Secondly, the x-axis text labels are not uniformly formatted which is not ideal (e.g. .1 should be .10).&lt;/p&gt;

&lt;p&gt;To fix this, some made up data needs to be added to the data frame. Some care needs to be done here as well as a value of .00 can not just be added to the x variable plotted. This would place a non-uniform gap between .00 and .05 (not shown, but try it for yourself by adapting the code below). Therefore, all values between 0 and .031 need to be manually added to the data frame to keep the spacing uniform. Finally, to not plot the made up values, I created a transparency variable called alpha. This variable was used to set the alpha values to 0 for the made up values and 1 for the real values. &lt;em&gt;scale_alpha_discrete&lt;/em&gt; was used to specify the range of alpha values, this is important otherwise the made up numbers will show up as a light gray. The final code to manually add the new data is shown below. Anyone have a less workaround procedure?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Reset aggregation vector
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))

# Add values
simdata_agg &amp;lt;- rbind(data.frame(x_rd = seq(0, .031, .001),
                                group = rep(1, 32),
                                facet = rep(1, 32),
                                y = rep(0, 32)),
                     simdata_agg)

# Create a new variable to use for transparent points
simdata_agg$alpha &amp;lt;- ifelse(simdata_agg$x_rd &amp;lt; .032, 0, 1)

# Create x_char variable again
simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)

# Needed formatting
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;&#39;, &#39;.00&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.2&#39;, &#39;.20&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.1&#39;, &#39;.10&#39;,
                             simdata_agg$x_char)

# Final plot
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(aes(alpha = factor(alpha)), size = 3) + 
  facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.10&#39;, &#39;.15&#39;, &#39;.20&#39;),
                   expand = c(.05, .05)) + 
  scale_alpha_discrete(guide = FALSE, range = c(0, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/addmadeupvalues-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Structured simulation of regression models - simReg package.</title>
   <link href="http://lebebr01.github.io/2014/10/01/simReg.html"/>
   <updated>2014-10-01T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/10/01/simReg</id>
   <content type="html">&lt;p&gt;I&#39;d like to introduce a package that simulates regression models. This includes both single level and multilevel (i.e. hierarchical or linear mixed) models up to two levels of nesting. The package produces a unified framework to simulate all types of continuous regression models. In the future, I&#39;d like to add the ability to simulate generalized linear models. This package is an extension of the functions I used to simulate data for my dissertation.&lt;/p&gt;

&lt;p&gt;The package is currently on github &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;https://github.com/lebebr01/simReg&lt;/a&gt;. Therefore, you can currently install the package by using the &lt;em&gt;devtools&lt;/em&gt; package like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(&quot;lebebr01/simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The primary function of interest in this package is &lt;em&gt;sim.reg&lt;/em&gt;. To show the use of this function, here is a simple example simulating a single level regression mode. Note, this example is pulled directly from the &lt;strong&gt;Intro&lt;/strong&gt; vignette.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simReg)
set.seed(100)
fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed.param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov.param &amp;lt;- list(mean = c(0, 0, 0), sd = c(4, 3, 3), var.type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
n &amp;lt;- 150
errorVar &amp;lt;- 3
err.dist &amp;lt;- &quot;norm&quot;
temp.single &amp;lt;- sim.reg(fixed = fixed, fixed.param = fixed.param, cov.param = cov.param,
n = n, errorVar = errorVar, err.dist = err.dist, data.str = &quot;single&quot;)
head(temp.single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.     act     diff numCourse act.numCourse    Fbeta      err
## 1            1 -2.0088  3.10406    -5.566       11.1815 -0.05022 -3.35921
## 2            1  0.5261  4.96051    -3.056       -1.6077 -4.84527 -5.75176
## 3            1 -0.3157 -0.05384    -3.135        0.9897 -8.31073  1.63173
## 4            1  3.5471 -0.07261    -1.954       -6.9306 -4.58382  0.06435
## 5            1  0.4679  0.75074     1.148        0.5372  9.71476 -0.44783
## 6            1  1.2745 -1.01137     3.096        3.9455 24.81272  0.59651
##   sim.data ID
## 1   -3.409  1
## 2  -10.597  2
## 3   -6.679  3
## 4   -4.519  4
## 5    9.267  5
## 6   25.409  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the above code, the package uses a single sided equation to represent the fixed effects. Other arguments include the values for those fixed effects (fixed.param), the scale for the covariates (cov.param), the sample size (n), the error variance (errorVar), and the error distribution (err.dist). These are all put into the function &lt;em&gt;sim.reg&lt;/em&gt; with the additional argument &lt;em&gt;data.str&lt;/em&gt; to tell the function that we indeed want a single level regression and you get the following output. The data frame that is returned gives the values for the design matrix, the fixed portion of the model (Fbeta), and the random error term (err). The value of most interest if conducting a simulation would be the actually simulated value (sim.data).&lt;/p&gt;

&lt;h3&gt;Nested Example&lt;/h3&gt;

&lt;p&gt;A slightly more complicated example is shown below where longitudinal data are simulated.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time + diff
fixed.param &amp;lt;- c(4, 2, 6, 2.3, 7)
random.param &amp;lt;- c(7, 4, 2)
cov.param &amp;lt;- list(mean = c(0, 0), sd = c(1.5, 4), var.type = c(&quot;lvl1&quot;, &quot;lvl2&quot;))
n &amp;lt;- 150
p &amp;lt;- 30
errorVar &amp;lt;- 4
randCor &amp;lt;- 0
rand.dist &amp;lt;- &quot;norm&quot;
err.dist &amp;lt;- &quot;norm&quot;
serCor &amp;lt;- &quot;ID&quot;
serCorVal &amp;lt;- NULL
data.str &amp;lt;- &quot;long&quot;
temp.long &amp;lt;- sim.reg(fixed, random, fixed.param, random.param, cov.param,
n, p, errorVar, randCor, rand.dist, err.dist, serCor, serCorVal, data.str)
head(temp.long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time     diff    act time.act    b0      b1    b2   Fbeta
## 1            1    0 -0.05455  1.608    0.000 5.118 -0.1118 0.251   7.371
## 2            1    1 -2.23677 -1.349   -1.349 5.118 -0.1118 0.251 -19.968
## 3            1    2  0.50321 -6.028  -12.056 5.118 -0.1118 0.251 -87.237
## 4            1    3  1.25027  8.436   25.308 5.118 -0.1118 0.251 214.063
## 5            1    4  2.05871  3.917   15.667 5.118 -0.1118 0.251 143.031
## 6            1    5 -1.87968  7.598   37.990 5.118 -0.1118 0.251 286.125
##   randEff     err sim.data withinID clustID
## 1   5.104  3.2637    15.74        1       1
## 2   4.444  0.9355   -14.59        2       1
## 3   5.020 -3.1693   -85.39        3       1
## 4   5.096  4.1523   223.31        4       1
## 5   5.187 -3.1716   145.05        5       1
## 6   4.086 -0.2605   289.95        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the arguments should look familiar to above, but a few are new. Most notably these are a one sided equation for the random effects (random), their variances (random.param), the number of observations within a cluster (p), the correlation among the random effects (randCor), the simulated distribution of the random effects (rand.dist), the serial correlation model for within cluster residuals (serCor), the values for the serial correlation models (serCorVal). Note now since this represents longitudinal data, the &lt;em&gt;data.str&lt;/em&gt; argument is now specified as &#39;long&#39;.&lt;/p&gt;

&lt;h3&gt;Other features&lt;/h3&gt;

&lt;p&gt;The package also simulates cross sectional multilevel models, covariates that are either a factor, ordinal, or categorical, and the basics for power simulation are there.&lt;/p&gt;

&lt;p&gt;For further information, see the vignette by doing the following after installing the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;vignette(&quot;Intro&quot;, package = &quot;simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bugs, comments, or feature requests can be submitted on the github site &lt;a href=&quot;https://github.com/lebebr01/simReg/issues&quot;&gt;https://github.com/lebebr01/simReg/issues&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Google location data -- Where I've been.</title>
   <link href="http://lebebr01.github.io/2014/09/26/googlelocations.html"/>
   <updated>2014-09-26T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/09/26/googlelocations</id>
   <content type="html">&lt;p&gt;I was emailed by a friend that was looking into their google location data and had asked if I had ever used a json file before in R. I said I had not, but I knew there were packages to do such things. The things I sent were things he had already tried, so what did I decide to do? I went ahead and downloaded my own google location data.&lt;/p&gt;

&lt;p&gt;If you use google services (particularly have an android phone) you can get your google location information here buried in google&#39;s settings page: &lt;a href=&quot;https://www.google.com/settings/datatools&quot;&gt;Google Data Page&lt;/a&gt;. From there you can click on create new archive at the bottom of the rightmost column under &quot;Download your data&quot;. If you&#39;d like to replicate the map below, you just need the location data, therefore I unselected all of the options except for location. Then there is some thinking on google&#39;s servers and they give you a download file (either .zip, .tbz, or .tgz) from which you can download. Mine did not take long to prepare, if they have more location information on you it may take longer.&lt;/p&gt;

&lt;p&gt;Below is a map of all the locations I&#39;ve been. I rounded the latitude and longitude values to two decimals (and had to add the decimals) to create less exact location values. This step could obviously be omitted. You&#39;ll notice in the ggplot2 code that I set the alpha equal to .01, this allowed the locations where I&#39;ve been longer to be darker. You could get more fancy with this, especially if you are able to figure out the code google uses for their timestamp. Just looked like mumbo jumbo to me. There is also accuracy, velocity, heading, altitude, and activity data.&lt;/p&gt;

&lt;p&gt;Kind of a cool process. The map shows places I&#39;ve been the last year or so (does not include San Francisco from AERA two years ago) including living in Fayetteville, Iowa City, Saint Paul. It also shows a few places I was for interviews last year including travel through some airports (Dallas, Houston, Charlotte, Chicago) and even shows my honeymoon to the panhandle of Florida. It also made me realize how much more I need to explore to the west (and east to some extent).&lt;/p&gt;

&lt;p&gt;Below is the code I used to load, manipulate, and plot my google location data. To replicate you would need to download your own google location data. Has anyone else made sense of all this data?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/myjson.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rjson)
json_file &amp;lt;- &quot;path/to/your/json/file&quot;
json_data &amp;lt;- fromJSON(file = json_file)
latlong &amp;lt;- data.frame(do.call(&quot;rbind&quot;, json_data[[2]]))
latlong2 &amp;lt;- subset(latlong, select = c(latitudeE7, longitudeE7))
latlong2$latR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$latitudeE7), 1, 2), 
                                   &quot;.&quot;, substr(as.character(latlong2$latitudeE7), 3, 4)))
latlong2$longR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$longitudeE7), 1, 3), 
                                    &quot;.&quot;, substr(as.character(latlong2$longitudeE7), 4, 5)))

library(maps)
library(ggplot2)

states &amp;lt;- map_data(&quot;state&quot;)

p &amp;lt;- ggplot(states) + 
  geom_polygon(aes(x = long, y = lat, group = group), 
               fill = &quot;white&quot;, color = &quot;black&quot;) + 
  theme_bw() + 
  theme(axis.text = element_blank(), line = element_blank(), 
        rect = element_blank(), axis.title = element_blank())
p + geom_point(data = latlong2, aes(x = longR, y = latR), 
               alpha = .01, color = &quot;red&quot;, size = 3)
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Offense or defense improve likelihood of becoming bowl eligible?</title>
   <link href="http://lebebr01.github.io/2014/09/05/winpct.html"/>
   <updated>2014-09-05T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/09/05/winpct</id>
   <content type="html">&lt;p&gt;I saw a post recently about the likelihood of a baseball team winning based on how many runs, hits, and other baseball statistics. I liked the idea and thought of applying that to college football. Particularly, I&#39;m interested in knowing whether scoring more points or having a stout defense improves the likelihood of becoming bowl eligible.&lt;/p&gt;

&lt;p&gt;Using some data scraped from the &lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;cfbDatawarehouse&lt;/a&gt; to figure out how likely a team would be bowl eligible based on the number of points they score. Below are the results of my exploration looking at both the points scores metric and the points against metric (also there is a quick interactive rCharts version of the plot down further). Seems to me that scoring more points leads to more assured success in the college game, perhaps that is why offensive recruits seem to be more sought after. This would also be interesting to create by decade to see if trends have shifted over the years.&lt;/p&gt;

&lt;p&gt;Enjoy, plots (and code for plots) shown below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;p &amp;lt;- ggplot(coaches, aes(x = PF)) + theme_bw() 
p + stat_smooth(data = ovrBE, aes(x = avg, y = bpct, linetype = group), 
                se = FALSE, size = 1.5, method = &quot;loess&quot;) + 
  geom_point(data = ovrBE, aes(x=avg, y = bpct, color = group), size = 2) + 
  scale_x_continuous(&quot;Points&quot;, limits = c(0, 500), breaks = c(0, 100, 200, 300, 400, 500)) + 
  scale_color_brewer(palette = &quot;Dark2&quot;) + 
  ylab(&quot;Bowl Eligibility Likelihood&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/points.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)

h1 &amp;lt;- hPlot(x = &quot;avg&quot;, y = &quot;bpct&quot;, group = &quot;group&quot;, data = ovrBE)
h1$yAxis(title = list(text = &quot;Bowl Eligibility Likelihood&quot;), min = 0, max = 1, tickInterval = .1)
h1$xAxis(title = list(text = &quot;Points&quot;),
         min = 0, max = 500, tickInterval = 100)
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Group&quot;))
h1$plotOptions(series = list(lineWidth = 2))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;script type=&#39;text/javascript&#39; src=//code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/highcharts-more.js&quot;&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=//code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 400px;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Bowl Eligibility Likelihood&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:              1,
&quot;tickInterval&quot;:            0.1 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
           34.5,
         0.848 
],
[
           62.5,
         0.889 
],
[
           71.5,
          0.85 
],
[
           77.5,
         0.881 
],
[
             83,
         0.846 
],
[
             88,
         0.789 
],
[
             92,
         0.702 
],
[
             96,
         0.789 
],
[
           99.5,
         0.745 
],
[
          102.5,
         0.708 
],
[
            105,
         0.625 
],
[
            108,
         0.753 
],
[
          111.5,
         0.754 
],
[
          114.5,
         0.704 
],
[
            117,
         0.732 
],
[
          119.5,
         0.697 
],
[
            122,
         0.649 
],
[
            124,
         0.627 
],
[
          126.5,
         0.643 
],
[
            129,
         0.635 
],
[
            131,
         0.732 
],
[
          133.5,
         0.657 
],
[
            136,
         0.721 
],
[
            138,
         0.532 
],
[
            140,
         0.593 
],
[
            142,
         0.617 
],
[
            144,
         0.531 
],
[
            146,
         0.582 
],
[
          147.5,
         0.576 
],
[
            149,
         0.646 
],
[
            151,
         0.542 
],
[
            153,
         0.692 
],
[
            155,
         0.619 
],
[
            157,
         0.677 
],
[
            159,
         0.582 
],
[
          160.5,
         0.553 
],
[
            162,
         0.573 
],
[
            164,
         0.611 
],
[
          165.5,
         0.725 
],
[
            167,
         0.585 
],
[
            169,
         0.597 
],
[
          170.5,
         0.676 
],
[
            172,
           0.5 
],
[
          173.5,
         0.619 
],
[
            175,
         0.508 
],
[
            177,
         0.514 
],
[
            179,
         0.533 
],
[
            181,
         0.549 
],
[
          182.5,
         0.479 
],
[
            184,
         0.635 
],
[
          185.5,
         0.571 
],
[
            187,
         0.531 
],
[
          188.5,
         0.564 
],
[
            190,
         0.594 
],
[
            192,
         0.557 
],
[
          193.5,
         0.556 
],
[
            195,
         0.593 
],
[
          196.5,
         0.703 
],
[
            198,
         0.562 
],
[
          199.5,
         0.578 
],
[
            201,
         0.508 
],
[
            203,
         0.623 
],
[
            205,
         0.657 
],
[
            207,
         0.536 
],
[
          208.5,
         0.487 
],
[
          209.5,
          0.55 
],
[
            211,
         0.588 
],
[
          212.5,
          0.49 
],
[
          213.5,
         0.462 
],
[
            215,
         0.479 
],
[
            217,
         0.533 
],
[
            219,
         0.704 
],
[
          220.5,
         0.562 
],
[
            222,
         0.468 
],
[
            224,
         0.574 
],
[
          225.5,
         0.568 
],
[
          226.5,
          0.64 
],
[
            228,
         0.593 
],
[
          229.5,
         0.629 
],
[
            231,
         0.531 
],
[
            233,
         0.478 
],
[
            235,
         0.464 
],
[
          236.5,
         0.469 
],
[
            238,
         0.539 
],
[
            240,
         0.547 
],
[
          241.5,
         0.423 
],
[
            243,
         0.561 
],
[
          244.5,
         0.353 
],
[
            246,
         0.603 
],
[
            248,
         0.429 
],
[
            250,
          0.54 
],
[
            252,
         0.472 
],
[
            254,
         0.387 
],
[
            256,
         0.609 
],
[
          257.5,
         0.472 
],
[
            259,
         0.478 
],
[
            261,
         0.426 
],
[
            263,
         0.485 
],
[
            265,
          0.47 
],
[
          266.5,
         0.361 
],
[
            268,
         0.453 
],
[
          270.5,
         0.386 
],
[
            273,
         0.475 
],
[
            275,
         0.407 
],
[
          276.5,
         0.622 
],
[
            278,
           0.5 
],
[
            280,
         0.481 
],
[
            282,
         0.589 
],
[
          283.5,
         0.378 
],
[
            285,
         0.549 
],
[
            287,
          0.46 
],
[
            289,
         0.486 
],
[
            291,
         0.379 
],
[
          293.5,
          0.43 
],
[
          295.5,
         0.364 
],
[
            297,
         0.453 
],
[
          299.5,
         0.353 
],
[
            302,
         0.447 
],
[
          304.5,
         0.489 
],
[
            307,
         0.358 
],
[
          309.5,
           0.5 
],
[
            312,
         0.351 
],
[
          314.5,
         0.426 
],
[
          317.5,
           0.4 
],
[
            321,
           0.4 
],
[
          324.5,
         0.333 
],
[
          327.5,
         0.385 
],
[
          330.5,
         0.246 
],
[
            334,
         0.328 
],
[
          337.5,
         0.227 
],
[
          340.5,
         0.357 
],
[
          343.5,
         0.396 
],
[
            347,
         0.297 
],
[
            351,
         0.262 
],
[
            355,
          0.31 
],
[
            359,
         0.308 
],
[
            363,
         0.308 
],
[
            367,
         0.348 
],
[
          371.5,
         0.291 
],
[
          376.5,
         0.246 
],
[
            382,
         0.309 
],
[
          387.5,
         0.255 
],
[
            394,
         0.259 
],
[
          402.5,
         0.206 
],
[
            412,
         0.177 
],
[
          421.5,
         0.232 
],
[
            431,
         0.164 
],
[
            448,
         0.136 
],
[
          477.5,
         0.183 
] 
],
&quot;name&quot;: &quot;Points Against&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
},
{
 &quot;data&quot;: [
 [
           34.5,
             0 
],
[
           62.5,
             0 
],
[
           71.5,
             0 
],
[
           77.5,
             0 
],
[
             83,
         0.015 
],
[
             88,
         0.018 
],
[
             92,
         0.016 
],
[
             96,
         0.017 
],
[
           99.5,
             0 
],
[
          102.5,
         0.048 
],
[
            105,
             0 
],
[
            108,
          0.05 
],
[
          111.5,
         0.127 
],
[
          114.5,
         0.102 
],
[
            117,
         0.125 
],
[
          119.5,
         0.125 
],
[
            122,
         0.115 
],
[
            124,
         0.055 
],
[
          126.5,
         0.159 
],
[
            129,
         0.149 
],
[
            131,
         0.183 
],
[
          133.5,
         0.088 
],
[
            136,
         0.147 
],
[
            138,
          0.18 
],
[
            140,
         0.158 
],
[
            142,
         0.096 
],
[
            144,
         0.098 
],
[
            146,
         0.211 
],
[
          147.5,
         0.197 
],
[
            149,
         0.143 
],
[
            151,
         0.164 
],
[
            153,
         0.167 
],
[
            155,
         0.189 
],
[
            157,
         0.305 
],
[
            159,
         0.433 
],
[
          160.5,
         0.262 
],
[
            162,
         0.361 
],
[
            164,
         0.149 
],
[
          165.5,
         0.276 
],
[
            167,
         0.324 
],
[
            169,
         0.391 
],
[
          170.5,
         0.324 
],
[
            172,
         0.315 
],
[
          173.5,
         0.296 
],
[
            175,
           0.4 
],
[
            177,
          0.39 
],
[
            179,
         0.259 
],
[
            181,
         0.323 
],
[
          182.5,
         0.397 
],
[
            184,
         0.364 
],
[
          185.5,
         0.314 
],
[
            187,
         0.321 
],
[
          188.5,
         0.343 
],
[
            190,
         0.403 
],
[
            192,
         0.406 
],
[
          193.5,
         0.478 
],
[
            195,
         0.446 
],
[
          196.5,
         0.378 
],
[
            198,
         0.381 
],
[
          199.5,
         0.328 
],
[
            201,
         0.339 
],
[
            203,
         0.475 
],
[
            205,
          0.44 
],
[
            207,
         0.407 
],
[
          208.5,
         0.493 
],
[
          209.5,
         0.514 
],
[
            211,
         0.382 
],
[
          212.5,
         0.579 
],
[
          213.5,
         0.429 
],
[
            215,
         0.367 
],
[
            217,
         0.418 
],
[
            219,
         0.344 
],
[
          220.5,
           0.5 
],
[
            222,
         0.446 
],
[
            224,
         0.362 
],
[
          225.5,
         0.353 
],
[
          226.5,
         0.531 
],
[
            228,
         0.488 
],
[
          229.5,
         0.429 
],
[
            231,
         0.562 
],
[
            233,
         0.559 
],
[
            235,
         0.706 
],
[
          236.5,
         0.548 
],
[
            238,
         0.475 
],
[
            240,
         0.561 
],
[
          241.5,
         0.687 
],
[
            243,
         0.673 
],
[
          244.5,
         0.587 
],
[
            246,
         0.621 
],
[
            248,
         0.623 
],
[
            250,
         0.596 
],
[
            252,
          0.69 
],
[
            254,
         0.547 
],
[
            256,
         0.705 
],
[
          257.5,
         0.647 
],
[
            259,
         0.729 
],
[
            261,
         0.633 
],
[
            263,
         0.719 
],
[
            265,
         0.644 
],
[
          266.5,
         0.787 
],
[
            268,
         0.693 
],
[
          270.5,
         0.672 
],
[
            273,
         0.772 
],
[
            275,
           0.8 
],
[
          276.5,
         0.604 
],
[
            278,
         0.746 
],
[
            280,
         0.706 
],
[
            282,
          0.75 
],
[
          283.5,
         0.708 
],
[
            285,
         0.845 
],
[
            287,
           0.7 
],
[
            289,
         0.889 
],
[
            291,
         0.714 
],
[
          293.5,
         0.908 
],
[
          295.5,
         0.796 
],
[
            297,
          0.75 
],
[
          299.5,
         0.811 
],
[
            302,
         0.806 
],
[
          304.5,
         0.839 
],
[
            307,
         0.929 
],
[
          309.5,
         0.905 
],
[
            312,
         0.889 
],
[
          314.5,
         0.827 
],
[
          317.5,
         0.789 
],
[
            321,
         0.873 
],
[
          324.5,
         0.883 
],
[
          327.5,
         0.954 
],
[
          330.5,
         0.898 
],
[
            334,
         0.905 
],
[
          337.5,
         0.909 
],
[
          340.5,
         0.981 
],
[
          343.5,
             1 
],
[
            347,
         0.984 
],
[
            351,
         0.962 
],
[
            355,
         0.957 
],
[
            359,
         0.931 
],
[
            363,
          0.98 
],
[
            367,
          0.97 
],
[
          371.5,
          0.93 
],
[
          376.5,
             1 
],
[
            382,
         0.984 
],
[
          387.5,
         0.984 
],
[
            394,
         0.981 
],
[
          402.5,
         0.982 
],
[
            412,
             1 
],
[
          421.5,
         0.984 
],
[
            431,
             1 
],
[
            448,
             1 
],
[
          477.5,
             1 
] 
],
&quot;name&quot;: &quot;Points Scored&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              3 
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Points&quot; 
},
&quot;min&quot;:              0,
&quot;max&quot;:            500,
&quot;tickInterval&quot;:            100 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Group&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              2 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot; 
} 
});
        });
    })(jQuery);
&lt;/script&gt;



</content>
 </entry>
 
 <entry>
   <title>Dodged bar charts, why not a line graph?</title>
   <link href="http://lebebr01.github.io/2014/08/05/trendgraphics.html"/>
   <updated>2014-08-05T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/08/05/trendgraphics</id>
   <content type="html">&lt;p&gt;I often see graphs that are poorly implemented in that they do not achieve their goal.  One such type of graph that I see are dodged bar charts.  Here is an example of a dodged bar chart summarizing the number of all star players by team (focusing specifically on the AL central division) and year from the &lt;em&gt;Lahman&lt;/em&gt; r package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(Lahman)
library(dplyr)
library(ggplot2)
library(RColorBrewer)

AllstarFull$selected &amp;lt;- 1

numAS &amp;lt;- AllstarFull  %&amp;gt;% 
  filter(yearID &amp;gt; 2006, lgID == &#39;AL&#39;, teamID %in% c(&#39;MIN&#39;, &#39;CLE&#39;, &#39;DET&#39;, &#39;CHA&#39;, &#39;KCA&#39;)) %&amp;gt;%
  group_by(teamID, yearID) %&amp;gt;%
  summarise(number = sum(selected))

b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bar.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note: If you are curious from the above graph, there appears to be two typos in the teamIDs, where CHA should be CHW (Chicago White Sox) and KCA should be KCR (Kansas City Royals).&lt;/p&gt;

&lt;p&gt;The plot above can be good for a few things, predominantly for comparison within a team. It is more difficult to compare between teams (although not impossible).  One way to possibly improve the plot would be to add the number either above each bar or inside of each bar.  This can be done in &lt;em&gt;ggplot2&lt;/em&gt; with the &lt;em&gt;geom_text&lt;/em&gt; function.  For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;b &amp;lt;- ggplot(numAS, aes(x = teamID, y = number, fill = factor(yearID))) + theme_bw()
b + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) + 
  scale_fill_brewer(&quot;Year&quot;, palette = &quot;Dark2&quot;) + 
  geom_text(aes(label = number), position = position_dodge(width = 0.9), 
            vjust = 1.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bartext.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A better alternative to a dodged bar chart in my opinion would be a simple line graph.  The line graph simplifies the graph to only include one variable on the x-axis and uses colors or shapes to differentiate the teams. See below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;l &amp;lt;- ggplot(numAS, aes(x = yearID, y = number, color = teamID, shape = teamID))
l + geom_point(size = 4) + geom_line(size = 1) +
  scale_y_continuous(limits = c(0, 7), expand = c(0,0)) + 
  scale_color_brewer(&quot;Team&quot;, palette = &quot;Dark2&quot;) + scale_shape_discrete(&quot;Team&quot;) + 
  xlab(&quot;Year&quot;) + theme_bw()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/line.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This presentation makes it much easier to compare teams within a single year and also see how the teams have changed over time. The ability to see differences also increases as the variability in the variable increases. In my opinion this is a much simpler graphic and usually is a better option to serve the purpose for the graphic. As always though, the best graphic is one that conveys the message in the simplest, easiest to understand form. You could improve this by making it interactive with &lt;em&gt;rCharts&lt;/em&gt;.  See my post on &lt;em&gt;rCharts&lt;/em&gt; &lt;a href=&quot;/2014/02/15/rcharts/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/2014/03/03/rChartsslidy/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Format Markdown Documents in R</title>
   <link href="http://lebebr01.github.io/2014/07/30/highlightHTML.html"/>
   <updated>2014-07-30T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/07/30/highlightHTML</id>
   <content type="html">&lt;p&gt;Have you ever used a markdown file to create an html file?  Have you ever wanted to quickly format the subsequent html file to add some color or other aspects?  If your answer is yes to both of those questions, this package may be of interest to you.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;&lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;&lt;/strong&gt; package aims to develop a flexible approach to add formatting to an html document by injecting CSS into the file.  To do this, tags are created within the markdown document telling the R routine where to look for these tags.  If you are familiar with the Twitterverse, this package will be equally comfortable.  The tags take the form of the hashtags on Twitter.  As an example, #bgblue, would be a command to change the background to blue.&lt;/p&gt;

&lt;p&gt;The next thing needed by the package is to tell how much of the word, sentence, or header that should be affected by the tag.  To do this, add braces before the tag and include all the content you want to be affected by the tag.  For example, {#bggold this example will have a blue background}.&lt;/p&gt;

&lt;p&gt;Once any tags you want to include are in the markdown document, then the document can be converted into a html file using programs such as &lt;em&gt;knitr&lt;/em&gt;, &lt;em&gt;pandoc&lt;/em&gt;, the RStudio &quot;knit HTML&quot; button (or any others).  Once the resulting html file is compiled, then run the html file through the &lt;strong&gt;highlightHTML&lt;/strong&gt; package and the html file is searched for the tags, the tags are changed to CSS ids, and by default the CSS tags will be inserted automatically back into the document.&lt;/p&gt;

&lt;h3&gt;Minimal Example&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;A markdown document that looks like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;markdown&quot;&gt;# Test of {#colgold highlightHTML} package

Can highlight {#bgblack multiple words}.

Even tables:

| Color Name | Number     |  
|------------|------------|  
| Blue       | 5  #bgblue |  
| Green      | 35         |  
| Orange     | 100        |  
| Red        | 200 #bgred |  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You would then convert the markdown above into a html file (I hit the knit HTML button in RStudio for this file), then run the following commands in R (assuming the highlightHTML package is not installed):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;)
library(highlightHTML)

tags &amp;lt;- c(&quot;#bgred {background-color: red;}&quot;, &quot;#bgblue {background-color: blue;}&quot;,
          &quot;#colgold {color: gold;}&quot;, &quot;#bgblack {background-color: black; color: white;}&quot;)
highlightHTML(input = &quot;path/to/infile.html&quot;, output = &quot;path/to/outfile.html&quot;, 
              updateCSS = TRUE, tags = tags, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will process the html file, look for tags, change the tags to CSS ids, inject the CSS into the document, and lastly open the output file in the browser to see how it looks.  The example above would look like the following after the above commands:
&lt;img src=&quot;http://educate-r.org/figs/mwe.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also go to this link to see the post-processed file: &lt;a href=&quot;/mwe.html&quot;&gt;educate-r.org/mwe.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Upcoming Features&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Currently the package assumes that you know CSS and can supply your own tags.  In the future I&#39;d like to relax this and allow for some basic tags that work without needing to supply the CSS.  I&#39;m hoping to allow background color and text color changes to be made without needing to specify the CSS.  For example, when specifying #bgblue in the markdown file, the R program knows that you want the background color (bg) to be blue.&lt;/p&gt;

&lt;p&gt;Try it out and let me know of new features or bugs as you work through the package.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>R gui Revisited</title>
   <link href="http://lebebr01.github.io/2014/05/27/rguirevisit.html"/>
   <updated>2014-05-27T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/05/27/rguirevisit</id>
   <content type="html">&lt;p&gt;A couple months ago I wrote about switching my class from using SPSS to one that uses R with a gui frontend (&lt;a href=&quot;http://educate-r.org/2014/02/03/Rgui.html&quot;&gt;original post&lt;/a&gt;).  Since the semester has wrapped up, below are my thoughts on how the course went with respect to the students using R.&lt;/p&gt;

&lt;h4&gt;Things that went well&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Many students by the end were starting to understand the power of R (even through a gui structure).  Most were able to create new variables, run statistical analyses, produce basic graphs or figures, and even understand a few basic commands. They also enjoyed that the language and program were free and they could bring their laptops to class when we were going to talk about doing something new in R.&lt;/p&gt;

&lt;p&gt;I also did not hear any stories of a gui system crashing (which was one complaint of &lt;em&gt;Deducer&lt;/em&gt; in the comments of my last post).  I had students using either &lt;em&gt;Deducer&lt;/em&gt; or &lt;em&gt;Rcmdr&lt;/em&gt;, but whenever possible steered them toward &lt;em&gt;Deducer&lt;/em&gt; as it is a bit more user friendly (in my opinion) and uses &lt;em&gt;ggplot2&lt;/em&gt; by default for graphics.  Although &lt;em&gt;Deducer&lt;/em&gt; did crash on me once while demonstrating something during class, I did not hear any students complain about it.&lt;/p&gt;

&lt;p&gt;During the last two weeks of the course when more assignments surrounding basic inferential methods were due, students were becoming much more confident and better able to navigate the R gui menus.  I do also think that the students did appreciate the simpleness of the R output, only giving you what you ask for (as compared to SPSS that gives you extremely more than you ask for). One part of any gui system is to figure out the menu structure and understand the basic language of the menu.  Once I was able to point students to the correct menus, give them correct names for statistical procedures, and also point out specific R terminology they were much more comfortable doing things on their own (and even on occasion trying new things on their own).&lt;/p&gt;

&lt;h4&gt;Things that went poorly&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;Using both &lt;em&gt;Deducer&lt;/em&gt; and &lt;em&gt;Rcmdr&lt;/em&gt; in the class.  I did not want to do this initially, but was forced to do it as I was unsure initially why some students were getting an error (it is based on the Java version installed).  I should have spent more time trying to transition students to &lt;em&gt;Deducer&lt;/em&gt; after figuring out the error, however did not want to have them learn a new system after starting to learn &lt;em&gt;Rcmdr&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Another sticky spot was that I did not have students learn &lt;em&gt;Markdown&lt;/em&gt;, therefore students were copying and pasting output into Word. If anyone has tried this in the past, it usually does not format the best.  In the future (definitely for a PhD level course) I would have students learn &lt;em&gt;Markdown&lt;/em&gt; as it would likely not take more than an hour.&lt;/p&gt;

&lt;p&gt;Students using &lt;em&gt;Rcmdr&lt;/em&gt; had difficulty created dichotomous variables from a continuous variable.  With &lt;em&gt;Rcmdr&lt;/em&gt;, one needs to know some basic R commands (like &lt;em&gt;ifelse&lt;/em&gt;) in order to create dichotomous variables.  This is not something that I spent much time going over in class and was a definite stumbling block for many students.&lt;/p&gt;

&lt;p&gt;An unfortunate aspect of any course where students need to learn software (or just any type of material in general) is that some students do not feel the software is something they are going to use down the road.  As a result, a handful of students seemed to be a bit more obstinate regarding the use of R (and my guess would have been a similar reaction to using SPSS).&lt;/p&gt;

&lt;p&gt;Lastly, I did not have assignments that focused specifically on learning R.  If I ever teach a course of this level again (which may not occur at my new job at the University of Iowa) I would definitely have more regular small assignments to accomplish more data manipulation tasks, such as creating a new variable, turn a variable into a factor, etc.&lt;/p&gt;

&lt;h4&gt;Summary&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;In general I was pleased with using R and more specifically using a R gui for the the course.  The scope of the class was not to teach students a statistical language and for many of these students this was likely their last research/statistics course. This gave me one shot to try to get them familiar enough with the program to be an option for them in the future.  I do feel that the students became familiar enough with R during the course to be able to use it for basic data manipulation and analysis in the future, but are still tied to the gui system.&lt;/p&gt;

&lt;p&gt;With that being said, if I ever teach a similar course in the future, I would likely create a shiny app that allows students to interact in the browser instead of using the R gui. The scope of the course is focused more on interpretation of the output rather than learning the statistical package to get the output, so the shiny app would work well (I&#39;m imagining a Tinkerplots-esque look and feel). I would also recommend for anyone who has students and a course at a similar level and you choose to use a gui system for R, to use &lt;em&gt;Deducer&lt;/em&gt;.  Once the initial setup bottlenecks are worked out it is much easier for the students to learn and use (and is more similar to SPSS if they use that program in the future).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>AERA Preview</title>
   <link href="http://lebebr01.github.io/2014/04/02/aerapreview.html"/>
   <updated>2014-04-02T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/04/02/aerapreview</id>
   <content type="html">&lt;p&gt;The American Educational Research Association (AERA) annual conference is this weekend in Philadelphia.  I was lucky to have a paper accepted into the conference.  I am presenting a meta analysis that I have been working on for the past two years or so titled: Model misspecification and assumption violations with the linear mixed model: A meta analysis.&lt;/p&gt;

&lt;p&gt;In this paper, I have compiled numerous monte carlo studies perform a quantitative synthesis of the literature.  I have focused primarily on longitudinal linear mixed models as that was what my dissertation topic, and practically speaking, I already had many monte carlo studies in hand making the task a bit simpler.&lt;/p&gt;

&lt;p&gt;Here is a sneak peak of some of the results from my paper in the form of an interactive chart using the &lt;em&gt;rChart&lt;/em&gt; package to get started.  Here is my r code to generate the initial chart:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)
h1 &amp;lt;- hPlot(x = &quot;fitSerCor2&quot;, y = &quot;avgt1e&quot;, group = &quot;missRE&quot;, data = intmean)
h1$yAxis(title = list(text = &quot;Empirical Type I Error Rate&quot;), min = 0.00, max = 0.2, tickInterval = 0.05)
h1$xAxis(title = list(text = &quot;Fitted Serial Correlation Structure&quot;),
         categories = c(&quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot;))
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Miss RE&quot;))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As in one of my prior posts about &lt;em&gt;rCharts&lt;/em&gt; I manually added a few features to the Javascript manually.  I find that easier than bundling lists upon lists to achieve the desired result.  Below is the final image:&lt;/p&gt;

&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 600px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Empirical Type I Error Rate&quot;,
   style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
   }
},
labels: {
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            0.2,
&quot;tickInterval&quot;:           0.05 
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.0519
],
 [
 &quot;AR1&quot;,
0.0635
],
[
 &quot;MA1&quot;,
0.0639
],
[
 &quot;MA2&quot;,
0.0665
], 
[
 &quot;ARMA&quot;,
0.0656
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#e41a1c&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;0&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
0.1837
],
 [
 &quot;AR1&quot;,
0.0864
],
[
 &quot;MA1&quot;,
0.1155
],
[
 &quot;MA2&quot;,
0.0999
], 
[
 &quot;ARMA&quot;,
0.0896
],
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#377eb8&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;1&quot;,
&quot;type&quot;: null,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
} 
],
&quot;xAxis&quot;: [
 {
 &quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted Serial Correlation Structure&quot;,
 style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Miss RE&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;,
  zoomType: &quot;y&quot;,
   &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;p&gt;If anyone is attending AERA this year and wants to listen to my presentation as well as others dealing with Methodological Considerations in Modeling Latent Growth (the title of the session) stop by the Convention Center on Sunday, April 6th from 4:05 to 5:35 pm in room 117.  Even if you do not want to hear about modeling latent growth, but would rather talk about r, perhaps we can meetup somewhere else.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Evolution of Code</title>
   <link href="http://lebebr01.github.io/2014/03/27/evolvecode.html"/>
   <updated>2014-03-27T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/03/27/evolvecode</id>
   <content type="html">&lt;p&gt;Recently while scraping some data from the college football data warehouse site, I started to realize the evolution of my code.  To preface this, I am definitely not a trained programmer, just a self taught junky who enjoys doing it when I have time.  I&#39;ve slowly evolved my programming skills from simply statistics languages like r or SPSS, to some other languages like LaTeX, HTML, CSS, Javascript, and I&#39;ve started to work through some python.&lt;/p&gt;

&lt;p&gt;Now back to my realization.  As I mentioned, I was scraping some data from &lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;CFB Data Warehouse&lt;/a&gt; for a project that I&#39;m working on with a colleague and was adapting some code that was written about 3 years ago.  The problem was that my old code was broken.  The original code was about 100 lines of code just to select the correct table and format it.  Here is a chunk of the original code to select the correct table.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;  ##Identifying correct tables
    tb &amp;lt;- vector(&quot;list&quot;, length(tableNodes))
      for(i in 1:length(tableNodes)){
        tb[[i]] &amp;lt;- readHTMLTable(tableNodes[[i]])
      }

  ##Tables that are the correct length
    tabNum &amp;lt;- matrix(nrow=length(tableNodes), ncol=2)
    tabNum[,1] &amp;lt;- sapply(tb, length)
    tabNum[,2] &amp;lt;- 1:length(tableNodes)

   Num &amp;lt;- subset(tabNum, tabNum[,1] == 7)[,2]

  ##Selecting and combining tables
if(length(Num) == 5){
   tb1 &amp;lt;- tb[[Num[3]]]
   tb1$Other &amp;lt;- 0
   tb2 &amp;lt;- tb[[Num[5]]]
   tb2$Other &amp;lt;- 1
   tab &amp;lt;- rbind(tb1, tb2)
 } else { 
  if(length(Num) ==3){
   tab &amp;lt;- tb[[Num[3]]]
   tab$Other &amp;lt;- 1
 } else {
  tab &amp;lt;- matrix(NA, ncol= 8, nrow=1)  
 }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code was looped over many different pages and was run once for every page.  Essentially the code is complicated and inconsistent, but at the time 3 years ago the code ran and that was enough for me.  Extract the data from the website no matter how much code was needed to do the work.  This was back in an era when I was just becoming familiar with much or &lt;em&gt;R&lt;/em&gt;, the &lt;em&gt;XML&lt;/em&gt; package, and attempting to scrape data from a messy/complicated site.&lt;/p&gt;

&lt;p&gt;My new code to extract the tables looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# extracting tables
  tabs &amp;lt;- lapply(seq(3, length(Nodes), 1), function(x) 
    readHTMLTable(Nodes[[x]], stringsAsFactors = FALSE))

  # Combine tables
  bowl &amp;lt;- do.call(&quot;rbind&quot;, tabs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much cleaner, simpler, more consistent, and quite possibly quicker.  The ability to focus on speed, readability, and consistency is something that comes later after one becomes more comfortable with the language.  I have been focusing on this for awhile, but these stark differences and ease I was able to adapt my old code especially struck me this time.  I haven&#39;t decided if this evolution for me is &lt;em&gt;mastery&lt;/em&gt; or &lt;em&gt;expert&lt;/em&gt; status of the r language, but I now feel I have progressed to a point where I feel confident and am able to shift my focus from having code that works, to code that is now clean, consistent, and readable.&lt;/p&gt;

&lt;p&gt;Has anyone else had similar epiphanies with their code?&lt;/p&gt;

&lt;p&gt;Lastly, if you want to see the raw code, go to the github page: &lt;a href=&quot;https://github.com/lebebr01/cfbFootball&quot;&gt;https://github.com/lebebr01/cfbFootball&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Update to highlightHTML package</title>
   <link href="http://lebebr01.github.io/2014/03/14/htmltext.html"/>
   <updated>2014-03-14T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2014/03/14/htmltext</id>
   <content type="html">&lt;p&gt;I&#39;ve added a new functionality to my &lt;em&gt;highlightHTML&lt;/em&gt; package.  This package post-processes HTML files and injects CSS and adds tags to create some further customization (for example highlight cells of a HTML table).  This is most useful when writing a document using markdown and converting it into a HTML document using a tool like knitr, slidify, or even pandoc.&lt;/p&gt;

&lt;p&gt;Up to now, my package only worked with tables, see my old post that talks about this if you are interested: &lt;a href=&quot;http://educate-r.org/2013/11/01/CondFormatMarkdown/&quot;&gt;highlight tables&lt;/a&gt;.  My update adds a similar functionality to text itself by including span tags in the document.&lt;/p&gt;

&lt;p&gt;The following code will install the package with the new feature from github:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;, ref = &quot;testing&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the package is installed, the new function is called &lt;strong&gt;highlightHTMLtext&lt;/strong&gt;. This function takes a HTML file as the input and post processes the file to add span tags to format text according to the CSS calls specified by the user.  The function looks for {#id text} to add the span tags.  The braces are used to define the text range that will use the id and the #id is the CSS id itself.&lt;/p&gt;

&lt;p&gt;Here is an example using the HTML file that comes with the package and which can also be found in the help file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(highlightHTML)
file &amp;lt;- system.file(&#39;examples&#39;, package = &#39;highlightHTML&#39;)
file1 &amp;lt;- paste(file, &quot;bgtext.html&quot;, sep = &quot;/&quot;)

# Change background color and text color with CSS
tags &amp;lt;- c(&quot;#bgblack {background-color: black; color: white;}&quot;,
  &quot;#bgblue {background-color: #0000FF; color: white;}&quot;)

# Post-process HTML file
highlightHTMLtext(input = file1, output = NULL, updateCSS = TRUE,
  tags = tags, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you run the above command, the file should open in your browser to see the result of the new HTML file.  The result should have boxes of color in specific areas that we indicated by the {#id text} syntax in the raw markdown and HTML file.&lt;/p&gt;

&lt;p&gt;My next step is to develop a master function to wrap these other functions so only one call would be needed to format text and tables.  Let me know of any issues by going to the github page: &lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;report bugs&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Before and After HTML&lt;/h3&gt;

&lt;p&gt;Here is what the body of the HTML file looks like before running the function:
```html
&lt;body&gt;&lt;/p&gt;

&lt;h1&gt;Test of Text&lt;/h1&gt;


&lt;p&gt;Testing the ability to change the {#bgblue color} of the text.&lt;/p&gt;


&lt;p&gt;Can also do {#bgblack multiple words of text}&lt;/p&gt;


&lt;p&gt;{#bgblack Even entire paragraphs that you want to really stand out from the rest of the document.  More than color could also be changed, anything alterable by CSS.  Test out the function and get creative with the CSS}&lt;/p&gt;


&lt;p&gt;&lt;/body&gt;
```&lt;/p&gt;

&lt;p&gt;This is what the HTML document looks like after running the function:
```html
&lt;body&gt;&lt;/p&gt;

&lt;h1&gt;Test of Text&lt;/h1&gt;


&lt;p&gt;Testing the ability to change the &lt;span id=&#39;bgblue&#39;&gt; color&lt;/span&gt; of the text.&lt;/p&gt;


&lt;p&gt;Can also do &lt;span id=&#39;bgblack&#39;&gt; multiple words of text&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span id=&#39;bgblack&#39;&gt; Even entire paragraphs that you want to really stand out from the rest of the document.  More than color could also be changed, anything alterable by CSS.  Test out the function and get creative with the CSS&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;/body&gt;
```&lt;/p&gt;

&lt;p&gt;The braces identify the location of the span tags and the custom CSS id tag to format the text.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>rCharts with slidy</title>
   <link href="http://lebebr01.github.io/2014/03/03/rChartsslidy.html"/>
   <updated>2014-03-03T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2014/03/03/rChartsslidy</id>
   <content type="html">&lt;p&gt;My last post I talked about using &lt;em&gt;rCharts&lt;/em&gt; to create interactive graphics for my interview presentations.  They seemed to go over pretty well in my interviews and helped me greatly as I did not need to remember or write down specific numbers to talk about.  I use &lt;em&gt;slidy&lt;/em&gt; to create my HTML slideshows and there was some interest from my last post to see exactly how I had these charts into a &lt;em&gt;slidy&lt;/em&gt; html presentation.&lt;/p&gt;

&lt;p&gt;First off, I did not use &lt;em&gt;rCharts&lt;/em&gt; and &lt;em&gt;knitr&lt;/em&gt; in tandem, but that would make the workflow a bit easier.  The major thing you&#39;d want to remember is to make sure to add the following chunk option: &lt;strong&gt;results = &#39;asis&#39;&lt;/strong&gt;.  This will ensure that the raw html printed from &lt;em&gt;rCharts&lt;/em&gt; will be included in the markdown file as is.&lt;/p&gt;

&lt;p&gt;I personally just copy and pasted the javascript into my markdown presentation (instead of using &lt;em&gt;knitr&lt;/em&gt; as talked about above).  This was easier for me as I edited many specific options in the raw Javascript to come to my final version (and created a boxplot from scratch).  It would be possible to make all the edits directly through the &lt;em&gt;rCharts&lt;/em&gt; framework, but I found it easier to edit the raw Javascript by looking at the highcharts.js documentation to get the figure I was looking for.&lt;/p&gt;

&lt;p&gt;For those who did not see my last post, here is the R code I used to create my graphic:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)

h1 &amp;lt;- hPlot(x = &quot;GenSerCor&quot;, y = &quot;percent&quot;, group = &quot;FitSerCor&quot;, data = converge)
h1$yAxis(title = list(text = &quot;Convergence Rate&quot;), min = 0, max = 100, tickInterval = 10)
h1$xAxis(title = list(text = &quot;Generated Serial Correlation Structure&quot;),
         categories = c(&quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot;))
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Fitted SC&quot;))
h1$plotOptions(series = list(lineWidth = 4))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After I ran this command in R, I edited the resulting Javascript code that was printed from the last line of the R code above.  My final Javascript code can be seen below.&lt;/p&gt;

&lt;p&gt;```JavaScript&lt;/p&gt;

&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 400px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 title: {
 text: &quot;Convergence Rate&quot;,
  style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
   }
 },
 labels: {
  formatter: function() {
   return this.value + &#39;%&#39;;
  },
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            100,
&quot;tickInterval&quot;:             10 ,
minRange: 10
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
   68.38 
],
[ &quot;AR1&quot;,
   64.88 
],
[ &quot;MA1&quot;,
   55.12 
],
[ &quot;MA2&quot;,
   61.98 
],
[ &quot;ARMA&quot;,
   42.17 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#e41a1c&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;AR1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Solid&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
  65.1 
],
[ &quot;AR1&quot;,
   60.45 
],
[ &quot;MA1&quot;,
  63.68 
],
[ &quot;MA2&quot;,
  54.88 
],
[ &quot;ARMA&quot;,
   63.6 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#377eb8&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;ARMA&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [&quot;Ind&quot;,
  72.48 
],
[ &quot;AR1&quot;,
  93.88 
],
[ &quot;MA1&quot;,
  92.23 
],
[ &quot;MA2&quot;,
  95.62 
],
[ &quot;ARMA&quot;,
  98.37 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#4daf4a&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#4daf4a&quot;,
&quot;name&quot;: &quot;Ind&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Dash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
  71.02 
],
[ &quot;AR1&quot;,
   81.37 
],
[ &quot;MA1&quot;,
   69.15 
],
[ &quot;MA2&quot;,
   84.5 
],
[ &quot;ARMA&quot;,
   88.02 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#984ea3&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#984ea3&quot;,
&quot;name&quot;: &quot;MA1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
   67.23 
],
[ &quot;AR1&quot;,
   70.78 
],
[ &quot;MA1&quot;,
   65.93 
],
[ &quot;MA2&quot;,
   68.83 
],
[ &quot;ARMA&quot;,
   72.9 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#ff7f00&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#ff7f00&quot;,
&quot;name&quot;: &quot;MA2&quot;,
&quot;type&quot;: null,
dashStyle: &#39;DashDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
} 
],
&quot;xAxis&quot;: [
 {
 title: {
 text: &quot;Generated Serial Correlation Structure&quot;,
  style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted SC&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:   4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;, 
 zoomType: &quot;y&quot;,
 &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;pre&gt;&lt;code&gt;
Once you have that in markdown format, you can turn it into a *slidy* html presentation with the following command in *pandoc*:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pandoc -s --mathjax -i -t slidy inputfile.md -o outfile.html
```&lt;/p&gt;

&lt;p&gt;This gives you a file that looks something like this:&lt;/p&gt;

&lt;p&gt;```html
&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&amp;lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Strict//EN&quot;
 &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd&quot;&gt;
&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;
&lt;head&gt;
  &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;
  &lt;meta http-equiv=&quot;Content-Style-Type&quot; content=&quot;text/css&quot; /&gt;
  &lt;meta name=&quot;generator&quot; content=&quot;pandoc&quot; /&gt;
  &lt;meta name=&quot;author&quot; content=&quot;Your Name&quot; /&gt;
  &lt;title&gt;Witty Title&lt;/title&gt;
  &lt;style type=&quot;text/css&quot;&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; media=&quot;screen, projection, print&quot;
    href=&quot;http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css&quot; /&gt;&lt;/p&gt;

&lt;script src=&quot;http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js&quot;
    charset=&quot;utf-8&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt; &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 1000px;
    height: 800px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;script src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;MathJax.Hub.Queue([&quot;Typeset&quot;,MathJax.Hub]);&lt;/script&gt;


&lt;p&gt; &lt;!--   &lt;script src=&quot;http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js&quot;
    charset=&quot;utf-8&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; --&gt;
&lt;/head&gt;
&lt;body&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            1000,
&quot;height&quot;:            600,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 title: {
 text: &quot;Convergence Rate&quot;,
  style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
   }
 },
 labels: {
  formatter: function() {
   return this.value + &#39;%&#39;;
  },
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            100,
&quot;tickInterval&quot;:             10 ,
minRange: 10
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
  68.38 
],
[ &quot;AR1&quot;,
  64.88 
],
[ &quot;MA1&quot;,
  55.12 
],
[ &quot;MA2&quot;,
  61.98 
],
[ &quot;ARMA&quot;,
  42.17 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#e41a1c&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;AR1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Solid&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
  65.1 
],
[ &quot;AR1&quot;,
  60.45 
],
[ &quot;MA1&quot;,
  63.68 
],
[ &quot;MA2&quot;,
  54.88 
],
[ &quot;ARMA&quot;,
   63.6 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#377eb8&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;ARMA&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
  72.48 
],
[ &quot;AR1&quot;,
  93.88 
],
[ &quot;MA1&quot;,
   92.23 
],
[ &quot;MA2&quot;,
   95.62 
],
[ &quot;ARMA&quot;,
   98.37 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#4daf4a&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#4daf4a&quot;,
&quot;name&quot;: &quot;Ind&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Dash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
   71.02 
],
[ &quot;AR1&quot;,
   81.37 
],
[ &quot;MA1&quot;,
   69.15 
],
[ &quot;MA2&quot;,
   84.5 
],
[ &quot;ARMA&quot;,
   88.02 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#984ea3&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#984ea3&quot;,
&quot;name&quot;: &quot;MA1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [ &quot;Ind&quot;,
   67.23 
],
[ &quot;AR1&quot;,
   70.78 
],
[ &quot;MA1&quot;,
   65.93 
],
[ &quot;MA2&quot;,
   68.83 
],
[ &quot;ARMA&quot;,
    72.9 
] 
],
events: {
            mouseOver: function () {
                this.update({
                    color: &#39;black&#39;
                });                
            },
            mouseOut: function () {
                this.update({
                    color: &#39;#ff7f00&#39;
                }); 
            }
        },
&quot;color&quot;: &quot;#ff7f00&quot;,
&quot;name&quot;: &quot;MA2&quot;,
&quot;type&quot;: null,
dashStyle: &#39;DashDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
} 
],
&quot;xAxis&quot;: [
 {
 title: {
 text: &quot;Generated Serial Correlation Structure&quot;,
  style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;20px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted SC&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;, 
 zoomType: &quot;y&quot;,
 &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;p&gt;&lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
```&lt;/p&gt;

&lt;p&gt;That should give you a html presentation with an interactive Javascript based figure.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rcharts</title>
   <link href="http://lebebr01.github.io/2014/02/15/rcharts.html"/>
   <updated>2014-02-15T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2014/02/15/rcharts</id>
   <content type="html">&lt;p&gt;---layout: post
title: Interactive charts with rCharts&lt;/p&gt;

&lt;h2&gt;tags: [R, rCharts, javascript]&lt;/h2&gt;

&lt;p&gt;I have a few upcoming presentations as a part of job interviews. To prepare for these interviews, I&#39;m attempting to make my figures a bit more interactive within my presentations.  The aim is to be able to limit any large cumbersome tables I would need to include in my presentations and replace them with interactive plots that can look up values, zoom in, etc.&lt;/p&gt;

&lt;p&gt;I initially explored both &lt;a href=&quot;http://plot.ly&quot;&gt;plot.ly&lt;/a&gt; and &lt;a href=&quot;http://ramnathv.github.io/rCharts/&quot;&gt;rCharts&lt;/a&gt;, but ended up using &lt;em&gt;rCharts&lt;/em&gt; as I found I was more easily able to put it directly into my presentation.  It may be possible with &lt;em&gt;plot.ly&lt;/em&gt; but I did not want to put in the time to figure it out.  I could only find a way to link to the website for the interactive version.&lt;/p&gt;

&lt;p&gt;Using &lt;em&gt;highcharts.js&lt;/em&gt; that is integrated into &lt;em&gt;rCharts&lt;/em&gt; I was able to create the following interactive figure that explores the convergence rate of a portion of my dissertation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rCharts)

h1 &amp;lt;- hPlot(x = &quot;GenSerCor&quot;, y = &quot;percent&quot;, group = &quot;FitSerCor&quot;, data = converge)
h1$yAxis(title = list(text = &quot;Convergence Rate&quot;), min = 0, max = 100, tickInterval = 10)
h1$xAxis(title = list(text = &quot;Generated Serial Correlation Structure&quot;),
         categories = c(&quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot;))
h1$legend(verticalAlign = &quot;top&quot;, align = &quot;right&quot;, layout = &quot;vertical&quot;, title = list(text = &quot;Fitted SC&quot;))
h1$plotOptions(series = list(lineWidth = 4))
h1$print(&#39;chart1&#39;, include_assets = TRUE, cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;script type=&#39;text/javascript&#39; src=http://code.jquery.com/jquery-1.9.1.min.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/highcharts-more.js&gt;&lt;/script&gt;


&lt;script type=&#39;text/javascript&#39; src=http://code.highcharts.com/modules/exporting.js&gt;&lt;/script&gt;


&lt;p&gt;
 &lt;style&gt;
  .rChart {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 800px;
    height: 400px;
    font-size: 200%;
  }&lt;br/&gt;
  &lt;/style&gt;&lt;/p&gt;

&lt;div id = &#39;chart1&#39; class = &#39;rChart highcharts&#39;&gt;&lt;/div&gt;


&lt;script type=&#39;text/javascript&#39;&gt;
    (function($){
        $(function () {
            var chart = new Highcharts.Chart({
 &quot;dom&quot;: &quot;chart1&quot;,
&quot;width&quot;:            800,
&quot;height&quot;:            400,
&quot;credits&quot;: {
 &quot;href&quot;: null,
&quot;text&quot;: null 
},
&quot;exporting&quot;: {
 &quot;enabled&quot;: false 
},
&quot;title&quot;: {
 &quot;text&quot;: null 
},
&quot;yAxis&quot;: [
 {
 title: {
 text: &quot;Convergence Rate&quot;,
  style: {
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;30px&#39;
   }
 },
 labels: {
  formatter: function() {
   return this.value + &#39;%&#39;;
  },
  style: {
   fontSize: &#39;18px&#39;
  }
 },
&quot;min&quot;:              0,
&quot;max&quot;:            100,
&quot;tickInterval&quot;:             10 ,
minRange: 10
} 
],
&quot;series&quot;: [
 {
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
         68.38 
],
[
 &quot;AR1&quot;,
         64.88 
],
[
 &quot;MA1&quot;,
         55.12 
],
[
 &quot;MA2&quot;,
         61.98 
],
[
 &quot;ARMA&quot;,
         42.17 
] 
],
&quot;color&quot;: &quot;#e41a1c&quot;,
&quot;name&quot;: &quot;AR1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Solid&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
          65.1 
],
[
 &quot;AR1&quot;,
         60.45 
],
[
 &quot;MA1&quot;,
         63.68 
],
[
 &quot;MA2&quot;,
         54.88 
],
[
 &quot;ARMA&quot;,
          63.6 
] 
],
&quot;color&quot;: &quot;#377eb8&quot;,
&quot;name&quot;: &quot;ARMA&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
         72.48 
],
[
 &quot;AR1&quot;,
         93.88 
],
[
 &quot;MA1&quot;,
         92.23 
],
[
 &quot;MA2&quot;,
         95.62 
],
[
 &quot;ARMA&quot;,
         98.37 
] 
],
&quot;color&quot;: &quot;#4daf4a&quot;,
&quot;name&quot;: &quot;Ind&quot;,
&quot;type&quot;: null,
dashStyle: &#39;Dash&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
         71.02 
],
[
 &quot;AR1&quot;,
         81.37 
],
[
 &quot;MA1&quot;,
         69.15 
],
[
 &quot;MA2&quot;,
          84.5 
],
[
 &quot;ARMA&quot;,
         88.02 
] 
],
&quot;color&quot;: &quot;#984ea3&quot;,
&quot;name&quot;: &quot;MA1&quot;,
&quot;type&quot;: null,
dashStyle: &#39;ShortDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6
} 
},
{
 &quot;data&quot;: [
 [
 &quot;Ind&quot;,
         67.23 
],
[
 &quot;AR1&quot;,
         70.78 
],
[
 &quot;MA1&quot;,
         65.93 
],
[
 &quot;MA2&quot;,
         68.83 
],
[
 &quot;ARMA&quot;,
          72.9 
] 
],
&quot;color&quot;: &quot;#ff7f00&quot;,
&quot;name&quot;: &quot;MA2&quot;,
&quot;type&quot;: null,
dashStyle: &#39;DashDot&#39;,
&quot;marker&quot;: {
 &quot;radius&quot;:              6 
} 
} 
],
&quot;xAxis&quot;: [
 {
 title: {
 text: &quot;Generated Serial Correlation Structure&quot;,
  style:{
   fontWeight: &#39;bold&#39;,
   fontSize: &#39;30px&#39;
 }
},
labels: {
 style: {
  fontSize: &#39;18px&#39;,
  fontWeight: &#39;bold&#39;
 }
},
&quot;categories&quot;: [ &quot;Ind&quot;, &quot;AR1&quot;, &quot;MA1&quot;, &quot;MA2&quot;, &quot;ARMA&quot; ] 
} 
],
&quot;subtitle&quot;: {
 &quot;text&quot;: null 
},
&quot;legend&quot;: {
 &quot;verticalAlign&quot;: &quot;top&quot;,
&quot;align&quot;: &quot;right&quot;,
&quot;layout&quot;: &quot;vertical&quot;,
symbolWidth: 40,
&quot;title&quot;: {
 &quot;text&quot;: &quot;Fitted SC&quot; 
} 
},
&quot;plotOptions&quot;: {
 &quot;series&quot;: {
 &quot;lineWidth&quot;:              4 
} 
},
&quot;id&quot;: &quot;chart1&quot;,
&quot;chart&quot;: {
 &quot;renderTo&quot;: &quot;chart1&quot;, 
 zoomType: &quot;y&quot;,
 &quot;style&quot;: {
 fontSize: &quot;24px&quot;
 },
 resetZoomButton: {
  position: {
   align: &#39;left&#39;
  }
 }
} 
});
        });
    })(jQuery);
&lt;/script&gt;


&lt;p&gt;I edited the javascript manually to get some of the effects that I was looking for.  For example, the differing line styles and adding the ability to zoom.  It is possible to add this directly through &lt;em&gt;rCharts&lt;/em&gt;, however I found it much more cumbersome compared to editing the effects I wanted manually.  I find the &lt;em&gt;rCharts&lt;/em&gt; framework is nice to give the user the barebones needed to produce an interactive plot that can be put into an HTML slideshow.  Once getting the general structure, it is easy to look at the documentation for the javascript library and customize the plot yourself.  I personally use &lt;em&gt;slidy&lt;/em&gt; for that aspect and that is where I will use plots like this in the future.  Creating these plots has also helped me to start learning some basics of Javascript which has been on my wish list for the last year or so.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Picking a gui interface for R</title>
   <link href="http://lebebr01.github.io/2014/02/03/Rgui.html"/>
   <updated>2014-02-03T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2014/02/03/Rgui</id>
   <content type="html">&lt;p&gt;Recently I decided to switch statistical programs used introductory statistics course for masters students that I teach at the University of Arkansas.  Historically this course has been taught with SPSS, but I am attempting the switch to R this semester.  Most students in this class have never used a statistical program before and have no programming background/interest.  As a result, I did not want to have them learn statistics and the R language in the same semester and have them using R with a gui interface.  The two primary gui systems/packages I explored were the &lt;em&gt;Deducer&lt;/em&gt; package and the &lt;em&gt;Rcmdr&lt;/em&gt; package.  Here are my initial thoughts on the switch.&lt;/p&gt;

&lt;h3&gt;Which gui to use?&lt;/h3&gt;

&lt;p&gt;This ultimately comes down to personal preference, however below I&#39;ve highlighted my intial thoughts on pros/cons of each package.&lt;/p&gt;

&lt;h4&gt;Deducer&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;: &lt;br/&gt;
- Shows syntax of commands run     &lt;br/&gt;
- Uses ggplot2 for plots           &lt;br/&gt;
- Very interactive menu structures&lt;br/&gt;
- Simple condensed data loading  &lt;br/&gt;
&lt;strong&gt;Cons&lt;/strong&gt;: &lt;br/&gt;
- Uses Java &lt;br/&gt;
- Menus differ from PC to MAC &lt;br/&gt;
- rJava package can be troublesome (not exactly sure why)&lt;/p&gt;

&lt;h4&gt;Rcmdr&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;: &lt;br/&gt;
- Shows syntax of commands run      &lt;br/&gt;
- Does not use Java                &lt;br/&gt;
- Very similar data menus across each OS &lt;br/&gt;
- Opens a new window so students know when it has loaded correctly &lt;br/&gt;
&lt;strong&gt;Cons&lt;/strong&gt;: &lt;br/&gt;
- Uses base graphics &lt;br/&gt;
- Data loading structures not integrated&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In general I prefer the &lt;em&gt;Deducer&lt;/em&gt; package as it uses ggplot2 and has a more unified menu structure.  For example, there are not differing menu options for loading data like in &lt;em&gt;Rcmdr&lt;/em&gt;.  Instead, &lt;em&gt;Deducer&lt;/em&gt; has a single load data menu where it is possible to load many types of data including csv, txt, rda, etc.  This is helpful for students who are not very familiar with differing file types and I do not have to spend 5 minutes explaining it.  &lt;em&gt;Deducer&lt;/em&gt; also uses ggplot2 for its graphics which I enjoy much more than base graphics.  In my opinion they look better and the syntax is ultimately easier to create high quality graphics.&lt;/p&gt;

&lt;p&gt;My biggest complaint of the &lt;em&gt;Deducer&lt;/em&gt; package is that it uses Java.  This is one more thing that the user needs to install and with my class we have had trouble on a few computers getting the &lt;em&gt;rJava&lt;/em&gt; package to work properly.  There was also the widely talked about Java exploit that may or may not have been fixed.  Lastly, the differing look of &lt;em&gt;Deducer&lt;/em&gt; has made it more difficult for me as I need to have two explanations, one for those on a PC and another for those on a Mac.  Although they are very similar, it has been difficult for me as I do not use a Mac or have access to one for testing purposes.  Therefore, I end up figuring out differences on the fly.&lt;/p&gt;

&lt;h3&gt;Concluding thoughts&lt;/h3&gt;

&lt;p&gt;I hope to write more about my experiences using both gui systems for my class, but upon initial inspection of them now I definitely prefer &lt;em&gt;Deducer&lt;/em&gt;.  The package just has not completely won me over as little problems have made me use both packages in my class so far, primarily due to the error loading the &lt;em&gt;rJava&lt;/em&gt; package.&lt;/p&gt;

&lt;p&gt;Does anyone else have experience using one or the other in a class before?  I&#39;d enjoy hearing any stories using these or different gui systems for R.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>When I use plyr/dplyr</title>
   <link href="http://lebebr01.github.io/2014/01/24/usePlyr.html"/>
   <updated>2014-01-24T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2014/01/24/usePlyr</id>
   <content type="html">&lt;p&gt;My last post I talked about how I use the &lt;em&gt;data.table&lt;/em&gt; package for aggregating and removing duplicate observations.  Although I use the &lt;em&gt;data.table&lt;/em&gt; package quite often, there are many times when I use &lt;em&gt;plyr&lt;/em&gt; (and now the new &lt;em&gt;dplyr&lt;/em&gt;) package, primarily because of its easy, intuitive syntax.&lt;/p&gt;

&lt;h3&gt;Arrange&lt;/h3&gt;

&lt;p&gt;One of my personal favorite functions in the &lt;em&gt;plyr&lt;/em&gt; suite of basic functions is the &lt;em&gt;arrange&lt;/em&gt; function.  The base functions for sorting/ordering are more difficult to use.  Not to mention there have been many times that I have used the &lt;em&gt;base::sort&lt;/em&gt; function when I really need to use the &lt;em&gt;base::order&lt;/em&gt; function (sort to me is the word I think of first).  &lt;em&gt;arrange&lt;/em&gt; is great due to the easy, general syntax used for it as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(dplyr)
arrange(dataframe, col1, col2, col3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When using the &lt;em&gt;base::order&lt;/em&gt; function, this needs to be done through the indexing operators and is not nearly as intuitive to me.  I always have to think for a second to get it right.  Here are two general examples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;dataframe[order(dataframe$col1, dataframe$col2, dataframe$col3), ]
with(dataframe, dataframe[order(col1, col2, col3), ])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both involve much more typing and are more difficult to read the code in my opinion.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Simple, Intuitive syntax&lt;/h3&gt;

&lt;p&gt;The other aspect of the &lt;em&gt;plyr&lt;/em&gt; (and &lt;em&gt;dplyr&lt;/em&gt;) suite of functions that keeps me coming back is their simple, intuitive syntax.  For example, if I am teaching a student how to aggregate or sort, &lt;em&gt;plyr&lt;/em&gt; is my go to package.  Easy to explain, easy to understand.  The common structure across all of the functions is brilliantly programmed and a standard for everyone else to replicate.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;New! Bonus use for &lt;em&gt;dplyr&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The new ability to use the &lt;em&gt;chain&lt;/em&gt; function or alternatively the &lt;em&gt;%.%&lt;/em&gt; operator is a great addition to R.  One of the difficulties with code readability in R is the whenever functions are nested together.  By default R interprets from inside to out, not how most of us read written words let alone code.  The &lt;em&gt;chain&lt;/em&gt; function and &lt;em&gt;%.%&lt;/em&gt; operator allows the user to write the functions in the order they will be processed by R, therefore the code can read from left to right.&lt;/p&gt;

&lt;p&gt;Using the mtcars dataset, suppose we wanted to select specific columns, aggregate the miles per gallon and weight by the number of cylinders and automatic transmission status, and filter so we select the rows that have an average miles per gallon greater than 20.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(dplyr)
mtcars %.% 
  group_by(cyl, am) %.%
  select(mpg, cyl, wt, am) %.%
  summarise(avgmpg = mean(mpg), avgwt = mean(wt)) %.%
  filter(avgmpg &amp;gt; 20)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Output&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;## Source: local data frame [3 x 4]
## Groups: cyl
## 
##   cyl am avgmpg avgwt
## 1   4  0  22.90 2.935
## 2   4  1  28.07 2.042
## 3   6  1  20.57 2.755
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compare the above syntax to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;filter(
  summarise(
    select(
      group_by(mtcars, cyl, am),
      mpg, cyl, wt, am),
    avgmpg = mean(mpg), avgwt = mean(wt)),
  avgmpg &amp;gt; 20)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Output&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;## Source: local data frame [3 x 4]
## Groups: cyl
## 
##   cyl am avgmpg avgwt
## 1   4  0  22.90 2.935
## 2   4  1  28.07 2.042
## 3   6  1  20.57 2.755
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both chunks give you the same result, however the first one is much easier to see the process taken to get to the end result.  Much easier to adapt the code to add/remove parts of it.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I use both &lt;em&gt;data.table&lt;/em&gt; and &lt;em&gt;plyr&lt;/em&gt;/&lt;em&gt;dplyr&lt;/em&gt; packages.  All of these packages are a great tool for certian data problems.  If I want to write a single line of code to do a lot of manipulations I will tend to use &lt;em&gt;data.table&lt;/em&gt;.  However, if I am writing code where I am doing more exploration or if I am collaborating with others I tend to write my code using &lt;em&gt;plyr&lt;/em&gt;/&lt;em&gt;dplyr&lt;/em&gt;.  The versatility that both packages bring together in tandem is an excellent and powerful combination.  I do not have time to be a complete package elitest, the correct tool for the right data problem is the best solution for me.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Two of my favorite data.table features</title>
   <link href="http://lebebr01.github.io/2014/01/06/FavDataTable.html"/>
   <updated>2014-01-06T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2014/01/06/FavDataTable</id>
   <content type="html">&lt;p&gt;When I started to use the &lt;em&gt;data.table&lt;/em&gt; package I was primarily using it to aggregate.  I had read about &lt;em&gt;data.table&lt;/em&gt; and its blazing speed compared to the other options from base or the &lt;em&gt;plyr&lt;/em&gt; package especially with large amounts of data.  As an example, I remember calculating averages or percentages while at Saint Paul Public Schools and while the calculations were running would walk away for 5 minutes to wait for them to finish.  When using &lt;em&gt;data.table&lt;/em&gt; to do the same calculations I didn&#39;t need to wait 5 minutes to see the calculated values.&lt;/p&gt;

&lt;p&gt;The speed of &lt;em&gt;data.table&lt;/em&gt; is publicized widely, however there are two features found in &lt;em&gt;data.table&lt;/em&gt; that are not talked about as frequently that I use very often.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Add aggregated variables to the raw data file&lt;/h2&gt;

&lt;p&gt;The ability to add aggregated variables to the raw data file can be very helpful in numerous data situations.  At Saint Paul Public Schools I used this feature to give differing levels of data to external clients requesting data.  I also used this feature when creating graphics.  Outside of the district world, this feature is extremely helpful when fitting linear mixed models with &lt;em&gt;lme4&lt;/em&gt; or &lt;em&gt;nlme&lt;/em&gt;.  Adding aggregated variables is needed if you want to add variables at any of the cluster levels (unless you calculate them on the fly with the &lt;strong&gt;I()&lt;/strong&gt; command).  Instead of creating a set of aggregated variables in a new data frame and merging back in, &lt;em&gt;data.table&lt;/em&gt; allows you to do it one one command.  Here is a small example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# generate a small dataset
set.seed(1234)
smalldat &amp;lt;- data.frame(group1 = rep(1:2, each = 5), 
                       group2 = rep(c(&#39;a&#39;,&#39;b&#39;), times = 5), 
                       x = rnorm(10))

# convert to data.frame to data.table
library(data.table)
smalldat &amp;lt;- data.table(smalldat)

# convert aggregated variable into raw data file
smalldat[, aggGroup1 := mean(x), by = group1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Output&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;##     group1 group2       x aggGroup1
##  1:      1      a -1.2071   -0.3524
##  2:      1      b  0.2774   -0.3524
##  3:      1      a  1.0844   -0.3524
##  4:      1      b -2.3457   -0.3524
##  5:      1      a  0.4291   -0.3524
##  6:      2      b  0.5061   -0.4140
##  7:      2      a -0.5747   -0.4140
##  8:      2      b -0.5466   -0.4140
##  9:      2      a -0.5645   -0.4140
## 10:      2      b -0.8900   -0.4140
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# aggregate with 2 variables
smalldat[, aggGroup1.2 := mean(x), by = list(group1, group2)]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Output&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;##     group1 group2       x aggGroup1 aggGroup1.2
##  1:      1      a -1.2071   -0.3524      0.1022
##  2:      1      b  0.2774   -0.3524     -1.0341
##  3:      1      a  1.0844   -0.3524      0.1022
##  4:      1      b -2.3457   -0.3524     -1.0341
##  5:      1      a  0.4291   -0.3524      0.1022
##  6:      2      b  0.5061   -0.4140     -0.3102
##  7:      2      a -0.5747   -0.4140     -0.5696
##  8:      2      b -0.5466   -0.4140     -0.3102
##  9:      2      a -0.5645   -0.4140     -0.5696
## 10:      2      b -0.8900   -0.4140     -0.3102
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key part of the syntax is the &lt;strong&gt;:=&lt;/strong&gt;, which tells &lt;em&gt;data.table&lt;/em&gt; to compute an aggregated variable and merge it back into the original data.  This is very compact syntax to create aggregated variables that are automatically placed within the original data.  The only drawback is the inability to create more than one aggregated variable at a time.  If I wanted to created the mean and the median of x for each level of the variable &lt;em&gt;group1&lt;/em&gt;, I would have to write two commands.  If a lot of variables need to be aggregated in this fashion, it may be more concise to create an aggregated data set and merge back into the original.  Below is an example of what I mean by aggregate then merge back:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(plyr)

# create aggregated data
aggdat1 &amp;lt;- ddply(smalldat, .(group1), summarize,
                 aggGroup1plyr = mean(x))
aggdat12 &amp;lt;- ddply(smalldat, .(group1, group2), summarize, 
                aggGroup1.1plyr = mean(x))

# join back into data
smalldat &amp;lt;- join(smalldat, aggdat1, by = &#39;group1&#39;)
smalldat &amp;lt;- join(smalldat, aggdat12, by = c(&#39;group1&#39;, &#39;group2&#39;))

# print data
smalldat
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Output&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;##     group1 group2       x aggGroup1 aggGroup1.2 aggGroup1plyr
##  1:      1      a -1.2071   -0.3524      0.1022       -0.3524
##  2:      1      b  0.2774   -0.3524     -1.0341       -0.3524
##  3:      1      a  1.0844   -0.3524      0.1022       -0.3524
##  4:      1      b -2.3457   -0.3524     -1.0341       -0.3524
##  5:      1      a  0.4291   -0.3524      0.1022       -0.3524
##  6:      2      b  0.5061   -0.4140     -0.3102       -0.4140
##  7:      2      a -0.5747   -0.4140     -0.5696       -0.4140
##  8:      2      b -0.5466   -0.4140     -0.3102       -0.4140
##  9:      2      a -0.5645   -0.4140     -0.5696       -0.4140
## 10:      2      b -0.8900   -0.4140     -0.3102       -0.4140
##     aggGroup1.1plyr
##  1:          0.1022
##  2:         -1.0341
##  3:          0.1022
##  4:         -1.0341
##  5:          0.1022
##  6:         -0.3102
##  7:         -0.5696
##  8:         -0.3102
##  9:         -0.5696
## 10:         -0.3102
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code using plyr likely won&#39;t take longer for R to run, however it does take more time to write out the code.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Removing duplicate observations&lt;/h2&gt;

&lt;p&gt;For most situations, using &lt;em&gt;data.table&lt;/em&gt; has become my go to way to remove duplicate observations.  This is especially useful when it does not matter which value of the variables you want to keep in the final data set (e.g. when values of the variables are repeated).  The ability of &lt;em&gt;data.table&lt;/em&gt; to create keyed values makes it extremely easy to remove duplicate observations based on those keyed variables.&lt;/p&gt;

&lt;p&gt;Using the dataset created above:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Set keys - this sorts the data based on these values
setkeyv(smalldat, c(&#39;group1&#39;,&#39;group2&#39;))

# keep unique observations (I also remove the variable x)
uniqdat &amp;lt;- subset(unique(smalldat), select = -x)

# print data
uniqdat
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;##    group1 group2 aggGroup1 aggGroup1.2 aggGroup1plyr aggGroup1.1plyr
## 1:      1      a   -0.3524      0.1022       -0.3524          0.1022
## 2:      1      b   -0.3524     -1.0341       -0.3524         -1.0341
## 3:      2      a   -0.4140     -0.5696       -0.4140         -0.5696
## 4:      2      b   -0.4140     -0.3102       -0.4140         -0.3102
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code above first sets two keys for the data.table.  The key acts as an identifier and the data are automatically sorted based on the key variables.  This is one of the reasons why the &lt;em&gt;data.table&lt;/em&gt; package can be so fast at doing many of its tasks.  Then unique observations are kept.  The &lt;em&gt;unique&lt;/em&gt; function in the &lt;em&gt;data.table&lt;/em&gt; package is similar to the same function in the base package, but when keys are defined for data.table, the &lt;em&gt;unique&lt;/em&gt; function automatically selects unique observations based on those key variables.&lt;/p&gt;

&lt;p&gt;For more complicated cases, I tend to use a combination of &lt;em&gt;order&lt;/em&gt; and &lt;em&gt;duplicated&lt;/em&gt; from base R, however for easy cases where observations are repeated on the variables I want to keep, this is a quick and easy way to remove duplicate observations.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Guessing Correlations&#58; A shiny app</title>
   <link href="http://lebebr01.github.io/2013/12/30/guessCorr.html"/>
   <updated>2013-12-30T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2013/12/30/guessCorr</id>
   <content type="html">&lt;p&gt;A recent hobby of mine (as with many other R users) is to play around with the relatively new R package: &lt;em&gt;shiny&lt;/em&gt;.  I started creating demo applications about a year ago just to figure out how powerful the platform could be, but it was not until this fall that I started creating some applications for others to use.&lt;/p&gt;

&lt;p&gt;I encountered a problem this fall at the University of Arkansas due to the huge Java exploit going public.  As a result of this, Java was blocked on all of the computers in the classrooms that I used for my intro statistics courses.  Most days this does not impact my lectures, however on a few days throughout the semester I use applets to help show certain concepts.&lt;/p&gt;

&lt;p&gt;Enter my solution, create shiny applications that attempts to mimic many of the same features found in the Java applets using &lt;em&gt;shiny&lt;/em&gt;.  The application I&#39;ve been working on lately is an application that allows users to estimate the correlation based on a scatterplot of data.&lt;/p&gt;

&lt;p&gt;You can run the shiny application from my github page using the following command (make sure you have the shiny package installed first:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(repo = &quot;shinyApps&quot;, username = &quot;lebebr01&quot;, subdir = &quot;guessCorr&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should open a session in your browser that looks like the following screenshot:
&lt;img src=&quot;http://educate-r.org/figs/GuessingCorrelations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see from this screenshot, there is a scatterplot in the main window and the user inputs a guess into the text box.  When they hit the &#39;Submit Guess&#39; button, the grey panel above the scatterplot updates to give hints about the direction the correlation is compared to the guess.  Once the user is within .05 (.05 above or below) the correlation, the correlation is printed in the top text box.&lt;/p&gt;

&lt;p&gt;The app also includes the ability to restrict the range of the scatterplot.  This can be seen in the image below (and can be done on the app by clicking the &#39;Restriction of Range&#39; checkbox):
&lt;img src=&quot;http://educate-r.org/figs/GuessingCorrelationsRR.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When that checkbox is clicked, a new slider shows up that restricts the range of the original scatterplot.  The data that lies outside of the restricted range shows up as a light grey in the updated graph.  Now the user attempts to guess the correlation for the restricted range data.  The correlation for the entire data can be seen in the graph.&lt;/p&gt;

&lt;p&gt;The one thing I was unable to implement was a second button that allows the user to click it to refresh the data to guess at another correlation.  The &#39;Submit Button&#39; in &lt;em&gt;shiny&lt;/em&gt; is too cumbersome and I could not get two &#39;Action Buttons&#39; to work side by side, although this may be possible.  The current workaround is to just refresh the page and a new scatterplot will load.  Alternatively, when using the restriction of range feature, changing the range will also generate new data.  Lastly, adding the option for a counter as an indication of how well the user is doing could make it an interesting contest in the classroom.&lt;/p&gt;

&lt;p&gt;Enjoy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>SPSS to R&#58; An R package to convert SPSS syntax</title>
   <link href="http://lebebr01.github.io/2013/11/26/SPSStoR.html"/>
   <updated>2013-11-26T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2013/11/26/SPSStoR</id>
   <content type="html">&lt;p&gt;My first statistical software package I used as an undergrad was SPSS.  I was fortunate during my senior year at &lt;a href=&quot;http://www.luther.edu&quot;&gt;Luther College&lt;/a&gt; to be initially introduced to &lt;a href=&quot;http://r-project.org&quot;&gt;R&lt;/a&gt;.  I did not realize it at the time (except for the pretty graphics) that this was the start of something big for me.  Fast forward a year to graduate school at the University of Minnesota and the majority of my program was again using SPSS.  Under the tutelage of &lt;a href=&quot;http://www.cehd.umn.edu/edpsych/people/Faculty/Zieffler.html&quot;&gt;Andy&lt;/a&gt; in my first graduate statistics course I started to do analyses in both R and SPSS.  After that I started to do all my analyses in R.  Fast forward five years this time to my first full-time job after graduate school at &lt;a href=&quot;http://www.spps.org&quot;&gt;Saint Paul Public Schools&lt;/a&gt; and again everyone was using SPSS.  Fortunately in my year there I was able to significantly push them toward using R more and more.&lt;/p&gt;

&lt;p&gt;This long introduction motivates the following package I started writing mostly just to play with regular expressions, but kept playing and came up with a package with many routines.  The package I came up with is called &lt;em&gt;SPSStoR&lt;/em&gt; which converts SPSS syntax into R syntax.  Using regular expressions to parse the SPSS syntax to figure out which routine is being run then prints out the R syntax to do the same analysis done by the SPSS syntax.&lt;/p&gt;

&lt;p&gt;As you can imagine, the SPSS language has many routines and this is not all encompassing, however it provides many basic commands such as:
* Aggregate
* Correlations
* Crosstab
* Sort Cases
* Descriptives
* One sample t-test
* Independent sample t-test
* Get for sav files (SPSS data files)
* Master SPSStoR function
* Graphics
* Frequencies&lt;/p&gt;

&lt;h1&gt;Examples&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;You can install the package directly from my github page using the devtools library:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(&quot;SPSStoR&quot;, &quot;lebebr01&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you install the package, I&#39;ve included some example SPSS syntax within the package to use as examples.  One example syntax file reads in an SPSS data file, sorts the file, then computes descriptive statistics on a handful of variables.  The following should run the command from your computer:
&lt;code&gt;r
library(SPSStoR)
file &amp;lt;- paste(system.file(&#39;SPSSsyntax&#39;, package = &#39;SPSStoR&#39;),
              &quot;/getDescExamp.txt&quot;, sep = &#39;&#39;)
spss_to_r(file)
&lt;/code&gt;&lt;/p&gt;

&lt;h3&gt;Output:&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;[1] &quot;# x is the name of your data frame&quot;
[2] &quot;library(foreign)&quot;
[3] &quot;x &amp;lt;- read.spss(&#39;/data/hubtemp.sav&#39;, to.data.frame = TRUE)&quot;
[4] &quot;x &amp;lt;- x[order(DIVISION, STORE, -AGE), ]&quot;
[5] &quot;library(SPSStoR)&quot;
[6] &quot;with(x, descmat(x = list(longmon, tollmon, equipmon, cardmon, wiremon), mean, sd, min, max))&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is another example doing a one-sample t-test:
&lt;code&gt;r
file &amp;lt;- paste(system.file(&#39;SPSSsyntax&#39;, package = &#39;SPSStoR&#39;),
              &quot;/ttestOneSampExamp.txt&quot;, sep = &#39;&#39;)
spss_to_r(file)
&lt;/code&gt;&lt;/p&gt;

&lt;h3&gt;Output:&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;[1] &quot;# x is the name of your data frame&quot;
[2] &quot;with(x, t.test(brake, mu = 322, conf.level = .90)&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;Summary&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Although some working R knowledge is needed to run this package, such as knowledge of installing packages and what an object is, this package may be useful to those trying to figure out a similar command in R.  Over time I hope to slowly add support for more SPSS routines, see my github page for those that I am currently prioritizing.  Let me know via the issues on github if you&#39;d like support for a specific routine or run into problems.&lt;/p&gt;

&lt;p&gt;The package home can be found on github: &lt;a href=&quot;https://github.com/lebebr01/SPSStoR&quot;&gt;SPSStoR&lt;/a&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>My Course Slide Generation</title>
   <link href="http://lebebr01.github.io/2013/11/18/CourseSlidesProcess.html"/>
   <updated>2013-11-18T00:00:00-06:00</updated>
   <id>http://lebebr01.github.io/2013/11/18/CourseSlidesProcess</id>
   <content type="html">&lt;p&gt;This past August I took an opportunity to step back into the University academic world as a &lt;a href=&quot;http://http://coehp.uark.edu/12216.php&quot;&gt;Visiting Assistant Professor&lt;/a&gt; at the &lt;a href=&quot;http://www.uark.edu&quot;&gt;University of Arkansas&lt;/a&gt;.  I have enjoyed the transition back into the academic world, including a more flexible schedule, variation in topics/duties, and collaborating with colleagues.&lt;/p&gt;

&lt;p&gt;However, there has been some growing pains, especially regarding creating my own slides for the courses I teach.  Although I am using the same books/curriculum used in previous semesters, I am making my own slides and adding my own pieces as I see fit.  In addition, I do not use powerpoint, which all of the existing slides are in.  Therefore, I am creating my own versions of the slides using a combination of &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt;, &lt;a href=&quot;http://yihui.name/knitr/&quot;&gt;knitr&lt;/a&gt;, &lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot;&gt;markdown&lt;/a&gt;, &lt;a href=&quot;http://johnmacfarlane.net/pandoc/&quot;&gt;pandoc&lt;/a&gt;, &lt;a href=&quot;http://www.w3.org/Talks/Tools/Slidy2/&quot;&gt;slidy&lt;/a&gt;, and &lt;a href=&quot;http://www.latex-project.org/&quot;&gt;LaTeX&lt;/a&gt;.  Below is my general process of making my slides and the slides I put online for students to have access to.&lt;/p&gt;

&lt;h2&gt;Step 1 - Create Source File&lt;/h2&gt;

&lt;p&gt;I start with a &lt;em&gt;Rmd&lt;/em&gt; file.  This allows me to embed R code into the source document.  This is particularly useful for me to include plots of distributions, graphically showing how ANOVA works, etc.  Once I am finished editing my &lt;em&gt;Rmd&lt;/em&gt;, if I am using &lt;a href=&quot;http://www.rstudio.com/&quot;&gt;Rstudio&lt;/a&gt; I just use the &lt;em&gt;Knit HTML&lt;/em&gt; button to automatically generate the markdown and HTML file for me.  Alternatively, the &lt;em&gt;knit&lt;/em&gt; command from the &lt;strong&gt;knitr&lt;/strong&gt; package will create the markdown file for you (but not the HTML file, although for me the HTML file is not needed in this step).  The defaults of the &lt;em&gt;knit&lt;/em&gt; command work fine for me.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;knit(input = &quot;/path/to/file.Rmd&quot;, output = &quot;/path/to/file.md&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Step 2 - Create HTML Presentation&lt;/h2&gt;

&lt;p&gt;Once we have the markdown file, I now use pandoc to create my HTML presentation.  There are a few ways to create HTML presentation slides, but I personally like slidy the best.  I like slidy because it easily fills the whole screen and also allows for content to go over the edges of the slide.  If content goes outside of the edges of a single slide, you can scroll to see the missing content.  I find this useful if I want to blow up an image or have two plots where I can show one then scroll to the second.  The pandoc command I use looks something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;pandoc -s --mathjax -i -t slidy inputfile.md -o outfile.html
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Step 3 (Optional) - Edit CSS for HTML Presentation&lt;/h2&gt;

&lt;p&gt;I use a custom CSS file to style my HTML presentation so it uses some of the official colors from the University of Arkansas.  For example, my header titles use the Arkansas red.  To use a custom CSS file, you just need to find the line that mentions CSS in the HTML file and change it to reflect your custom file.  The defaults look good, although perhaps slightly bland.&lt;/p&gt;

&lt;h2&gt;Step 4 - Create pdf slides&lt;/h2&gt;

&lt;p&gt;I then create a different set of slides using LaTeX that I post on the blackboard site for each of my courses.  Pandoc is how I get the &lt;em&gt;tex&lt;/em&gt; file to compile with LaTeX.  The command is very simple:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;pandoc -s inputfile.md -o outfile.tex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two things I change, I make sure the base text size is 12 pt.  I also make sure to use the &lt;em&gt;float&lt;/em&gt; package and change any figure positions from &lt;em&gt;htbp&lt;/em&gt; to &lt;em&gt;H&lt;/em&gt; which forces the figures to stay in position and not float around.  Then I compile the resulting &lt;em&gt;tex&lt;/em&gt; using Rstudio or from the command line with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;pdflatex -interaction=nonstopmode -synctex=1 outfile.tex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my opinion this creates great looking html presentations that are highly customizable.  One thing to note is that by default to get the slideshow, you need to be connected to the internet.  Both &lt;strong&gt;slidy&lt;/strong&gt; and &lt;strong&gt;mathjax&lt;/strong&gt; refer to javascript files that are on downloaded directly from the web.  You should be able to download these files, store them locally, and refer to the local versions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Formatting Markdown Tables with R</title>
   <link href="http://lebebr01.github.io/2013/11/01/CondFormatMarkdown.html"/>
   <updated>2013-11-01T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2013/11/01/CondFormatMarkdown</id>
   <content type="html">&lt;p&gt;This past summer when the &lt;a href=&quot;http://www.meetup.com/twincitiesrug/&quot;&gt;twin cities R user group&lt;/a&gt; was starting to get back up and running, I offered to present on some R related things that I was working on.  One thing I was working on was a part of my last &lt;a href=&quot;http://http://educate-r.org/2013/09/28/ConditionalFormat/&quot;&gt;post&lt;/a&gt;.  In a response to discussing this during a meeting, I was posed with the problem of how to do this with a markdown table.  I replied I was unsure how to do this directly with R, but it could likely be possible.&lt;/p&gt;

&lt;p&gt;After replying to this e-mail, I went to work thinking about how this could be done.  I knew you could add some CSS to the resulting HTML file, but the question remained how could this be done succintly and with conditional formatting.&lt;/p&gt;

&lt;p&gt;The resulting thought process led me to create the &lt;strong&gt;&lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;&lt;/strong&gt; which post processes the HTML file to inject some CSS into the HTML file.  Here is a simple example to get you started.&lt;/p&gt;

&lt;p&gt;First you have a table written in markdown that looks like the following:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number   &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt; 5        &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt; 35       &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt; 100      &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt; 200      &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;Now suppose we want to turn the background color of those less than 5 to blue, and those greater than 100 to red.  To do this using the &lt;strong&gt;highlightHTML&lt;/strong&gt; package, the table would change to this:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number     &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt; 5  #bgblue &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt; 35         &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt; 100        &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt; 200 #bgred &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;The addition of the &#39;#bgblue&#39; and &#39;#bgred&#39; tags indicate which cells to change and will also define new id values to assign directly to these cells through CSS.  After adding the tags to the cells to format and converting the markdown file to HTML, it is now time to run the &lt;em&gt;highlightHTMLcells&lt;/em&gt; command within R.  This command will remove the tags from the table, inject CSS into the resulting HTML document, and assign the id to the specific cells.  Below are the commands needed to install the package and post-process the file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(repo = &quot;highlightHTML&quot;, username = &quot;lebebr01&quot;)
library(highlightHTML)
tags &amp;lt;- c(&quot;#bgred {background-color: #FF0000;}&quot;, &quot;#bgblue {background-color: #0000FF;}&quot;)
highlightHTMLcells(input = &quot;path/to/file&quot;, output = &quot;path/to/saved/file&quot;, updateCSS = TRUE, 
    tags = tags)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This results in an HTML table that looks like the following:&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Color Name&lt;/th&gt;
&lt;th&gt;Number&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Blue&lt;/td&gt;
&lt;td id=&#39;bgblue&#39;&gt;5 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Green&lt;/td&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Orange&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Red&lt;/td&gt;
&lt;td id=&#39;bgred&#39;&gt;200&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;More explanation of the &lt;em&gt;highlightHTMLcells&lt;/em&gt; command, the input argument is the location of the pre-processed HTML file, the output argument is the place the post-processed HTML file is saved (note: if no output argument is given, it will overwrite the input file), the updateCSS argument tells the function whether to inject the CSS or not, finally the tags argument is a vector of the CSS that will be injected into the post-processed HTML file.  The last argument highlights a drawback of the package in it&#39;s current state, the user must know some CSS to tell the function what to inject into the HTML file.  On the one hand, CSS is not overly difficult to learn, but some default behavior would be nice.  I hope to add this in the future.&lt;/p&gt;

&lt;p&gt;There you have it, a way to add some formatting to a table written in markdown and being presented in HTML.  Future additions will hopefully add the conditional part into the mix as well.  Stay tuned.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Conditional Formatting Tables using R</title>
   <link href="http://lebebr01.github.io/2013/09/28/ConditionalFormat.html"/>
   <updated>2013-09-28T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2013/09/28/ConditionalFormat</id>
   <content type="html">&lt;p&gt;One thing that I had the opportunity to develop while working last year at &lt;a href=&quot;http://spps.org/&quot;&gt;Saint Paul Public Schools&lt;/a&gt; was figuring out a quick, easy, and painless way to do interactive report generation.  When I arrived in the REA department at Saint Paul Public Schools, the report generation process was roughly as follows:&lt;br/&gt;
1. Do the analysis in SPSS (compute percent proficient for standard tests by various subgroups).&lt;br/&gt;
2. Format output and copy output into Excel.&lt;br/&gt;
3. Once in Excel, do lookup tables to generate the report in Excel.&lt;/p&gt;

&lt;p&gt;This process provided a few areas that could introduce errors.  The copying from SPSS into Excel could produce errors and the lookup formula&#39;s in Excel can be tricky.  The correct columns need to be specified in the correct destination on another sheet.&lt;/p&gt;

&lt;p&gt;One of the largest pushes in a school district is to receive the district&#39;s test score results and quickly as possible.  I felt that I could create an interactive report through the use of &lt;em&gt;R&lt;/em&gt; and &lt;em&gt;LaTeX&lt;/em&gt; that would greatly enhance the workflow and speed of report generation.&lt;/p&gt;

&lt;p&gt;My process involved creating R script files for each report and export the tables for the reports as &lt;em&gt;.tex&lt;/em&gt; files.  The &lt;em&gt;.tex&lt;/em&gt; files were created using the &lt;em&gt;Hmisc&lt;/em&gt; R package, more specifically the &lt;em&gt;latex&lt;/em&gt; function.  The &lt;em&gt;latex&lt;/em&gt; function is great as it offers a lot of control over the output of the resulting &lt;em&gt;.tex&lt;/em&gt; table file.  One thing you can do is conditional formatting of the table, see this document for a more thorough explanation: &lt;a href=&quot;http://biostat.mc.vanderbilt.edu/twiki/pub/Main/StatReport/latexFineControl.pdf&quot;&gt;conditional formatting with the latex function&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is a small minimal example.  In the example, suppose we want to calculate the average Melanoma thickness by the status of the person (i.e. did they die from Melanoma, still alive, or died from other causes).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(MASS)   # Load for Melanoma Data
library(Hmisc)  # Load for latex function
library(data.table)  # Used for aggregating

mela &amp;lt;- data.table(Melanoma)

# Aggregating
mela.status &amp;lt;- mela[, list(avgThick = mean(thickness)), by = status]

# Conditional formatting
cellTex &amp;lt;- matrix(rep(&quot;&quot;, NROW(mela.status) * NCOL(mela.status)),
                  nrow = NROW(mela.status))
cellTex[,1] &amp;lt;- ifelse(mela.status$avgThick &amp;gt; 4, &quot;cellcolor{red}&quot;,
                  ifelse(mela.status$avgThick &amp;lt; 3, &quot;cellcolor{green}&quot;,
                         &quot;&quot;))

# Shading alternate rows
my.rownamesTexCmd &amp;lt;- rep(&quot;&quot;, nrow(mela.status))
index &amp;lt;- (1:nrow(mela.status)/2) == (1:nrow(mela.status)%/%2)
my.rownamesTexCmd[index] &amp;lt;- &quot;shadeRow&quot;

# Creating the .tex file
# Note, this is currently printed in R console
latex(round(mela.status, 2), title = &#39;&#39;, file = &#39;&#39;, booktabs = TRUE, 
      rownamesTexCmd = my.rownamesTexCmd, cellTexCmds = cellTex,
      rowname = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is the resulting &lt;em&gt;LaTeX&lt;/em&gt; code that is created from the &lt;em&gt;latex&lt;/em&gt; function. The conditional formatting is the &lt;em&gt;\cellcolor{}&lt;/em&gt; commands.  You need to ensure that the color is defined, either as a default color or one you define in the preamble.  Secondly, the \shadeRow command will shade that row and you need to ensure you have the first line below in your preamble.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;latex&quot;&gt;% Including a similar command in your preamble to define row shading.
\providecommand{\shadeRow}{\rowcolor[rgb]{0, 0.99, 0}}
% 
% 
\begin{table}[!tbp]
\begin{center}
\begin{tabular}{rr}
\toprule
\multicolumn{1}{c}{status}&amp;amp;\multicolumn{1}{c}{avgThick}\tabularnewline
\midrule
 $3$&amp;amp;   $3.72$\tabularnewline
\shadeRow   $2$&amp;amp;\cellcolor{green}   $2.24$\tabularnewline
  $1$&amp;amp;\cellcolor{red}   $4.31$\tabularnewline
\bottomrule
\end{tabular}
\end{center}
\end{table}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Blog Logo</title>
   <link href="http://lebebr01.github.io/2013/09/11/BlogLogo.html"/>
   <updated>2013-09-11T00:00:00-05:00</updated>
   <id>http://lebebr01.github.io/2013/09/11/BlogLogo</id>
   <content type="html">&lt;p&gt;Welcome to my new website/blog.  I am aiming to highlight some of the R packages that I have created.  You can see a list of all the R packages I have in development and also see the source code on github here: &lt;a href=&quot;http://educate-r.org/projects.html&quot;&gt;R packages&lt;/a&gt;.  In addition, I&#39;ll likely talk about various topics with statistics, teaching, research, or R in general.&lt;/p&gt;

&lt;p&gt;For my first post, I want to highlight my code to generate my blog logo.  The code took a lot of trial and error and definitely is dependent on the size of the image file that is outputted.  By far the most difficult part of the logo was the R logo, specifically the grey oval of the R logo.  I tried to get the oval to change sizes at the correct point and to do this I created a size variable in my data.frame and passed this variable to &lt;strong&gt;ggplot2&lt;/strong&gt; to make the size change.  It isn&#39;t perfect, but is a bit unique.&lt;/p&gt;

&lt;p&gt;The next logo I need to develop is my favicon.ico.  Send me suggestions in the comments of this post.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;### Creating words with connected points.
capE &amp;lt;- data.frame(x = c(1.5,1,1,1.25,1,1,1.5), 
                   y = c(3,3,2,2,2,1,1))
capE$time &amp;lt;- 1:nrow(capE)

letd &amp;lt;- data.frame(x = c(2, 1.75, 1.65, 1.75, 2, 2), 
                   y = c(2,2,1.5,1,1,2.5))
letd$time &amp;lt;- 1:nrow(letd)

letu &amp;lt;- data.frame(x = c(2.2, 2.2, 2.35, 2.55, 2.55, 2.55), 
                   y = c(2,1.15,1,1.15,2,1))
letu$time &amp;lt;- 1:nrow(letu)

letc &amp;lt;- data.frame(x = c(3.05, 2.8, 2.7, 2.8, 3.05), 
                   y = c(2,2,1.5,1,1))
letc$time &amp;lt;- 1:nrow(letc)

leta &amp;lt;- data.frame(x = c(3.55, 3.35, 3.2, 3.35, 3.55, 3.55, 3.55), 
                   y = c(1.85, 2, 1.5, 1, 1.15, 1.85, 1))
leta$time &amp;lt;- 1:nrow(leta)

lett &amp;lt;- data.frame(x = c(3.75, 3.75, 3.575, 3.925, 3.75, 3.75), 
                   y = c(2.5, 2.25, 2.25, 2.25, 2.25, 1))
lett$time &amp;lt;- 1:nrow(lett)

lete &amp;lt;- data.frame(x = c(4.3, 4.05, 3.95, 4.125, 4.3, 4.125, 3.95), 
                   y = c(1.05, 1, 1.75, 2, 1.75, 1.6, 1.75))
lete$time &amp;lt;- 1:nrow(lete)

rlogo &amp;lt;- data.frame(x = c(5.1, 5.1, 5.3, 5.4, 5.45, 5.4, 5.3, 5.1, 5.2,
                          5.25, 5.35, 5.45),
                    y = c(.5, 2, 2, 1.85, 1.675, 1.4, 1.25, 1.25, 1.25,
                          1.2, 1.05, .5))
rlogo$time &amp;lt;- 1:nrow(rlogo)

rcirclogo &amp;lt;- data.frame(x = c(5.6, 5.6, 5.55, 5.45, 5.35, 5.25, 5.15,
                              5.05, 4.95, 4.85,4.75,  4.75, 4.75,
                              4.8, 4.95, 5.05, 5.15, 5.25, 5.35, 5.45,
                              5.55, 5.6, 5.6),
                        y= c(1.65, 1.8, 2, 2.15, 2.25, 2.3, 2.3, 2.25,
                             2.15, 2.05, 1.85, 1.7, 1.55, 
                             1.35, 1.15, 1.05, .95, .95, 1.05, 1.15,
                             1.35, 1.55, 1.65),
                        size = c(2.25, 2.75, 3, 3.5, 4, 4, 4.5, 5, 5,
                                 5, 5, 5, 5, 4.5, 4, 3.75, 3.25, 3,
                                 2.75, 2.5, 2.25, 2.25, 2))
rcirclogo$time &amp;lt;- 1:nrow(rcirclogo)



library(ggplot2)
library(scales)

p &amp;lt;- ggplot(capE, aes(x = x, y = y)) + theme_bw()
p + geom_path(lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = letd, lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = letu, lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = letc, lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = leta, lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = lett,lwd = 3, lineend = &quot;round&quot;) + 
  geom_path(data = lete, lwd = 3, lineend = &quot;round&quot;) +
  geom_path(data = rcirclogo, aes(size = size), color = &quot;grey&quot;, 
            lineend = &quot;round&quot;, linejoin = &quot;bevel&quot;) + 
  geom_path(data = rlogo, color = &quot;steelblue&quot;, lwd = 6, 
            lineend = &quot;round&quot;) + 
  geom_path(data = rlogo, color = &quot;grey60&quot;, lwd = .5, 
            lineend= &quot;round&quot;) +
  theme(legend.position = &quot;none&quot;, text = element_blank(), 
        panel.grid = element_blank(),
        plot.background = element_rect(fill = &quot;transparent&quot;, 
                                       color = NA),
        panel.background = element_rect(fill = &quot;transparent&quot;, 
                                        color = NA),
        panel.border = element_blank(),
        axis.line = element_blank(), axis.ticks = element_blank(),
        line = element_blank()) + scale_size(range = c(2, 8))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/logo.png&quot; alt=&quot;plot of chunk logo&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 

</feed>
