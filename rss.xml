<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Educate-R</title>
		<description>R and data miscellany</description>
		<link>http://educate-r.org</link>
		<atom:link href="http://educate-r.org/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Simulation and power analysis of generalized linear mixed models</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Simulation and power analysis of generalized linear mixed models&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;(G)LMMs&lt;/li&gt;
&lt;li&gt;Power&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Demo Shiny App!
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linear Mixed Model (LMM)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/equations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is the ability to statistically detect a true effect (i.e. non-zero population effect).&lt;/li&gt;
&lt;li&gt;For simple models (e.g. t-tests, regression) there are closed form equations for generating power.

&lt;ul&gt;
&lt;li&gt;R has routines for these: &lt;code&gt;power.t.test, power.anova.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gpower3
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Example&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;n &amp;lt;- seq(4, 1000, 2)
power &amp;lt;- sapply(seq_along(n), function(i) 
  power.t.test(n = n[i], delta = .15, sd = 1, type = &#39;two.sample&#39;)$power)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/power_plot-1.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power for (G)LMM&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power for more complex models is not as straightforward;

&lt;ul&gt;
&lt;li&gt;particularly with messy real world data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There is software for the GLMM models to generate power:

&lt;ul&gt;
&lt;li&gt;Optimal Design: &lt;a href=&quot;http://hlmsoft.net/od/&quot;&gt;http://hlmsoft.net/od/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLPowSim: &lt;a href=&quot;http://www.bristol.ac.uk/cmm/software/mlpowsim/&quot;&gt;http://www.bristol.ac.uk/cmm/software/mlpowsim/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Snijders, &lt;em&gt;Power and Sample Size in Multilevel Linear Models&lt;/em&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is hard&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In practice, power is hard.&lt;/li&gt;
&lt;li&gt;Need to make many assumptions on data that has not been collected.

&lt;ul&gt;
&lt;li&gt;Therefore, data assumptions made for power computations will likely differ from collected sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A power analysis needs to be flexible, exploratory, and well thought out.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; Overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; aims to simulate (G)LMMs with up to three levels of nesting (aim to add more later).&lt;/li&gt;
&lt;li&gt;Flexible data generation allows:

&lt;ul&gt;
&lt;li&gt;any number of covariates and discrete covariates&lt;/li&gt;
&lt;li&gt;change random distribution&lt;/li&gt;
&lt;li&gt;unbalanced data&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;li&gt;serial correlation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Also has routines to generate power.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Demo Shiny App&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(&#39;simglm&#39;, username = &#39;lebebr01&#39;, subdir = &#39;inst/shiny_examples/demo&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
library(simglm)
run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Must have following packages installed: &lt;code&gt;simglm, shiny, shinydashboard, ggplot2, lme4, DT&lt;/code&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/06/29/user2016.html&quot;&gt;http://educate-r.org/2016/06/29/user2016.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01&quot;&gt;http://github.com/lebebr01&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 29 Jun 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/06/29/user2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/06/29/user2016.html</guid>
			</item>
		
			<item>
				<title>Assessing the validity of item response theory models when calibrating field test items</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Assessing the validity of item response theory models when calibrating field test items&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Validity for IRT Models&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Validity is important for any assessment and the argument should begin with psychometrics.&lt;/li&gt;
&lt;li&gt;How the psychometrics is performed directly impacts properties of the assessment that are assessed later for evidence of validity.

&lt;ul&gt;
&lt;li&gt;Are scores reported below chance level?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The validity of the psychometrics is particularly important for field test data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT Model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/irt.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Field Testing&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Field testing (FT) is essential to new assessment development or form building.

&lt;ul&gt;
&lt;li&gt;A way to gather information to make informed decisions about which items become operational.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Limitations:

&lt;ul&gt;
&lt;li&gt;Many items are tried that do not become operational.

&lt;ul&gt;
&lt;li&gt;This spreads a fixed pool of individuals (respondents) across many field test items.&lt;/li&gt;
&lt;li&gt;Ultimately, sample size can be significantly smaller compared to operational assessments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Issues with distractors.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Threats to Validity in FT&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Generalizeability

&lt;ul&gt;
&lt;li&gt;Is the FT sample representative of the desired population?&lt;/li&gt;
&lt;li&gt;Over-fitting with 3PL model?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Uncertainty in estimates

&lt;ul&gt;
&lt;li&gt;Sample size and lower asymptote estimation&lt;/li&gt;
&lt;li&gt;Interconnected parameter estimates
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Generalizeability&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;We assume respondents are randomly sampled from some population.

&lt;ul&gt;
&lt;li&gt;Are item responses truly randomly sampled from the population of interest?

&lt;ul&gt;
&lt;li&gt;Selection or Measurement bias&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If not, estimates are extremely sample dependent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3PL model may provide better fit, but is this at the cost of overfitting?

&lt;ul&gt;
&lt;li&gt;Fit should not be the only consideration when deciding on an IRT model for FT data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Sample size (1000 commonly cited for 3PL model):

&lt;ul&gt;
&lt;li&gt;Tends to be smaller in field test designs.&lt;/li&gt;
&lt;li&gt;Even with small samples, can achieve convergence with 3PL model with help of priors, ridge, etc.

&lt;ul&gt;
&lt;li&gt;Are our estimates now biased?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Estimating Lower Asymptote (pseudo-guessing):

&lt;ul&gt;
&lt;li&gt;Difficulty in estimating this term ($c_{j}$) has direct impact on estimation of the other two terms.

&lt;ul&gt;
&lt;li&gt;This leads to a cascading vortex of problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The pseudo-guessing is commonly a nuisance parameter, why allow a nuisance parameter to drastically affect estimation of other terms?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Methodology&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Individual response strings were resampled in a two stage framework:

&lt;ul&gt;
&lt;li&gt;First, individuals who took the field test were resampled with replacement within each field test booklet.&lt;/li&gt;
&lt;li&gt;Second, individuals who only took operational items were resampled with replacement to fill out the remaining observations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After resampling, items were calibrated with Bilog-MG.&lt;/li&gt;
&lt;li&gt;This process was replicated 5000 times to generate bootstrapped item parameters.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math57.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math572pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread653pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread652pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;ICC Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;For individual items, the variation in the ICCs for a 3PL model can be large.

&lt;ul&gt;
&lt;li&gt;This may lower usefulness of estimates in helping to select operational (best) items.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How can these 3PL curves be expected to generalize beyond this sample with so much variability?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;b and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_bc_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ac_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and b est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ab_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The pseudo-guessing estimates are:

&lt;ul&gt;
&lt;li&gt;negatively related to the estimates of the b and a.&lt;/li&gt;
&lt;li&gt;positively related to the uncertainty in the b parameter, likely the parameter of most interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In turn, increasing the uncertainty in the b parameter:

&lt;ul&gt;
&lt;li&gt;further increases the uncertainty in the a parameter.&lt;/li&gt;
&lt;li&gt;is also negatively related to estimates of the a parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thus, creating the cascading vortex of problems.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Item parameters estimated from FT data should not be treated as truth.

&lt;ul&gt;
&lt;li&gt;Variation in these parameter estimates needs to be considered.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fit should not be the only concern when selecting an IRT model, uncertainty, generalizeability, and usefulness should also be considered.&lt;/li&gt;
&lt;li&gt;Estimates are much more stable when using the 2PL model.

&lt;ul&gt;
&lt;li&gt;Thus providing a stronger foundation with which to start the validity argument for an assessment.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/09/ncme2016.html&quot;&gt;http://educate-r.org/2016/04/09/ncme2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Sat, 09 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/09/ncme2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/09/ncme2016.html</guid>
			</item>
		
			<item>
				<title>Informative vs uninformative prior distributions with characteristic curve linking methods</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Informative vs uninformative prior distributions with characteristic curve linking methods&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Keyu Chen, Wei Cheng Liu, and Aaron McVay&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;With item response theory (IRT), the ability scale is arbitrarily defined (commonly mean of 0 and sd of 1).&lt;/li&gt;
&lt;li&gt;Linking is useful to help place individual ability and IRT item parameters on the same scale.

&lt;ul&gt;
&lt;li&gt;Particularly when two forms are administered to non-equivalent groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Four linking methods are common:

&lt;ul&gt;
&lt;li&gt;Mean/Mean&lt;/li&gt;
&lt;li&gt;Mean/Sigma&lt;/li&gt;
&lt;li&gt;Haebara&lt;/li&gt;
&lt;li&gt;Stocking Lord
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Transformation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/link.PNG&quot; alt=&quot;&quot; height = &quot;400&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Designs&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Random Groups&lt;/li&gt;
&lt;li&gt;Single group with counterbalancing&lt;/li&gt;
&lt;li&gt;Common-item nonequivalent group design&lt;/li&gt;
&lt;li&gt;More details in Kolen &amp;amp; Brennan (2014).
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Common-item NEG Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/commonitem.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Prior Weights&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The proficiency points and weights can be specified to reflect the ability distribution of the original scale.&lt;/li&gt;
&lt;li&gt;In addition, proficiency points and weights can be specified to reflect the ability distribution of the new scale.&lt;/li&gt;
&lt;li&gt;More details are provided in Kim &amp;amp; Lee (2006).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;strong&gt;Research Questions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;To what extent does the prior distribution have an impact on the estimation of the transformation constants?&lt;/li&gt;
&lt;li&gt;To what extent does the relationship from #1 generalize across the simulation conditions?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/simulation_conditions.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The A and B transformation constants were also simulated as a part of the design.

&lt;ul&gt;
&lt;li&gt;This was done in an attempt to increase generalizeability of study results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both were simulated from a random uniform distribution.

&lt;ul&gt;
&lt;li&gt;A ranged from 0.5 to 1.5 rounded to nearest .05 (21 possibilities)&lt;/li&gt;
&lt;li&gt;B ranged from -2 to 2 rounded to nearest 0.10 (41 possibilities)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1000 replications
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Procedures&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A population of 55 items were simulated as Form X from a normal ability distribution.&lt;/li&gt;
&lt;li&gt;Form Y consisted of common items from Form X (transformed based on A and B parameters).

&lt;ul&gt;
&lt;li&gt;Additional items were simulated to fill out Form Y.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Form Y was calibrated with Bilog-MG using a 3PL IRT model.&lt;/li&gt;
&lt;li&gt;Transformation constants were computed from calibrated Form Y item parameters and population Form X item parameters.

&lt;ul&gt;
&lt;li&gt;An R package, plink, was used.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Study Outcomes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Bias in the transformation constants (A and B) were explored descriptively and inferentially:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bias.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation recovery&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/heatmap_b.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results&lt;/h1&gt;

&lt;table style=&quot;font-size: 26pt;&quot;&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;Variable&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta A&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta B&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.699&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.149&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.045&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.008&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.387&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results A Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/a_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results B Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/b_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Prior distribution used for linking the two forms does not have a large impact on the estimation of the A and B constants.&lt;/li&gt;
&lt;li&gt;Even correctly specifying the shape of the ability distribution through the weights does not help with non-normal ability distributions.&lt;/li&gt;
&lt;li&gt;The ability distribution shape has the most impact on accurate estimation of the A and B constants.

&lt;ul&gt;
&lt;li&gt;Normalizing transformations of the ability distribution may be helpful to limit bias when estimating these linking constants.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/08/aera2016.html&quot;&gt;http://educate-r.org/2016/04/08/aera2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 08 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/08/aera2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/08/aera2016.html</guid>
			</item>
		
			<item>
				<title>AERA Poster 2016 Monte Carlo</title>
				<description>&lt;p&gt;I have a poster session at AERA &lt;a href=&quot;http://www.aera.net/&quot;&gt;http://www.aera.net/&lt;/a&gt; on Monday, April 11. This paper explores design characteristics of Monte Carlo studies to include key simulation conditions as a part of the simulation design. The main advantage, it is argued, of this approach is a gain in generalizeability while still maintaining strong internal validity.&lt;/p&gt;

&lt;p&gt;A pdf of the final poster can be found here: &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=sanBSLasqc90VykOI%2fZhinG5hX%2b8HrkK7wnsL1a6hxw%3d&amp;amp;docid=08c154563ec1243359598b5a5ee3fee90&quot;&gt;Link to Poster&lt;/a&gt; and &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=70eHPGH0%2fiYPNo%2bA9aGxsDiE6pZ30PirRS5Gk7DgHeM%3d&amp;amp;docid=011ba7819f0c741d8ab0ee91ee6bf7449&quot;&gt;Initial Proposal&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Wed, 06 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/06/aeraposter.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/06/aeraposter.html</guid>
			</item>
		
			<item>
				<title>Interactively building test forms from an IRT perspective An application of R and Shiny</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Interactively building test forms from an IRT perspective: An application of R and Shiny&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/flowchart.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is an open source statistical programming language.

&lt;ul&gt;
&lt;li&gt;Pros:

&lt;ul&gt;
&lt;li&gt;Common statistical procedures are found in R&lt;/li&gt;
&lt;li&gt;Can extend functionality with packages/functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons:

&lt;ul&gt;
&lt;li&gt;Need to be comfortable with code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Rlogo.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Reproducible Research&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Reproducible research has become popular.

&lt;ul&gt;
&lt;li&gt;Commonly a document that contains both analysis and text.&lt;/li&gt;
&lt;li&gt;This can be done with &lt;code&gt;Rmarkdown&lt;/code&gt; and &lt;code&gt;knitr.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/rmarkdown.PNG&quot; alt=&quot;&quot;/&gt;
&lt;img src=&quot;http://educate-r.org/figs/knitr.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative/Interactive Data Analysis&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;This type of analysis requires some input from the user.

&lt;ul&gt;
&lt;li&gt;Data analysts may use &lt;code&gt;R&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Shiny&lt;/code&gt; is a great option for code novices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/shiny.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative Task Examples&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Building Assessments&lt;/li&gt;
&lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
&lt;li&gt;Exploring Missing Data Patterns&lt;/li&gt;
&lt;li&gt;Model Selection/Building
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iterative Analysis Structure&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/useless_meeting.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;What is Shiny?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Shiny&lt;/code&gt; is an interactive web application framework for R.

&lt;ul&gt;
&lt;li&gt;Example: &lt;a href=&quot;http://shiny.rstudio.com/gallery/movie-explorer.html&quot;&gt;http://shiny.rstudio.com/gallery/movie-explorer.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/shiny_example.PNG&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Components of Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;User Interface (ui.r)

&lt;ul&gt;
&lt;li&gt;What the user sees and interacts with&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;R Analysis (server.r)

&lt;ul&gt;
&lt;li&gt;The R code running behind the scenes
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;User Interface&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Simple user interface example from RStudio

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyUI(

  fluidPage(    

    titlePanel(&quot;Telephones by region&quot;),

    sidebarLayout(      

      sidebarPanel(
        selectInput(&quot;region&quot;, &quot;Region:&quot;, 
                    choices = colnames(WorldPhones)),
        hr(),
        helpText(&quot;Data from AT&amp;amp;T (1961) The World&#39;s Telephones.&quot;)
      ),

      mainPanel(
        plotOutput(&quot;phonePlot&quot;)  
      )

    )
  )
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Server File&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The server file for RStudio example

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyServer(function(input, output) {

  output$phonePlot &amp;lt;- renderPlot({

    barplot(WorldPhones[ , input$region] * 1000, 
            main = input$region,
            ylab = &quot;Number of Telephones&quot;,
            xlab = &quot;Year&quot;)
  })
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Interactivity is Key&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/interactivity.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Tools for Interactivity&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Interactive Graphics

&lt;ul&gt;
&lt;li&gt;Using JavaScript - D3 graphics (&lt;code&gt;rCharts&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Interactive static graphics - Garrett&#39;s presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Interactive Tables

&lt;ul&gt;
&lt;li&gt;Using DT R package
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Reporting from Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Using &lt;code&gt;Rmarkdown&lt;/code&gt; and &lt;code&gt;knitr&lt;/code&gt; to create customizable reproducible reports

&lt;ul&gt;
&lt;li&gt;Example: generate report button&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generate final data files

&lt;ul&gt;
&lt;li&gt;Example: download data button
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Strengths of Using Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;The app can be written solely using R code

&lt;ul&gt;
&lt;li&gt;Can use CSS, JavaScript, or HTML as needed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User does not need to know any R&lt;/li&gt;
&lt;li&gt;Many hosting options&lt;/li&gt;
&lt;li&gt;Application can be as simple or complex as needed (both visually and functionally)&lt;/li&gt;
&lt;li&gt;Flexible output
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of Using Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;May take more time to develop initially&lt;/li&gt;
&lt;li&gt;Need some R familiarity for development
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background for Demo&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In educational assessment, we need to create new test forms

&lt;ul&gt;
&lt;li&gt;Exposure concerns&lt;/li&gt;
&lt;li&gt;Add new content&lt;/li&gt;
&lt;li&gt;Altering test landscape&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building test forms is an iterative process that involves gathering information from:

&lt;ul&gt;
&lt;li&gt;Item analyses&lt;/li&gt;
&lt;li&gt;Test blueprints&lt;/li&gt;
&lt;li&gt;Item response theory (IRT)
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##      Item.1 Item.2 Item.3 Item.4 Item.5 Item.6 Item.7 Item.8
## [1,]      1      1      1      1      1      1      1      1
## [2,]      0      1      0      0      1      0      1      0
## [3,]      1      1      1      0      1      0      1      0
## [4,]      0      1      0      1      1      0      1      0
## [5,]      0      1      1      1      1      0      1      1
## [6,]      1      1      0      0      1      0      1      0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Logistic Curve&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/logistic-1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Demo&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/lebebr01/BuildForm&quot;&gt;https://github.com/lebebr01/BuildForm&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Basic Theme
shiny::runGitHub(&#39;lebebr01/BuildForm&#39;, subdir = &#39;R&#39;, ref = &#39;basic&#39;)

# shinydashboard
shiny::runGitHub(&#39;lebebr01/BuildForm&#39;, subdir = &#39;R&#39;, ref = &#39;testmodule&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Benefits of Shiny for Iterative Data Analysis&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Free valuable data analyst/scientist resources.&lt;/li&gt;
&lt;li&gt;Improve data literacy in the organization.&lt;/li&gt;
&lt;li&gt;Highly customizable

&lt;ul&gt;
&lt;li&gt;Analysis (server.r)&lt;/li&gt;
&lt;li&gt;User interface (ui.r)&lt;/li&gt;
&lt;li&gt;Reporting
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of Shiny for Iterative Data Analysis&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Need to train users

&lt;ul&gt;
&lt;li&gt;Analysis&lt;/li&gt;
&lt;li&gt;Navigating web application&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge of JavaScript, CSS, or HTML useful.
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Guidelines for Building Shiny Apps&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Understand reactive coding.&lt;/li&gt;
&lt;li&gt;Modularize your code - define functions for repetitive code chunks.&lt;/li&gt;
&lt;li&gt;Define scope early.

&lt;ul&gt;
&lt;li&gt;Define output.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clean up UI last.
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Summary&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/flowchart.png&quot; alt=&quot;&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Shiny Resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/&quot;&gt;http://shiny.rstudio.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/articles/&quot;&gt;http://shiny.rstudio.com/articles/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/&quot;&gt;http://shiny.rstudio.com/gallery/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.rstudio.com/products/shiny/shiny-user-showcase/&quot;&gt;https://www.rstudio.com/products/shiny/shiny-user-showcase/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/02/18/cspshiny/&quot;&gt;http://educate-r.org/2016/02/18/cspshiny/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 18 Feb 2016 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2016/02/18/cspshiny.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/02/18/cspshiny.html</guid>
			</item>
		
			<item>
				<title>Web Scraping to Item Response Theory - A College Football Adventure</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Web Scraping to Item Response Theory: A College Football Adventure&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Andrew Zieffler, and Kyle Nickodem&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa &amp;amp; University of Minnesota&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Began after Tim Brewster was fired&lt;/li&gt;
&lt;li&gt;Wanted to try to predict next great coach
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data Available&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is available at three levels

&lt;ol&gt;
&lt;li&gt;Coach&lt;/li&gt;
&lt;li&gt;Game by Game&lt;/li&gt;
&lt;li&gt;Team
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Coach&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall record&lt;/li&gt;
&lt;li&gt;Team history&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;Coordinator history
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example Coach Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##   Year Team Win Loss Tie     Pct  PF  PA Delta        coach
## 1 2010 Iowa   8    5   0 0.61538 376 221   155 Kirk Ferentz
## 2 2011 Iowa   7    6   0 0.53846 358 310    48 Kirk Ferentz
## 3 2012 Iowa   4    8   0 0.33333 232 275   -43 Kirk Ferentz
## 4 2013 Iowa   8    5   0 0.61538 342 246    96 Kirk Ferentz
## 5 2014 Iowa   7    6   0 0.53846 367 333    34 Kirk Ferentz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Game by Game&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Final score of each game&lt;/li&gt;
&lt;li&gt;Date played&lt;/li&gt;
&lt;li&gt;Location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Not Available

&lt;ul&gt;
&lt;li&gt;No information within a game
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example GBG Data&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##    Team           Official Year       Date WL          Opponent PF PA
## 1  Iowa University of Iowa 2014  8/30/2014  W     Northern Iowa 31 23
## 2  Iowa University of Iowa 2014   9/6/2014  W     Ball St. (IN) 17 13
## 3  Iowa University of Iowa 2014  9/13/2014  L          Iowa St. 17 20
## 4  Iowa University of Iowa 2014  9/20/2014  W   Pittsburgh (PA) 24 20
## 5  Iowa University of Iowa 2014  9/27/2014  W       Purdue (IN) 24 10
## 6  Iowa University of Iowa 2014 10/11/2014  W           Indiana 45 29
## 7  Iowa University of Iowa 2014 10/18/2014  L          Maryland 31 38
## 8  Iowa University of Iowa 2014  11/1/2014  W Northwestern (IL) 48  7
## 9  Iowa University of Iowa 2014  11/8/2014  L         Minnesota 14 51
## 10 Iowa University of Iowa 2014 11/15/2014  W          Illinois 30 14
## 11 Iowa University of Iowa 2014 11/22/2014  L         Wisconsin 24 26
## 12 Iowa University of Iowa 2014 11/28/2014  L          Nebraska 34 37
## 13 Iowa University of Iowa 2014   1/2/2015  L         Tennessee 28 45
##              Location
## 1       Iowa City, IA
## 2       Iowa City, IA
## 3       Iowa City, IA
## 4      Pittsburgh, PA
## 5  West Lafayette, IN
## 6       Iowa City, IA
## 7    College Park, MD
## 8       Iowa City, IA
## 9     Minneapolis, MN
## 10      Champaign, IL
## 11      Iowa City, IA
## 12      Iowa City, IA
## 13   Jacksonville, FL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Team&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data

&lt;ul&gt;
&lt;li&gt;Overall team record&lt;/li&gt;
&lt;li&gt;Team statistics&lt;/li&gt;
&lt;li&gt;Rankings&lt;/li&gt;
&lt;li&gt;Conference Affiliation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data is very similar to that of the coach level
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data were obtained from many sources

&lt;ul&gt;
&lt;li&gt;Much from &lt;a href=&quot;http://cfbdatawarehouse.com&quot;&gt;http://cfbdatawarehouse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Also used wikipedia, ESPN, and rivals
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa.png&quot; alt=&quot;&quot; height = &quot;500&quot; width = &quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa State Coaches Over Time&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iowa_state.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Strengths in web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data is relatively easily obtained&lt;/li&gt;
&lt;li&gt;Structured process for obtaining data&lt;/li&gt;
&lt;li&gt;Can be easily updated
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Challenges of web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;At the mercy of the website

&lt;ul&gt;
&lt;li&gt;Many sites are old&lt;/li&gt;
&lt;li&gt;Not up to date on current design standards&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data validation can be difficult and time consuming&lt;/li&gt;
&lt;li&gt;Need some basic knowledge of html
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;When is Web Scraping Worthwhile?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best when scraping many pages

&lt;ul&gt;
&lt;li&gt;Particularly when web addresses are not structured&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Useful when data need to be updated&lt;/li&gt;
&lt;/ul&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt;Not useful if only scraping a single page/table
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;HTML Basics&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt; HTML is structured by start tags (e.g. &lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;) and end tags (e.g. &lt;code&gt;&amp;lt;&amp;frasl;table&amp;gt;&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt; Common tags 
&lt;/li&gt;
&lt;/ul&gt;


&lt;div style=&quot;float: left; width: 75%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; - &lt;code&gt;&amp;lt;h6&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;a href=&amp;quot;http://www.google.com&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;div style=&quot;float: right; width: 25%;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; &amp;amp; &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;


&lt;hr&gt;


&lt;ul&gt;
&lt;li&gt; Highly structured pages are the easiest to scrape &lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;HTML Code Example&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ferentz_wikiside.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Tools for web scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rvest&lt;/code&gt;: &lt;a href=&quot;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&quot;&gt;http://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;XML&lt;/code&gt;: &lt;a href=&quot;http://www.omegahat.org/RSXML/&quot;&gt;http://www.omegahat.org/RSXML/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;beautiful soup&lt;/code&gt;: &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/&quot;&gt;http://www.crummy.com/software/BeautifulSoup/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Misc

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SelectorGadget&lt;/code&gt;: &lt;a href=&quot;http://selectorgadget.com/&quot;&gt;http://selectorgadget.com/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Basics of rvest&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;read_html&lt;/code&gt; is the most basic function&lt;/li&gt;
&lt;li&gt;&lt;code&gt;html_node&lt;/code&gt; or &lt;code&gt;html_nodes&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;These functions need css selectors or xpath&lt;/li&gt;
&lt;li&gt;SelectorGadget is the easiest way to get this
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;SelectorGadget&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;SelectorGadget is a Javascript addon for web browsers&lt;/li&gt;
&lt;li&gt;Can quickly identify a css selector or xpath to select correct portion of web page&lt;/li&gt;
&lt;li&gt;Demo:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;&gt;https://en.wikipedia.org/wiki/Kirk_Ferentz&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Combine SelectorGadget with rvest&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rvest)
wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;)
wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
    html_nodes(&quot;.vcard td , .vcard th&quot;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## {xml_nodeset (6)}
## [1] &amp;lt;td colspan=&quot;2&quot; style=&quot;text-align:center&quot;&amp;gt;&amp;lt;a href=&quot;/wiki/File:Kirk_p ...
## [2] &amp;lt;th scope=&quot;row&quot;&amp;gt;Sport(s)&amp;lt;/th&amp;gt;
## [3] &amp;lt;td class=&quot;category&quot;&amp;gt;\n  &amp;lt;a href=&quot;/wiki/American_football&quot; title=&quot;Am ...
## [4] &amp;lt;th colspan=&quot;2&quot; style=&quot;text-align:center;background-color: lightgray ...
## [5] &amp;lt;th scope=&quot;row&quot;&amp;gt;Title&amp;lt;/th&amp;gt;
## [6] &amp;lt;td&amp;gt;\n  &amp;lt;a href=&quot;/wiki/Head_coach&quot; title=&quot;Head coach&quot;&amp;gt;Head coach&amp;lt;/a&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract text&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_text&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;\nFerentz at the 2010 Orange Bowl\n&quot;
## [2] &quot;Sport(s)&quot;                           
## [3] &quot;Football&quot;                           
## [4] &quot;Current position&quot;                   
## [5] &quot;Title&quot;                              
## [6] &quot;Head coach&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Encoding problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Two solutions to fix encoding problems

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;guess_encoding&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repair_encoding&lt;/code&gt;: fix encoding problems&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;%
  guess_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       encoding language confidence
## 1        UTF-8                1.00
## 2 windows-1252       en       0.36
## 3 windows-1250       ro       0.18
## 4 windows-1254       tr       0.13
## 5     UTF-16BE                0.10
## 6     UTF-16LE                0.10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Fix Encoding Problems&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Best practice to reload page with correct encoding&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk &amp;lt;- read_html(&quot;https://en.wikipedia.org/wiki/Kirk_Ferentz&quot;, 
                       encoding = &#39;UTF-8&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can also repair encoding after the fact&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_text() %&amp;gt;% 
  repair_encoding()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract html tags&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_name&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_name()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;td&quot; &quot;th&quot; &quot;td&quot; &quot;th&quot; &quot;th&quot; &quot;td&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract html attributes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard td , .vcard th&quot;) %&amp;gt;%
  html_attrs()
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
##             colspan               style 
##                 &quot;2&quot; &quot;text-align:center&quot; 
## 
## [[2]]
## scope 
## &quot;row&quot; 
## 
## [[3]]
##      class 
## &quot;category&quot; 
## 
## [[4]]
##                                          colspan 
##                                              &quot;2&quot; 
##                                            style 
## &quot;text-align:center;background-color: lightgray;&quot; 
## 
## [[5]]
## scope 
## &quot;row&quot; 
## 
## [[6]]
## named character(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;html_attrs&lt;/code&gt; function again&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;wiki_kirk_extract &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.vcard a&quot;) %&amp;gt;%
  html_attr(&#39;href&#39;)
head(wiki_kirk_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;/wiki/American_football&quot;                           
## [3] &quot;/wiki/Head_coach&quot;                                  
## [4] &quot;/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Valid Links&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;paste0&lt;/code&gt; function is helpful for this&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;valid_links &amp;lt;- paste0(&#39;https://www.wikipedia.org&#39;, wiki_kirk_extract)
head(valid_links)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &quot;https://www.wikipedia.org/wiki/File:Kirk_pressconference_orangebowl2010.JPG&quot;
## [2] &quot;https://www.wikipedia.org/wiki/American_football&quot;                           
## [3] &quot;https://www.wikipedia.org/wiki/Head_coach&quot;                                  
## [4] &quot;https://www.wikipedia.org/wiki/Iowa_Hawkeyes_football&quot;                      
## [5] &quot;https://www.wikipedia.org/wiki/Big_Ten_Conference&quot;                          
## [6] &quot;https://www.wikipedia.org/wiki/Iowa_City,_Iowa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Extract Tables&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;html_table&lt;/code&gt; function is useful to scrape well formatted tables&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;record_kirk &amp;lt;- wiki_kirk %&amp;gt;%
  html_nodes(&quot;.wikitable&quot;) %&amp;gt;%
  .[[1]] %&amp;gt;%
  html_table(fill = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Caveats to Web Scraping&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Keep in mind when scraping we are using their bandwidth

&lt;ul&gt;
&lt;li&gt;Do not want to repeatedly do expensive bandwidth operations&lt;/li&gt;
&lt;li&gt;Better to scrape once, then run only to update data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some websites are copyrighted (i.e. illegal to scrape)
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data Modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Research Questions

&lt;ol&gt;
&lt;li&gt;Who is the next great coach?&lt;/li&gt;
&lt;li&gt;What characteristics are in common for these coaches?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT modeling&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;So far we have explored the win/loss records of teams in the BCS era with item response theory (IRT)&lt;/li&gt;
&lt;li&gt;IRT is commonly used to model assessment data to estimate item parameters and person &#39;ability&#39;&lt;/li&gt;
&lt;li&gt;We recode the Win/Loss/Tie game by game results

&lt;ul&gt;
&lt;li&gt;1 = Win&lt;/li&gt;
&lt;li&gt;0 = Otherwise
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example code with lme4&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A 1 parameter multilevel IRT model can be fitted using &lt;code&gt;glmer&lt;/code&gt; in the &lt;code&gt;lme4&lt;/code&gt; package&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(lme4)
fm1a &amp;lt;- glmer(wingbg ~ 0 + (1|coach) + (1|Team), 
              data = yby_coach, family = binomial)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Plot Showing Team Ability&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/team_ability.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Connect&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;e-mail: brandon-lebeau (at) uiowa.edu&lt;/li&gt;
&lt;li&gt;Twitter: @blebeau11; &lt;a href=&quot;https://twitter.com/blebeau11&quot;&gt;https://twitter.com/blebeau11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Linkedin: &lt;a href=&quot;https://www.linkedin.com/in/lebeaubr&quot;&gt;https://www.linkedin.com/in/lebeaubr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://educate-r.org/2015/12/04/centraliowaruser/&quot;&gt;http://educate-r.org/2015/12/04/centraliowaruser/&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 04 Dec 2015 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2015/12/04/centraliowaruser.html</link>
				<guid isPermaLink="true">http://educate-r.org//2015/12/04/centraliowaruser.html</guid>
			</item>
		
			<item>
				<title>Speed test of sequence generation for unbalanced simulation</title>
				<description>&lt;p&gt;I have a simulation package that allows for the simulation of regression models including nested data structures. You can see the package on github here: &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;simReg&lt;/a&gt;. Over the weekend I updated the package to allow for the simulation of unbalanced designs. I&#39;m hoping to put together a new vigenette soon highlighting the functionality.&lt;/p&gt;

&lt;p&gt;I am working on a simulation that uses the unbalanced functionality and while simulating longitudinal data I&#39;ve found the function is much slower than the cross sectional counterparts (and balanced designs). I&#39;ve ran some additional testing and I believe I have the speed issues narrowed down to the fact that I am generating a time variable. Essentially, I have a vector of number of observations per cluster. The function then turns this vector of lengths into a time variable starting at 0 up to the maximum number of observations minus 1 by 1. As an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;x &amp;lt;- round(runif(5, min = 3, max = 10), 0)
unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] 0 1 2 3 4 5 6 7 0 1 2 0 1 2 3 4 5 6 0 1 2 3 4 0 1 2 3 4 5 6 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From the code above, you can see that there the number of observations is generated using &lt;em&gt;runif&lt;/em&gt; which is saved to the object &lt;em&gt;x&lt;/em&gt;. Then I use a combination of lapply, unlist, and the &#39;:&#39; operator to generate the sequence. This is the same code used in my package above to generate the time variable.&lt;/p&gt;

&lt;p&gt;As such, I was interested in testing various ways to generate the sequence and do a performance comparison. I compared the following ways, the &lt;em&gt;&#39;:&#39;&lt;/em&gt; operator, &lt;em&gt;seq.int&lt;/em&gt;, &lt;em&gt;seq&lt;/em&gt;, &lt;em&gt;do.call&lt;/em&gt; with &lt;em&gt;mapply&lt;/em&gt;, and &lt;em&gt;rep.int&lt;/em&gt; for the balanced case as a comparison to how it was done before. This was all done with the great &lt;strong&gt;microbenchmark&lt;/strong&gt; package.&lt;/p&gt;

&lt;p&gt;Here are the results from the 7 comparisons:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(microbenchmark)
x &amp;lt;- round(runif(100, min = 3, max = 15), 0)
microbenchmark(
  colon = unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  seq.int = unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  seq = unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  seq.int_mapply = do.call(c, mapply(seq.int, 0, x - 1)),
  seq_mapply = do.call(c, mapply(seq, 0, x - 1)),
  colon_mapply = do.call(c, mapply(&#39;:&#39;, 0, x - 1)),
  rep.int = rep.int(1:8 - 1, times = 100), # balanced case for reference.
  times = 1000L
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Unit: microseconds
##            expr      min       lq        mean    median        uq        max neval  cld
##           colon  133.429  148.618  255.474605  160.1145  235.8605  57706.598  1000 ab  
##         seq.int  180.231  203.632  270.517868  223.1330  309.9640   2671.845  1000 ab  
##             seq 2255.960 2626.685 4207.210575 2933.1590 3466.4605  88721.432  1000    d
##  seq.int_mapply  227.854  258.235  499.000451  292.7210  397.4110 105037.011  1000  b  
##      seq_mapply  953.293 1079.126 1534.250895 1203.9320 1543.2495  57174.117  1000   c 
##    colon_mapply  167.094  195.832  383.431252  220.4645  299.0845  61779.643  1000 ab  
##         rep.int    2.053    4.516    5.807329    5.7480    6.9800     30.792  1000 a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The results (in microseconds) show that this is where the significant slowdown is coming in my package implementing the unbalanced cases, although it appears that the &#39;:&#39; operator is the second best alternative. For those that have not seen the significant speed bump of the &lt;em&gt;seq.int&lt;/em&gt; and &lt;em&gt;rep.int&lt;/em&gt; over the &lt;em&gt;seq&lt;/em&gt; and &lt;em&gt;rep&lt;/em&gt; alternatives should also pay close attention (compare lines 2 and 3 above).&lt;/p&gt;

&lt;p&gt;I&#39;d be interested in alternative procedures that I am not aware of as well. Although not a big deal when running the package once, doing it 50,000 times does add up.&lt;/p&gt;

&lt;p&gt;Lastly, for those that are interested, we can show they are all equivalent methods (except for the &lt;em&gt;rep.int&lt;/em&gt; case).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;identical(
  unlist(lapply(1:length(x), function(xx) (1:x[xx]) - 1)),
  unlist(lapply(1:length(x), function(xx) seq.int(0, x[xx] - 1, 1))),
  unlist(lapply(1:length(x), function(xx) seq(0, x[xx] - 1, 1))),
  do.call(c, mapply(seq.int, 0, x - 1)),
  do.call(c, mapply(seq, 0, x - 1)),
  do.call(c, mapply(&#39;:&#39;, 0, x - 1))
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] TRUE
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Tue, 31 Mar 2015 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2015/03/31/seqspeed.html</link>
				<guid isPermaLink="true">http://educate-r.org//2015/03/31/seqspeed.html</guid>
			</item>
		
			<item>
				<title>Remove leading 0 with ggplot2.</title>
				<description>&lt;p&gt;I recently had an occasion while working on a three variable interaction plot for a paper where I wanted to remove the leading 0&#39;s in the x-axis text labels using &lt;em&gt;ggplot2&lt;/em&gt;. This was primarily due to some space concerns I had for the x-axis labels. Unfortunately, I did not find an obvious way to do this in my first go around. After tickering a bit, I&#39;ve found a workaround. The process is walked through below.&lt;/p&gt;

&lt;p&gt;First, some simulated data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Sim some data
simdata &amp;lt;- data.frame(x = runif(2400, min = .032, max = .210),
                      y = c(rnorm(2000, mean = 0, sd = .1), 
                            rnorm(400, mean = 1, sd = .25)),
                      group = c(sample(1:2, 1600, replace = TRUE),
                                rep(1, 400), 
                                rep(2, 400)),
                      facet = rep(1:3, each = 800))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As shown below, initially there is no group differences, but there are facet differences. Exploring the interaction between the grouping variables shows there is a two variable interaction. Note: This example is not identical to the three variable interaction I originally described above, but assume here that the x variable is also important.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, group, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##          1          2 
## 0.00342121 0.33040069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, facet, mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             1             2             3 
## -0.0009751953  0.0025336609  0.5028529069
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;with(simdata, tapply(y, interaction(group, facet), mean))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           1.1           2.1           1.2           2.2           1.3 
##  0.0031464214 -0.0048761903  0.0056148873 -0.0005785326  0.0014837970 
##           2.3 
##  1.0042220169
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the example in the paper, I aggregated the unique x values to the third decimal place. That is done with the following &lt;em&gt;dplyr&lt;/em&gt; code. Note: The data did not need to be aggregated, but it is a bit easier to work with when plotting later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# round value to .001 and aggregate
simdata$x_rd &amp;lt;- round(simdata$x, 3)

# aggregate
library(dplyr)
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))
simdata_agg 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [962 x 4]
## Groups: x_rd, group
## 
##     x_rd group facet            y
## 1  0.032     1     2 -0.088397852
## 2  0.032     2     2  0.228654211
## 3  0.033     1     1 -0.001843538
## 4  0.033     1     2 -0.021662299
## 5  0.033     1     3 -0.110077646
## 6  0.033     2     1  0.080429131
## 7  0.033     2     3  0.915228939
## 8  0.034     1     1  0.025164086
## 9  0.034     1     2 -0.046522430
## 10 0.034     1     3  0.037889712
## ..   ...   ...   ...          ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the data is aggregated, it can be directly plotted with &lt;em&gt;ggplot2&lt;/em&gt;. This is the base plot that contains the leading 0&#39;s by default and treats the x variable as continuous (which it really is continuous).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(ggplot2)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_rd, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_continuous(&quot;x&quot;, limits = c(0, .25), 
                     breaks = seq(0, .25, .05))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotwith0-1.png&quot; alt=&quot;&quot; /&gt;
The plot above is a good start, but I was worried about the x-axis labels being too close together and ultimately being difficult to read. I decided I wanted to omit the leading 0&#39;s to omit some space. This was useful in my scenario as the variable on the x-axis could only take on values between 0 and 1, therefore the leading 0 is not important.&lt;/p&gt;

&lt;p&gt;One way to remove the leading 0 is to convert the continuous variable into a character variable and use a simple regular expression (with &lt;em&gt;gsub&lt;/em&gt;) to remove the 0 at the beginning of the character string. Below is the code to do that and also the resulting plot. The key point of the plotting code below is the use of the &lt;em&gt;breaks&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;. Without this all the unique character values will be plotted, not good.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(size = 3) + facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.1&#39;, &#39;.15&#39;, &#39;.2&#39;, &#39;.25&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/plotno0-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot above has a few flaws. First, there are values at the edge of each facet. This could be fixed with the &lt;em&gt;expand&lt;/em&gt; argument to &lt;em&gt;scale_x_discrete&lt;/em&gt;, but I still wanted to include the value of .00 on the x-axis. Secondly, the x-axis text labels are not uniformly formatted which is not ideal (e.g. .1 should be .10).&lt;/p&gt;

&lt;p&gt;To fix this, some made up data needs to be added to the data frame. Some care needs to be done here as well as a value of .00 can not just be added to the x variable plotted. This would place a non-uniform gap between .00 and .05 (not shown, but try it for yourself by adapting the code below). Therefore, all values between 0 and .031 need to be manually added to the data frame to keep the spacing uniform. Finally, to not plot the made up values, I created a transparency variable called alpha. This variable was used to set the alpha values to 0 for the made up values and 1 for the real values. &lt;em&gt;scale_alpha_discrete&lt;/em&gt; was used to specify the range of alpha values, this is important otherwise the made up numbers will show up as a light gray. The final code to manually add the new data is shown below. Anyone have a less workaround procedure?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# Reset aggregation vector
simdata_agg &amp;lt;- simdata %&amp;gt;%
  group_by(x_rd, group, facet) %&amp;gt;%
  summarise(y = mean(y))

# Add values
simdata_agg &amp;lt;- rbind(data.frame(x_rd = seq(0, .031, .001),
                                group = rep(1, 32),
                                facet = rep(1, 32),
                                y = rep(0, 32)),
                     simdata_agg)

# Create a new variable to use for transparent points
simdata_agg$alpha &amp;lt;- ifelse(simdata_agg$x_rd &amp;lt; .032, 0, 1)

# Create x_char variable again
simdata_agg$x_char &amp;lt;- as.character(simdata_agg$x_rd)
simdata_agg$x_char &amp;lt;- gsub(&quot;^0&quot;, &quot;&quot;, simdata_agg$x_char)

# Needed formatting
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;&#39;, &#39;.00&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.2&#39;, &#39;.20&#39;,
                             simdata_agg$x_char)
simdata_agg$x_char &amp;lt;- ifelse(simdata_agg$x_char == &#39;.1&#39;, &#39;.10&#39;,
                             simdata_agg$x_char)

# Final plot
p &amp;lt;- ggplot(simdata_agg, aes(x = x_char, y = y, shape = factor(group))) + 
  theme_bw()
p + geom_point(aes(alpha = factor(alpha)), size = 3) + 
  facet_grid(. ~ facet) + 
  scale_x_discrete(&quot;x&quot;, breaks = c(&#39;.00&#39;, &#39;.05&#39;, &#39;.10&#39;, &#39;.15&#39;, &#39;.20&#39;),
                   expand = c(.05, .05)) + 
  scale_alpha_discrete(guide = FALSE, range = c(0, 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/addmadeupvalues-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
				<pubDate>Mon, 23 Mar 2015 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2015/03/23/removelead0.html</link>
				<guid isPermaLink="true">http://educate-r.org//2015/03/23/removelead0.html</guid>
			</item>
		
			<item>
				<title>Structured simulation of regression models - simReg package.</title>
				<description>&lt;p&gt;I&#39;d like to introduce a package that simulates regression models. This includes both single level and multilevel (i.e. hierarchical or linear mixed) models up to two levels of nesting. The package produces a unified framework to simulate all types of continuous regression models. In the future, I&#39;d like to add the ability to simulate generalized linear models. This package is an extension of the functions I used to simulate data for my dissertation.&lt;/p&gt;

&lt;p&gt;The package is currently on github &lt;a href=&quot;https://github.com/lebebr01/simReg&quot;&gt;https://github.com/lebebr01/simReg&lt;/a&gt;. Therefore, you can currently install the package by using the &lt;em&gt;devtools&lt;/em&gt; package like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(devtools)
install_github(&quot;lebebr01/simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The primary function of interest in this package is &lt;em&gt;sim.reg&lt;/em&gt;. To show the use of this function, here is a simple example simulating a single level regression mode. Note, this example is pulled directly from the &lt;strong&gt;Intro&lt;/strong&gt; vignette.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simReg)
set.seed(100)
fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed.param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov.param &amp;lt;- list(mean = c(0, 0, 0), sd = c(4, 3, 3), var.type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
n &amp;lt;- 150
errorVar &amp;lt;- 3
err.dist &amp;lt;- &quot;norm&quot;
temp.single &amp;lt;- sim.reg(fixed = fixed, fixed.param = fixed.param, cov.param = cov.param,
n = n, errorVar = errorVar, err.dist = err.dist, data.str = &quot;single&quot;)
head(temp.single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.     act     diff numCourse act.numCourse    Fbeta      err
## 1            1 -2.0088  3.10406    -5.566       11.1815 -0.05022 -3.35921
## 2            1  0.5261  4.96051    -3.056       -1.6077 -4.84527 -5.75176
## 3            1 -0.3157 -0.05384    -3.135        0.9897 -8.31073  1.63173
## 4            1  3.5471 -0.07261    -1.954       -6.9306 -4.58382  0.06435
## 5            1  0.4679  0.75074     1.148        0.5372  9.71476 -0.44783
## 6            1  1.2745 -1.01137     3.096        3.9455 24.81272  0.59651
##   sim.data ID
## 1   -3.409  1
## 2  -10.597  2
## 3   -6.679  3
## 4   -4.519  4
## 5    9.267  5
## 6   25.409  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the above code, the package uses a single sided equation to represent the fixed effects. Other arguments include the values for those fixed effects (fixed.param), the scale for the covariates (cov.param), the sample size (n), the error variance (errorVar), and the error distribution (err.dist). These are all put into the function &lt;em&gt;sim.reg&lt;/em&gt; with the additional argument &lt;em&gt;data.str&lt;/em&gt; to tell the function that we indeed want a single level regression and you get the following output. The data frame that is returned gives the values for the design matrix, the fixed portion of the model (Fbeta), and the random error term (err). The value of most interest if conducting a simulation would be the actually simulated value (sim.data).&lt;/p&gt;

&lt;h3&gt;Nested Example&lt;/h3&gt;

&lt;p&gt;A slightly more complicated example is shown below where longitudinal data are simulated.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time + diff
fixed.param &amp;lt;- c(4, 2, 6, 2.3, 7)
random.param &amp;lt;- c(7, 4, 2)
cov.param &amp;lt;- list(mean = c(0, 0), sd = c(1.5, 4), var.type = c(&quot;lvl1&quot;, &quot;lvl2&quot;))
n &amp;lt;- 150
p &amp;lt;- 30
errorVar &amp;lt;- 4
randCor &amp;lt;- 0
rand.dist &amp;lt;- &quot;norm&quot;
err.dist &amp;lt;- &quot;norm&quot;
serCor &amp;lt;- &quot;ID&quot;
serCorVal &amp;lt;- NULL
data.str &amp;lt;- &quot;long&quot;
temp.long &amp;lt;- sim.reg(fixed, random, fixed.param, random.param, cov.param,
n, p, errorVar, randCor, rand.dist, err.dist, serCor, serCorVal, data.str)
head(temp.long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time     diff    act time.act    b0      b1    b2   Fbeta
## 1            1    0 -0.05455  1.608    0.000 5.118 -0.1118 0.251   7.371
## 2            1    1 -2.23677 -1.349   -1.349 5.118 -0.1118 0.251 -19.968
## 3            1    2  0.50321 -6.028  -12.056 5.118 -0.1118 0.251 -87.237
## 4            1    3  1.25027  8.436   25.308 5.118 -0.1118 0.251 214.063
## 5            1    4  2.05871  3.917   15.667 5.118 -0.1118 0.251 143.031
## 6            1    5 -1.87968  7.598   37.990 5.118 -0.1118 0.251 286.125
##   randEff     err sim.data withinID clustID
## 1   5.104  3.2637    15.74        1       1
## 2   4.444  0.9355   -14.59        2       1
## 3   5.020 -3.1693   -85.39        3       1
## 4   5.096  4.1523   223.31        4       1
## 5   5.187 -3.1716   145.05        5       1
## 6   4.086 -0.2605   289.95        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Most of the arguments should look familiar to above, but a few are new. Most notably these are a one sided equation for the random effects (random), their variances (random.param), the number of observations within a cluster (p), the correlation among the random effects (randCor), the simulated distribution of the random effects (rand.dist), the serial correlation model for within cluster residuals (serCor), the values for the serial correlation models (serCorVal). Note now since this represents longitudinal data, the &lt;em&gt;data.str&lt;/em&gt; argument is now specified as &#39;long&#39;.&lt;/p&gt;

&lt;h3&gt;Other features&lt;/h3&gt;

&lt;p&gt;The package also simulates cross sectional multilevel models, covariates that are either a factor, ordinal, or categorical, and the basics for power simulation are there.&lt;/p&gt;

&lt;p&gt;For further information, see the vignette by doing the following after installing the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;vignette(&quot;Intro&quot;, package = &quot;simReg&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bugs, comments, or feature requests can be submitted on the github site &lt;a href=&quot;https://github.com/lebebr01/simReg/issues&quot;&gt;https://github.com/lebebr01/simReg/issues&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Wed, 01 Oct 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/10/01/simReg.html</link>
				<guid isPermaLink="true">http://educate-r.org//2014/10/01/simReg.html</guid>
			</item>
		
			<item>
				<title>Google location data -- Where I've been.</title>
				<description>&lt;p&gt;I was emailed by a friend that was looking into their google location data and had asked if I had ever used a json file before in R. I said I had not, but I knew there were packages to do such things. The things I sent were things he had already tried, so what did I decide to do? I went ahead and downloaded my own google location data.&lt;/p&gt;

&lt;p&gt;If you use google services (particularly have an android phone) you can get your google location information here buried in google&#39;s settings page: &lt;a href=&quot;https://www.google.com/settings/datatools&quot;&gt;Google Data Page&lt;/a&gt;. From there you can click on create new archive at the bottom of the rightmost column under &quot;Download your data&quot;. If you&#39;d like to replicate the map below, you just need the location data, therefore I unselected all of the options except for location. Then there is some thinking on google&#39;s servers and they give you a download file (either .zip, .tbz, or .tgz) from which you can download. Mine did not take long to prepare, if they have more location information on you it may take longer.&lt;/p&gt;

&lt;p&gt;Below is a map of all the locations I&#39;ve been. I rounded the latitude and longitude values to two decimals (and had to add the decimals) to create less exact location values. This step could obviously be omitted. You&#39;ll notice in the ggplot2 code that I set the alpha equal to .01, this allowed the locations where I&#39;ve been longer to be darker. You could get more fancy with this, especially if you are able to figure out the code google uses for their timestamp. Just looked like mumbo jumbo to me. There is also accuracy, velocity, heading, altitude, and activity data.&lt;/p&gt;

&lt;p&gt;Kind of a cool process. The map shows places I&#39;ve been the last year or so (does not include San Francisco from AERA two years ago) including living in Fayetteville, Iowa City, Saint Paul. It also shows a few places I was for interviews last year including travel through some airports (Dallas, Houston, Charlotte, Chicago) and even shows my honeymoon to the panhandle of Florida. It also made me realize how much more I need to explore to the west (and east to some extent).&lt;/p&gt;

&lt;p&gt;Below is the code I used to load, manipulate, and plot my google location data. To replicate you would need to download your own google location data. Has anyone else made sense of all this data?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/myjson.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(rjson)
json_file &amp;lt;- &quot;path/to/your/json/file&quot;
json_data &amp;lt;- fromJSON(file = json_file)
latlong &amp;lt;- data.frame(do.call(&quot;rbind&quot;, json_data[[2]]))
latlong2 &amp;lt;- subset(latlong, select = c(latitudeE7, longitudeE7))
latlong2$latR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$latitudeE7), 1, 2), 
                                   &quot;.&quot;, substr(as.character(latlong2$latitudeE7), 3, 4)))
latlong2$longR &amp;lt;- as.numeric(paste0(substr(as.character(latlong2$longitudeE7), 1, 3), 
                                    &quot;.&quot;, substr(as.character(latlong2$longitudeE7), 4, 5)))

library(maps)
library(ggplot2)

states &amp;lt;- map_data(&quot;state&quot;)

p &amp;lt;- ggplot(states) + 
  geom_polygon(aes(x = long, y = lat, group = group), 
               fill = &quot;white&quot;, color = &quot;black&quot;) + 
  theme_bw() + 
  theme(axis.text = element_blank(), line = element_blank(), 
        rect = element_blank(), axis.title = element_blank())
p + geom_point(data = latlong2, aes(x = longR, y = latR), 
               alpha = .01, color = &quot;red&quot;, size = 3)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<pubDate>Fri, 26 Sep 2014 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2014/09/26/googlelocations.html</link>
				<guid isPermaLink="true">http://educate-r.org//2014/09/26/googlelocations.html</guid>
			</item>
		
	</channel>
</rss>
