<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Educate-R</title>
		<description>R and data miscellany</description>
		<link>http://educate-r.org</link>
		<atom:link href="http://educate-r.org/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>simglm submission to CRAN this week</title>
				<description>&lt;p&gt;This is a quick note looking for any further feedback on the simglm package prior to CRAN submission later this week. The goal is to submit Thursday or Friday this week. The last few documentation finishing touches are happening now working toward a version 0.5.0 release on CRAN.&lt;/p&gt;

&lt;p&gt;For those who have not seen this package yet, the aim is to simulate regression models (single level and multilevel models) as well as employ empirical power analyses based on Monte Carlo simulation. The package is relatively flexible in user control of inputs to generate data.&lt;/p&gt;

&lt;p&gt;To install the package and also build the vignettes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&quot;lebebr01/simglm&quot;, build_vignettes = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then to generate a simple single level data set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simglm)

fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed_param &amp;lt;- c(2, 4, 1, 3.5, 2)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;), 
                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;),
                  cov_param = list(list(mean = 0, sd = 4),
                                   list(mean = 0, sd = 3),
                                   list(mean = 0, sd = 3)))
n &amp;lt;- 150
error_var &amp;lt;- 3
with_err_gen = &#39;rnorm&#39;
temp_single &amp;lt;- sim_reg(fixed = fixed, fixed_param = fixed_param, 
                       cov_param = cov_param,
                       n = n, error_var = error_var, 
                       with_err_gen = with_err_gen, 
                       data_str = &quot;single&quot;)
head(temp_single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.         act       diff   numCourse act.numCourse     Fbeta
## 1            1 -2.11697901 -0.1490870 -0.90292680  1.9114770938 -5.954293
## 2            1  0.01298227 -0.1310381 -0.06197237 -0.0008045421  1.702379
## 3            1  0.44564723  0.5913073 -0.59650183 -0.2658293887  1.754481
## 4            1 -0.03528805 -0.5113031 -0.05915731  0.0020875460  1.144669
## 5            1  1.77940941  0.5097288  0.54804919  0.9752038827 13.495946
## 6            1 -1.42185444  0.4145870  1.08424301 -1.5416357400 -2.561252
##          err  sim_data ID
## 1 -0.9567737 -6.911066  1
## 2  1.3386926  3.041071  2
## 3  0.3470914  2.101572  3
## 4  0.9178861  2.062555  4
## 5  0.8016335 14.297580  5
## 6  0.2499601 -2.311292  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then one can extend this to conduct of power analysis. The benefit of this approach is that you are able to generate data that hopefully more closely resembles data that is to be collected and can also evaluate assumption violations, sample size differences, and other conditions directly into the power analysis similar to a Monte Carlo simulation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~ 1 + act + diff + numCourse + act:numCourse
fixed_param &amp;lt;- c(0.5, 1.1, 0.6, 0.9, 1.1)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;), 
                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;),
                  opts = list(list(mean = 0, sd = 2),
                              list(mean = 0, sd = 2),
                              list(mean = 0, sd = 1)))
n &amp;lt;- NULL
error_var &amp;lt;- NULL
with_err_gen &amp;lt;- &#39;rnorm&#39;
pow_param &amp;lt;- c(&#39;(Intercept)&#39;, &#39;act&#39;, &#39;diff&#39;, &#39;numCourse&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;t&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 10
terms_vary &amp;lt;- list(n = c(20, 40, 60, 80, 100), error_var = c(5, 10, 20),
                   fixed_param = list(c(0.5, 1.1, 0.6, 0.9, 1.1), 
                                      c(0.6, 1.1, 0.6, 0.9, 1.1)),
                cov_param = list(list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;),
                                       mean = c(0, 0, 0), sd = c(2, 2, 1), 
                                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;)),
                                  list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;, &#39;rnorm&#39;),
                                       mean = c(0.5, 0, 0), sd = c(2, 2, 1), 
                                  var_type = c(&quot;single&quot;, &quot;single&quot;, &quot;single&quot;))
                                  )
                   )
power_out &amp;lt;- sim_pow(fixed = fixed, fixed_param = fixed_param, 
                     cov_param = cov_param,
                     n = n, error_var = error_var, with_err_gen = with_err_gen, 
                     data_str = &quot;single&quot;, pow_param = pow_param, alpha = alpha,
                     pow_dist = pow_dist, pow_tail = pow_tail, 
                     replicates = replicates, terms_vary = terms_vary)
head(power_out)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [6 x 11]
## Groups: var, n, error_var, fixed_param [3]
## 
##           var     n error_var         fixed_param
##        &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;              &amp;lt;fctr&amp;gt;
## 1 (Intercept)    20         5 0.5,1.1,0.6,0.9,1.1
## 2 (Intercept)    20         5 0.5,1.1,0.6,0.9,1.1
## 3 (Intercept)    20         5 0.6,1.1,0.6,0.9,1.1
## 4 (Intercept)    20         5 0.6,1.1,0.6,0.9,1.1
## 5 (Intercept)    20        10 0.5,1.1,0.6,0.9,1.1
## 6 (Intercept)    20        10 0.5,1.1,0.6,0.9,1.1
## # ... with 7 more variables: cov_param &amp;lt;fctr&amp;gt;, avg_test_stat &amp;lt;dbl&amp;gt;,
## #   sd_test_stat &amp;lt;dbl&amp;gt;, power &amp;lt;dbl&amp;gt;, num_reject &amp;lt;dbl&amp;gt;, num_repl &amp;lt;dbl&amp;gt;,
## #   data &amp;lt;list&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Questions and feedback are welcomed by filing an issue on GitHub here: &lt;a href=&quot;https://github.com/lebebr01/simglm/issues&quot;&gt;https://github.com/lebebr01/simglm/issues&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Tue, 23 May 2017 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2017/05/23/simglmcran.html</link>
				<guid isPermaLink="true">http://educate-r.org//2017/05/23/simglmcran.html</guid>
			</item>
		
			<item>
				<title>Make Power Fun (Again?)</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Make Power Fun (Again?)&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;(G)LMMs&lt;/li&gt;
&lt;li&gt;Power&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Shiny Demo - Broken!
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linear Mixed Model (LMM)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/equations.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is the ability to statistically detect a true effect (i.e. non-zero population effect).&lt;/li&gt;
&lt;li&gt;For simple models (e.g. t-tests, regression) there are closed form equations for generating power.

&lt;ul&gt;
&lt;li&gt;R has routines for these: &lt;code&gt;power.t.test, power.anova.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gpower3
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Example&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;n &amp;lt;- seq(4, 1000, 2)
power &amp;lt;- sapply(seq_along(n), function(i) 
  power.t.test(n = n[i], delta = .15, sd = 1, type = &#39;two.sample&#39;)$power)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/power_plot-1.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power for (G)LMM&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power for more complex models is not as straightforward;

&lt;ul&gt;
&lt;li&gt;particularly with messy real world data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There is software for GLMM models to generate power:

&lt;ul&gt;
&lt;li&gt;Optimal Design: &lt;a href=&quot;http://hlmsoft.net/od/&quot;&gt;http://hlmsoft.net/od/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLPowSim: &lt;a href=&quot;http://www.bristol.ac.uk/cmm/software/mlpowsim/&quot;&gt;http://www.bristol.ac.uk/cmm/software/mlpowsim/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Snijders, &lt;em&gt;Power and Sample Size in Multilevel Linear Models&lt;/em&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is hard&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In practice, power is hard.&lt;/li&gt;
&lt;li&gt;Need to make many assumptions on data that has not been collected.

&lt;ul&gt;
&lt;li&gt;Therefore, data assumptions made for power computations will likely differ from collected sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A power analysis needs to be flexible, exploratory, and well thought out.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is Fun?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Three common reasons to do power analysis:

&lt;ol&gt;
&lt;li&gt;Power evidence for grant/planning&lt;/li&gt;
&lt;li&gt;Post Hoc to explore insignificant results&lt;/li&gt;
&lt;li&gt;Monte Carlo studies
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; Overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; aims to simulate (G)LMMs with up to three levels of nesting (aim to add more later).&lt;/li&gt;
&lt;li&gt;Flexible data generation allows:

&lt;ul&gt;
&lt;li&gt;any number of covariates and discrete covariates&lt;/li&gt;
&lt;li&gt;change distribution of continuous covariates&lt;/li&gt;
&lt;li&gt;change random distribution&lt;/li&gt;
&lt;li&gt;unbalanced data&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;li&gt;serial correlation
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power with &lt;code&gt;simglm&lt;/code&gt;&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power with &lt;code&gt;simglm&lt;/code&gt; takes on a Monte Carlo approach

&lt;ul&gt;
&lt;li&gt;This can provide a more thorough analysis/understanding of power.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Always outputs a data frame

&lt;ul&gt;
&lt;li&gt;Useful for plotting&lt;/li&gt;
&lt;li&gt;Data manipulation&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Serves as a wrapper around data generation process.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Analysis with &lt;code&gt;simglm&lt;/code&gt;&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Factorial Design:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Idenfity factors that influences power&lt;/li&gt;
&lt;li&gt;Determine number of replications&lt;/li&gt;
&lt;li&gt;Explore results&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Future Development&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Add ability for data generation and power model to differ
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simple Example&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Suppose we wished to generate data for a simple logistic regression.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(simglm)

fixed &amp;lt;- ~ 1 + act + diff
fixed_param &amp;lt;- c(0.1, 0.5, 0.3)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;),
                  var_type = c(&quot;single&quot;, &quot;single&quot;),
                  opts = list(list(mean = 0, sd = 2),
                              list(mean = 0, sd = 4)))
n &amp;lt;- 50
temp_single &amp;lt;- sim_glm(fixed = fixed, fixed_param = fixed_param, 
                      cov_param = cov_param, 
                      n = n, data_str = &quot;single&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(temp_single)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept.         act       diff       Fbeta  logistic sim_data ID
## 1            1 -0.02913722 -0.4430546 -0.04748497 0.4881310        1  1
## 2            1  0.66199364  2.1443743  1.07430910 0.7454155        1  2
## 3            1  1.44621026 -1.1909231  0.46582819 0.6143959        0  3
## 4            1 -0.26011629  3.4395304  1.00180096 0.7314125        0  4
## 5            1 -0.09984213  0.8485436  0.30464201 0.5755769        1  5
## 6            1 -2.72704127  3.3246515 -0.26612517 0.4338586        0  6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simple Power Analysis&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Suppose we wish to use the same generating model for a power analysis&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;pow_param &amp;lt;- c(&#39;(Intercept)&#39;, &#39;act&#39;, &#39;diff&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;z&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 100

power_out &amp;lt;- sim_pow_glm(fixed = fixed, fixed_param = fixed_param, 
                         cov_param = cov_param, 
                         n = n, data_str = &quot;single&quot;, 
                         pow_param = pow_param, alpha = alpha,
                         pow_dist = pow_dist, pow_tail = pow_tail, 
                         replicates = replicates)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 6
##           var avg_test_stat sd_test_stat power num_reject num_repl
##        &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)      0.878713    0.6709319  0.01          1      100
## 2         act      2.342617    0.5777646  0.34         34      100
## 3        diff      2.609432    0.5506204  0.56         56      100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Varying Arguments&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Now suppose we wish to vary the following arguments:

&lt;ul&gt;
&lt;li&gt;Vary n - 50 vs 150&lt;/li&gt;
&lt;li&gt;vary effect size on diff - .3 vs .45&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;terms_vary &amp;lt;- list(n = c(50, 150),
                   fixed_param = list(c(0.1, 0.5, 0.3), 
                                      c(0.1, 0.5, 0.45)))

power_out &amp;lt;- sim_pow_glm(fixed = fixed, fixed_param = fixed_param, 
                         cov_param = cov_param, 
                         n = n, data_str = &quot;single&quot;, 
                         pow_param = pow_param, alpha = alpha,
                         pow_dist = pow_dist, pow_tail = pow_tail, 
                         replicates = replicates, 
                         terms_vary = terms_vary)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [12 x 8]
## Groups: var, n [?]
## 
##            var     n  fixed_param avg_test_stat sd_test_stat power
##         &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;       &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  (Intercept)    50  0.1,0.5,0.3     0.7778328    0.5863240  0.00
## 2  (Intercept)    50 0.1,0.5,0.45     0.8364212    0.6377631  0.01
## 3  (Intercept)   150  0.1,0.5,0.3     0.8629973    0.5814426  0.00
## 4  (Intercept)   150 0.1,0.5,0.45     0.9183353    0.6879182  0.01
## 5          act    50  0.1,0.5,0.3     2.4246997    0.6222346  0.44
## 6          act    50 0.1,0.5,0.45     2.2247451    0.6688308  0.34
## 7          act   150  0.1,0.5,0.3     4.3196568    0.6233962  0.99
## 8          act   150 0.1,0.5,0.45     3.9515646    0.6332452  0.97
## 9         diff    50  0.1,0.5,0.3     2.7887204    0.4892985  0.73
## 10        diff    50 0.1,0.5,0.45     3.0747886    0.3988745  0.89
## 11        diff   150  0.1,0.5,0.3     4.7892881    0.5025082  1.00
## 12        diff   150 0.1,0.5,0.45     5.6060130    0.2823105  1.00
## # ... with 2 more variables: num_reject &amp;lt;dbl&amp;gt;, num_repl &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Move to Mixed Models&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;It is simple to move from single level to multilevel or mixed models.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;fixed &amp;lt;- ~1 + time + diff + act + time:act
random &amp;lt;- ~1 + time
fixed_param &amp;lt;- c(0, 0.2, 0.1, 0.3, 0.05)
random_param &amp;lt;- list(random_var = c(3, 2), rand_gen = &quot;rnorm&quot;)
cov_param &amp;lt;- list(dist_fun = c(&#39;rnorm&#39;, &#39;rnorm&#39;),
                  var_type = c(&quot;lvl1&quot;, &quot;lvl2&quot;),
                  opts = list(list(mean = 0, sd = 3),
                              list(mean = 0, sd = 2)))
n &amp;lt;- 50
p &amp;lt;- 6
data_str &amp;lt;- &quot;long&quot;

temp_long &amp;lt;- sim_glm(fixed = fixed, random = random, fixed_param = fixed_param,
                     random_param = random_param, cov_param = cov_param,
                     n = n, p = p, k = NULL, data_str = data_str)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(temp_long)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   X.Intercept. time        diff        act   time.act        b0        b1
## 1            1    0 -6.76572749 -0.3932853  0.0000000 -1.947485 -2.295427
## 2            1    1  0.15530420 -0.3932853 -0.3932853 -1.947485 -2.295427
## 3            1    2  0.07605058 -0.3932853 -0.7865707 -1.947485 -2.295427
## 4            1    3 -1.11192544 -0.3932853 -1.1798560 -1.947485 -2.295427
## 5            1    4 -4.17141062 -0.3932853 -1.5731413 -1.947485 -2.295427
## 6            1    5  4.77024867 -0.3932853 -1.9664267 -1.947485 -2.295427
##         Fbeta    randEff   logistic         prob sim_data withinID clustID
## 1 -0.79455835  -1.947485  -2.742044 6.053757e-02        0        1       1
## 2  0.07788055  -4.242913  -4.165032 1.529175e-02        0        2       1
## 3  0.25029093  -6.538340  -6.288049 1.854935e-03        0        3       1
## 4  0.31182906  -8.833767  -8.521938 1.990136e-04        0        4       1
## 5  0.18621627 -11.129195 -10.942978 1.768142e-05        0        5       1
## 6  1.26071793 -13.424622 -12.163904 5.215325e-06        0        6       1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Doing Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is also easily extended.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;pow_param &amp;lt;- c(&#39;time&#39;, &#39;diff&#39;, &#39;act&#39;)
alpha &amp;lt;- .01
pow_dist &amp;lt;- &quot;z&quot;
pow_tail &amp;lt;- 2
replicates &amp;lt;- 20

power_out &amp;lt;- sim_pow_glm(fixed = fixed, random = random, 
                     fixed_param = fixed_param, 
                     random_param = random_param, cov_param = cov_param, 
                     k = NULL, n = n, p = p,
                     data_str = data_str, unbal = FALSE, pow_param = pow_param, 
                     alpha = alpha, pow_dist = pow_dist, pow_tail = pow_tail,
                     replicates = replicates)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 6
##      var avg_test_stat sd_test_stat power num_reject num_repl
##   &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1    act      12.06197     46.70227  0.20          4       20
## 2   diff      11.89673     45.13827  0.25          5       20
## 3   time      18.78877     79.36869  0.05          1       20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Vary Arguments&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Perhaps our effect size estimate is conservative.&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;terms_vary &amp;lt;- list(fixed_param = list(c(0, 0.2, 0.1, 0.3, 0.05), 
                                      c(0, 0.2, 0.3, 0.3, 0.05)))

power_out &amp;lt;- sim_pow_glm(fixed = fixed, random = random, 
                     fixed_param = fixed_param, 
                     random_param = random_param, cov_param = cov_param, 
                     k = NULL, n = n, p = p,
                     data_str = data_str, unbal = FALSE, pow_param = pow_param, 
                     alpha = alpha, pow_dist = pow_dist, pow_tail = pow_tail,
                     replicates = replicates, 
                     terms_vary = terms_vary)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Output&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;power_out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [6 x 7]
## Groups: var [?]
## 
##      var        fixed_param avg_test_stat sd_test_stat power num_reject
##   &amp;lt;fctr&amp;gt;             &amp;lt;fctr&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1    act 0,0.2,0.1,0.3,0.05     1.1914255    0.8114762  0.10          2
## 2    act 0,0.2,0.3,0.3,0.05    22.9059014   96.3531136  0.15          3
## 3   diff 0,0.2,0.1,0.3,0.05     1.3071639    0.8681348  0.05          1
## 4   diff 0,0.2,0.3,0.3,0.05    17.4774138   62.2814403  0.95         19
## 5   time 0,0.2,0.1,0.3,0.05     0.9281452    0.7670600  0.05          1
## 6   time 0,0.2,0.3,0.3,0.05    12.1678311   49.9607401  0.05          1
## # ... with 1 more variables: num_repl &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Shiny App&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Note: This app currently looks nice, but is utterly broken!&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(&#39;simglm&#39;, username = &#39;lebebr01&#39;, subdir = &#39;inst/shiny_examples/demo&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
library(simglm)
run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Must have following packages installed: &lt;code&gt;simglm, shiny, shinydashboard, ggplot2, lme4, DT&lt;/code&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; timeline&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Aim to have this package submitted to CRAN by the end of March.&lt;/li&gt;
&lt;li&gt;Fix Shiny application.&lt;/li&gt;
&lt;li&gt;For now look for the package on GitHub &lt;a href=&quot;http://github.com/lebebr01/simglm&quot;&gt;http://github.com/lebebr01/simglm&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2017/02/24/csp2017.html&quot;&gt;http://educate-r.org/2017/02/24/csp2017.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01/simglm&quot;&gt;http://github.com/lebebr01/simglm&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 24 Feb 2017 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2017/02/24/csp2017.html</link>
				<guid isPermaLink="true">http://educate-r.org//2017/02/24/csp2017.html</guid>
			</item>
		
			<item>
				<title>Use CSS to format markdown or HTML files</title>
				<description>&lt;p&gt;Markdown (and Rmarkdown) are great ways to quickly develop material without worrying about the formatting. The documents can then be compiled using the &lt;code&gt;knitr&lt;/code&gt; or &lt;code&gt;rmarkdown&lt;/code&gt; packages to output formats such as HTML, latex, or even word. The main drawback of this approach is that formatting of documents is limited to italics, bold, or strikethrough. Markdown does have support for inline HTML, therefore you can add your own formatting inline using CSS or other HTML attributes, however this moves away from the quick markdown flavor.&lt;/p&gt;

&lt;p&gt;To help solve this problem, many R packages are useful for formatting tables, either through conditional formatting or otherwise. The most interesting to me is the &lt;a href=&quot;https://renkun.me/formattable/&quot;&gt;formattable&lt;/a&gt; package. Other options include the &lt;a href=&quot;http://davidgohel.github.io/ReporteRs/&quot;&gt;ReporteRs&lt;/a&gt; and &lt;a href=&quot;https://cran.r-project.org/web/packages/condformat/index.html&quot;&gt;condformat&lt;/a&gt; packages. These packages however focus on table formatting. An option I started working on a few years ago, &lt;a href=&quot;https://github.com/lebebr01/highlightHTML&quot;&gt;highlightHTML&lt;/a&gt;, is a relatively simple package that will help inject CSS automatically into an HTML document to take care of formatting of text and tables.&lt;/p&gt;

&lt;p&gt;Since this package uses CSS for the formatting, knowledge of CSS is required to create the tags to be injected. This has the advantage of allowing users a lot of flexibility with the look they wish to achieve, however, it will be more difficult for users if they do not know CSS. Below is a short demo of functions of interest.&lt;/p&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;The package was published on CRAN a few days ago and can be installed using &lt;code&gt;install.packages&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;install.packages(&#39;highlightHTML&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get the most out of the package, &lt;code&gt;rmarkdown&lt;/code&gt; and &lt;code&gt;knitr&lt;/code&gt; are useful to have installed as well, although not required.&lt;/p&gt;

&lt;h2&gt;Simple Example&lt;/h2&gt;

&lt;p&gt;Suppose you have a table like the following:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number       &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt;  5           &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt;  35          &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt;  100         &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt;  200         &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;You could then add some conditional formatting by adding the following tags to the table.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt; Color Name &lt;/th&gt;
&lt;th&gt; Number       &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; Blue       &lt;/td&gt;
&lt;td&gt;  5  #bgblue  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Green      &lt;/td&gt;
&lt;td&gt;  35          &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Orange     &lt;/td&gt;
&lt;td&gt;  100         &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; Red        &lt;/td&gt;
&lt;td&gt;  200 #bgred  &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;The addition of the &lt;em&gt;#bgblue&lt;/em&gt; and &lt;em&gt;#bgred&lt;/em&gt; indicates which cells will be changed. After turning the markdown document into an html file, this package can now be used to post-process the html file. The post-processing will add an id value for each cell with the &lt;em&gt;#bgblue&lt;/em&gt; or &lt;em&gt;#bgred&lt;/em&gt; and remove those from the table.&lt;/p&gt;

&lt;p&gt;The function to use for the post-processing is &lt;code&gt;highlight_html&lt;/code&gt; and requires three arguments, the input file, the output file, and the CSS tags themselves. This will look something like the following using an example file from the package:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(highlightHTML)
file &amp;lt;- system.file(&#39;examples&#39;, &#39;bgtable.html&#39;, 
                    package = &#39;highlightHTML&#39;)
tags &amp;lt;- c(&quot;#bgred {background-color: #FF0000;}&quot;, 
  &quot;#bgblue {background-color: #0000FF;}&quot;)
highlight_html(input = file, 
               output = tempfile(fileext = &quot;.html&quot;), 
               tags = tags,
               update_css = TRUE, 
               browse = TRUE,
               print = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will return an HTML file that automatically injects the CSS tags shown above. The new HTML file will add background color to the HTML file as such:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;figs/highlight_table.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Formatting Text&lt;/h2&gt;

&lt;p&gt;The package also allows for the formatting of text with CSS as well. The following is markdown text that will be formatted:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;markdown&quot;&gt;Can highlight {#bgblack multiple words}.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key is the use of braces following by the CSS id to add to the HTML file. Example usage can be shown with an example file that comes with the package and generated with the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;file &amp;lt;- system.file(&#39;examples&#39;, &#39;bgtext.html&#39;, package = &#39;highlightHTML&#39;)

# Change background color and text color with CSS
tags &amp;lt;- c(&quot;#bgblack {background-color: black; color: white;}&quot;, 
  &quot;#bgblue {background-color: #0000FF; color: white;}&quot;,
  &quot;#colgreen {color: green;}&quot;)

# Post-process HTML file
highlight_html(input = file, output = tempfile(fileext = &quot;.html&quot;),
               tags = tags, update_css = TRUE, browse = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The HTML file would look as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;figs/highlight_text.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Markdown to HTML Directly&lt;/h2&gt;

&lt;p&gt;Finally, with help of the &lt;code&gt;rmarkdown&lt;/code&gt; package, files can be rendered directly from markdown to an HTML file. Below is an example of this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;file &amp;lt;- system.file(&#39;examples&#39;, &#39;mwe.md&#39;, package = &#39;highlightHTML&#39;)
tags &amp;lt;- c(&quot;#bgred {background-color: #FF0000; color: white;}&quot;,
   &quot;#bgblue {background-color: #0000FF; color: white;}&quot;,
   &quot;#bgblack {background-color: #000000; color: white;}&quot;,
   &quot;#colgold {color: #FFD700;}&quot;)
highlight_html(input = file, output = tempfile(fileext = &#39;.html&#39;),
  tags = tags, update_css = TRUE, browse = TRUE, render = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;The package has a few additional features including the ability to inject tags directly into R tables, see  for an example of this. To come are a few basic CSS tags that will be built into the package using specific CSS ids. Bug reports are appreciated and can be logged on GitHub &lt;a href=&quot;https://github.com/lebebr01/highlightHTML/issues&quot;&gt;https://github.com/lebebr01/highlightHTML/issues&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
				<pubDate>Tue, 03 Jan 2017 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2017/01/03/highlighthtml.html</link>
				<guid isPermaLink="true">http://educate-r.org//2017/01/03/highlighthtml.html</guid>
			</item>
		
			<item>
				<title>Introduction of the pdfsearch package</title>
				<description>&lt;p&gt;I&#39;m happy to introduce an add-on package, &lt;code&gt;pdfsearch&lt;/code&gt;, that adds the ability to do keyword searches on pdf files. This add-on package uses the excellent &lt;code&gt;pdftools&lt;/code&gt; package from the &lt;a href=&quot;https://ropensci.org/&quot;&gt;ropensci&lt;/a&gt; project to read in pdf files and perform keyword searches based character strings of interest.&lt;/p&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;The package is currently only hosted on &lt;a href=&quot;https://github.com/lebebr01/pdfsearch&quot;&gt;github&lt;/a&gt; and can be installed with the devtools library.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/pdfsearch&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Basic Example&lt;/h2&gt;

&lt;p&gt;Doing a simple keyword search on a single pdf file uses the &lt;code&gt;keyword_search&lt;/code&gt; function. The following is a simple example using a pdf from &lt;a href=&quot;https://arxiv.org/&quot;&gt;arXiv&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;library(pdfsearch)

file &amp;lt;- system.file(&#39;pdf&#39;, &#39;1501.00450.pdf&#39;, package = &#39;pdfsearch&#39;)

key_res &amp;lt;- keyword_search(file, 
                          keyword = c(&#39;repeated measures&#39;, &#39;mixed effects&#39;),
                          path = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the following example, the function &lt;code&gt;keyword_search&lt;/code&gt; takes two required arguments, the path to the pdf file and the keyword(s) to search for in the pdf. The optional argument shown above, &lt;code&gt;path&lt;/code&gt; tells the function to read in the raw pdf using the &lt;code&gt;pdftools&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;data.frame(key_res)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##              keyword page_num line_num
## 1  repeated measures        1       24
## 2  repeated measures        2       57
## 3  repeated measures        2      108
## 4  repeated measures        2      110
## 5  repeated measures        2      125
## 6  repeated measures        6      444
## 7  repeated measures        6      445
## 8  repeated measures        6      474
## 9  repeated measures        6      485
## 10 repeated measures        9      708
##                                                                                                                                 line_text
## 1  cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical
## 2             fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the
## 3             repeated measures design in different stages of treatment        in this section we assume all users appear in all periods,
## 4               ing the repeated measures analysis, reporting a &amp;lt;U+0093&amp;gt;per week&amp;lt;U+0094&amp;gt;       to metrics that are defined as simple average and assume
## 5               In fact, the crossover design is a type of repeated measures     designs considered can be examined in the same framework
## 6          values and the absence in a specific time window can still          It is common to analyze data from repeated measures design
## 7              provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,
## 8                                      \022             \023                      As an example, one possible model for repeated measures
## 9          a similar example; also see (Van der Vaart 2000) for a text         possible. In repeated measures data, users might appear in
## 10                 framework of repeated measures design. Experimenters should          &amp;lt;U+0095&amp;gt; Wash-out and decide: If we have little informa-
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;head(key_res$line_text, n = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &quot;cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical&quot;
## 
## [[2]]
## [1] &quot;fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output includes the keyword, the page number it is located, the line number the keyword was found, and the line of text. By default, only the line matching the keyword is returned. If the context of the result is desired, there is an optional argument &lt;code&gt;surround_lines&lt;/code&gt; that can include the lines around the line of the matching keyword.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;key_res &amp;lt;- keyword_search(file, 
                          keyword = c(&#39;repeated measures&#39;, &#39;mixed effects&#39;),
                          path = TRUE, 
                          surround_lines = 2)
head(key_res$line_text, n = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &quot;to be evaluated, and the speed new feature iterations. We             Running under powered experiments have many perils. Not&quot;         
## [2] &quot;introduce more sophisticated experimental designs, specifi-           only would we miss potentially beneficial effects, we may also&quot;  
## [3] &quot;cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical&quot;
## [4] &quot;design and related variants, to increase KPI sensitivity with         power increases with larger effect size, and smaller variances.&quot; 
## [5] &quot;the same traffic size and duration of experiment. In this pa-         Let us look at these aspects in turn.&quot;                           
## 
## [[2]]
## [1] &quot;benefits (see Kohavi et al. 2012, Section 3.4). This poses&quot;                                                                     
## [2] &quot;a limitation to any online experimentation platform, where       within-subject variation. We also discuss practical consid-&quot;   
## [3] &quot;fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the&quot;    
## [4] &quot;rewards.                                                         crossover design to study the carry over effect, including the&quot;
## [5] &quot;&amp;lt;U+0093&amp;gt;re-randomized&amp;lt;U+0094&amp;gt; design (row 5 in table 1).&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Directory Search&lt;/h2&gt;

&lt;p&gt;This package also has the ability to loop over a directory of pdf files in a single run. To do this, the &lt;code&gt;keyword_directory&lt;/code&gt; function is of interest. Much of the arguments are the same, except a directory is specified instead of a single path to the location of the pdf files.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;# find directory
directory &amp;lt;- system.file(&#39;pdf&#39;, package = &#39;pdfsearch&#39;)

# do search over two files
head(keyword_directory(directory, 
       keyword = c(&#39;repeated measures&#39;, &#39;measurement error&#39;),
       surround_lines = 1, full_names = TRUE), n = 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    ID       pdf_name           keyword page_num line_num
## 1   1 1501.00450.pdf repeated measures        1       24
## 2   1 1501.00450.pdf repeated measures        2       57
## 3   1 1501.00450.pdf repeated measures        2      108
## 4   1 1501.00450.pdf repeated measures        2      110
## 5   1 1501.00450.pdf repeated measures        2      125
## 6   1 1501.00450.pdf repeated measures        6      444
## 7   1 1501.00450.pdf repeated measures        6      445
## 8   1 1501.00450.pdf repeated measures        6      474
## 9   1 1501.00450.pdf repeated measures        6      485
## 10  1 1501.00450.pdf repeated measures        9      708
## 11  2 1610.00147.pdf measurement error        1        5
## 12  2 1610.00147.pdf measurement error        1       19
##                                                                                                                                                                                                                                                                                                                                                                                                              line_text
## 1  introduce more sophisticated experimental designs, specifi-           only would we miss potentially beneficial effects, we may also, cally the repeated measures design, including the crossover           get false confidence about lack of negative effects. Statistical, design and related variants, to increase KPI sensitivity with         power increases with larger effect size, and smaller variances.
## 2                           a limitation to any online experimentation platform, where       within-subject variation. We also discuss practical consid-, fast iterations and testing many ideas can reap the most         erations to repeated measures design, with variants to the, rewards.                                                         crossover design to study the carry over effect, including the
## 3                                 In this paper we extend the idea further by employing the        weeks. To facilitate our illustration, in all the derivation, repeated measures design in different stages of treatment        in this section we assume all users appear in all periods,, assignment. The traditional A/B test can be analyzed us-         i.e. no missing measurement. We also restrict ourselves
## 4                                       assignment. The traditional A/B test can be analyzed us-         i.e. no missing measurement. We also restrict ourselves, ing the repeated measures analysis, reporting a &amp;lt;U+0093&amp;gt;per week&amp;lt;U+0094&amp;gt;       to metrics that are defined as simple average and assume, treatment effect, as show in row 3 &amp;lt;U+0093&amp;gt;parallel&amp;lt;U+0094&amp;gt; design in ta-      treatment and control have the same sample size. We fur-
## 5                                                                     each user serves as his/her own control in the measurement.      fixed effects in the model in this section. This way, various, In fact, the crossover design is a type of repeated measures     designs considered can be examined in the same framework, design commonly used in biomedical research to control for       and easily compared.
## 6                                                       to realize infrequent users are more likely to have missing         5.1 Review of Existing Methods, values and the absence in a specific time window can still          It is common to analyze data from repeated measures design, provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,
## 7                        values and the absence in a specific time window can still          It is common to analyze data from repeated measures design, provide information on the user behavior and in reality there       with the repeated measures ANOVA model and the F-test,, might be other factors causing user to be missing that are          under certain assumptions, such as normality, sphericity (ho-
## 8                                                                                                                                                                                                                    0 0, \022             \023                      As an example, one possible model for repeated measures, Xi Xi0                             using lme4&amp;lt;U+0092&amp;gt;s formula syntax (Bates et al. 2012a;b) is
## 9                      the delta-method; see Deng et al. (2013, Appendix B) for            Random effect makes modeling within-subject variability, a similar example; also see (Van der Vaart 2000) for a text         possible. In repeated measures data, users might appear in, book treatment of the delta-method.                                 multiple periods, represented as multiple rows in the dataset.
## 10                                         At the design stage, we face a few choices under the same               measure it directly and should be used here., framework of repeated measures design. Experimenters should          &amp;lt;U+0095&amp;gt; Wash-out and decide: If we have little informa-, use domain knowledge and past experiments to inform the                 tion to judge carry over effect, we can run the first
## 11                                                                                                                                                                                                                                         Abstract, Often in surveys, key items are subject to measurement errors. Given just the, data, it can be difficult to determine the distribution of this error process, and
## 12                                                                                                                                                                                               National Survey of College Graduates. We also present a process for assessing, the sensitivity of various analyses to different choices for the measurement error, models. Supplemental material is available online.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two relavent arguments for the &lt;code&gt;keyword_directory&lt;/code&gt; function are &lt;code&gt;full_names&lt;/code&gt; and &lt;code&gt;recursive&lt;/code&gt;. These functions ask whether the full path for the pdf files in the directory will be used and whether subfolders within the directory will also be searched.&lt;/p&gt;

&lt;h2&gt;Uses for pdfsearch&lt;/h2&gt;

&lt;p&gt;This package may be extremely useful when conducting research syntheses or meta analyses, particularly when screening articles for inclusion into the research synthesis or meta analysis. This aim is hopeful to be explored later in more depth.&lt;/p&gt;

&lt;h3&gt;Limitations&lt;/h3&gt;

&lt;p&gt;The limitations of the package and the quality of text matches will depend on the pdfs being searched. For example, words that wrap across lines (i.e. hyphenated words) will not be included in the matches as entire words are currently being searched to be matched.&lt;/p&gt;

&lt;h2&gt;Moving Forward&lt;/h2&gt;

&lt;p&gt;The package will be submitted to CRAN next week, however, any bugs or problems can be submitted to the github site &lt;a href=&quot;https://github.com/lebebr01/pdfsearch/issues&quot;&gt;https://github.com/lebebr01/pdfsearch/issues&lt;/a&gt;.&lt;/p&gt;
</description>
				<pubDate>Fri, 02 Dec 2016 00:00:00 -0600</pubDate>
				<link>http://educate-r.org//2016/12/02/intro_pdfsearch.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/12/02/intro_pdfsearch.html</guid>
			</item>
		
			<item>
				<title>Extending accessibility of open-source statistical software to the masses A shiny case study</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Extending accessibility of open-source statistical software to the masses: A shiny case study&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is an open source statistical programming language.

&lt;ul&gt;
&lt;li&gt;Pros:

&lt;ul&gt;
&lt;li&gt;Common statistical procedures are found in R&lt;/li&gt;
&lt;li&gt;Can extend functionality with packages/functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cons:

&lt;ul&gt;
&lt;li&gt;Need to be comfortable with code
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Flexibility of R&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;R is powerful and flexible due to the many user written packages.&lt;/li&gt;
&lt;li&gt;However, to capture this flexibility:

&lt;ul&gt;
&lt;li&gt;users need to be comfortable with programming&lt;/li&gt;
&lt;li&gt;users need to find the package&lt;/li&gt;
&lt;li&gt;users need to understand package specific syntax
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;R package documentation and examples&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise&quot;&gt;https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Blog posts&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.rstudio.org/2014/01/17/introducing-dplyr/&quot;&gt;https://blog.rstudio.org/2014/01/17/introducing-dplyr/&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Vignettes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html&quot;&gt;https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html&lt;/a&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Weaknesses of these types of documentations&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;They still rely on user understanding and reading R code.&lt;/li&gt;
&lt;li&gt;Not interactive, although the user can copy and paste code into an R session.&lt;/li&gt;
&lt;li&gt;This type of documentation will not capture the nontraditional useR.&lt;/li&gt;
&lt;li&gt;Shiny is the path to the nontraditional useR.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;What is Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Shiny is an open-source framework for creating applications viewed in a web browser with R.&lt;/li&gt;
&lt;li&gt;Shiny Examples:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/movie-explorer.html&quot;&gt;http://shiny.rstudio.com/gallery/movie-explorer.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gallery.shinyapps.io/drinkr/&quot;&gt;https://gallery.shinyapps.io/drinkr/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wordbank.stanford.edu/analyses?name=item_trajectories&quot;&gt;http://wordbank.stanford.edu/analyses?name=item_trajectories&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Advantages of Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;User needs no R knowledge&lt;/li&gt;
&lt;li&gt;App is viewed in the browser so able to use

&lt;ul&gt;
&lt;li&gt;Javascript&lt;/li&gt;
&lt;li&gt;HTML&lt;/li&gt;
&lt;li&gt;CSS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiple hosting options&lt;/li&gt;
&lt;li&gt;Flexible Output
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Disadvantages of Shiny&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Need a R developer to create the app.

&lt;ul&gt;
&lt;li&gt;More difficult as the code is somewhat different compared to traditional R code.&lt;/li&gt;
&lt;li&gt;Shiny uses reactive programming.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Components of Shiny&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;User Interface (ui.r)

&lt;ul&gt;
&lt;li&gt;What the user sees and interacts with&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;R Analysis (server.r)

&lt;ul&gt;
&lt;li&gt;The R code running behind the scenes
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;User Interface&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Simple user interface example from RStudio

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyUI(
  fluidPage(    
    titlePanel(&quot;Telephones by region&quot;),
    sidebarLayout(      
      sidebarPanel(
        selectInput(&quot;region&quot;, &quot;Region:&quot;, 
                    choices = colnames(WorldPhones)),
        hr(),
        helpText(&quot;Data from AT&amp;amp;T (1961) The World&#39;s Telephones.&quot;)
      ),

      mainPanel(
        plotOutput(&quot;phonePlot&quot;)  
      )
    )
  )
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Server File&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The server file for RStudio example

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://shiny.rstudio.com/gallery/telephones-by-region.html&quot;&gt;http://shiny.rstudio.com/gallery/telephones-by-region.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shinyServer(function(input, output) {

  output$phonePlot &amp;lt;- renderPlot({

    barplot(WorldPhones[ , input$region] * 1000, 
            main = input$region,
            ylab = &quot;Number of Telephones&quot;,
            xlab = &quot;Year&quot;)
  })
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Case Study&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;pdfsearch

&lt;ul&gt;
&lt;li&gt;Note, you may need &lt;em&gt;rtools&lt;/em&gt; to install this package.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This following commands will run the pdfsearch shiny application locally.

&lt;ul&gt;
&lt;li&gt;Note, the following packages are required: shiny, shinydashboard, pdfsearch, DT
&lt;a href=&quot;https://github.com/lebebr01/pdfsearch&quot;&gt;https://github.com/lebebr01/pdfsearch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;install.packages(&#39;devtools&#39;)
devtools::install_github(&#39;lebebr01/pdfsearch&#39;)
pdfsearch::run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Case Study 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;simglm

&lt;ul&gt;
&lt;li&gt;Note, need the following packages: shiny, shinydashboard, DT, simglm, ggplot2, lme4, highcharter
&lt;a href=&quot;https://github.com/lebebr01/simglm&quot;&gt;https://github.com/lebebr01/simglm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
simglm::run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Shiny can give useRs an interactive framework to try out an R package.&lt;/li&gt;
&lt;li&gt;Benefits include

&lt;ul&gt;
&lt;li&gt;interactivity&lt;/li&gt;
&lt;li&gt;no errors (for well developed Shiny applications)&lt;/li&gt;
&lt;li&gt;no need to learn R or package specific syntax&lt;/li&gt;
&lt;li&gt;only need a browser, no need to have R install locally when hosted on a server.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/10/07/canam.html&quot;&gt;http://educate-r.org/2016/10/07/canam.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01&quot;&gt;http://github.com/lebebr01&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 07 Oct 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/10/07/canam.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/10/07/canam.html</guid>
			</item>
		
			<item>
				<title>Estimating NCAA Football Coaches’ Abilities An Application of Item Response Theory</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Estimating NCAA Football Coaches’ Abilities An Application of Item Response Theory&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Andrew Zieffler, and Kyle Nickodem&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa &amp;amp; University of Minnesota&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Began after Tim Brewster was fired at the University of Minnesota.

&lt;ul&gt;
&lt;li&gt;Now they have a new coach again!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wanted to try to predict next great coach.&lt;/li&gt;
&lt;li&gt;Proceeded to explore data available to answer this question.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Data&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Data came from a few sources:

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cfbdatawarehouse.com/&quot;&gt;http://www.cfbdatawarehouse.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wikipedia
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Goals&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Predict the &#39;ability&#39; of the coaches.&lt;/li&gt;
&lt;li&gt;Find other variables that explain variation in the &#39;ability&#39; of the coaches.&lt;/li&gt;
&lt;li&gt;Predict the next &#39;great&#39; coach.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/cfbmodel.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Model 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Not a traditional IRT model as the game ID is not included.

&lt;ul&gt;
&lt;li&gt;The model does allow for a coaches ability to vary with years.&lt;/li&gt;
&lt;li&gt;The team effect is constant.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;This model was fitted using R: &lt;code&gt;lme4&lt;/code&gt; and &lt;code&gt;rstan&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Results shown throughout are from &lt;code&gt;lme4&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&#39;Modern&#39; era data, 1998 onward and coaches with at least 6 games per year.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Team Effect&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/teameffect.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Ability Estimates&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ISU.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Iowa State made good hire?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/ISU_good_hire.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Fire Tim Brewster?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/UMN.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Does a coach overperform compared to average team ability?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Value-added like logic.&lt;/li&gt;
&lt;li&gt;If coaches over/under perform compared to a team average

&lt;ul&gt;
&lt;li&gt;are they more likely to be retained?&lt;/li&gt;
&lt;li&gt;if fired, are they a good fit for another team?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How quickly does team expectation change?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;6 Coaches on the Hot Seat&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Hot_seat_coach_plot.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Which of these 6 should be fired?&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Hot_seat_relative_plot.svg&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Back to Minnesota&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/Minnesota-Coaches-2.png&quot; alt=&quot;&quot; height=&quot;525px&quot; width=&quot;1000px&quot;&gt;
    &lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Next Steps&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Add covariates to model shown above

&lt;ul&gt;
&lt;li&gt;or use the ability estimates obtained above as an outcome.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Explore moving average for team expectation.&lt;/li&gt;
&lt;li&gt;Explore good vs bad coaching hires.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Connect&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;e-mail: brandon-lebeau (at) uiowa.edu&lt;/li&gt;
&lt;li&gt;Twitter: @blebeau11; &lt;a href=&quot;https://twitter.com/blebeau11&quot;&gt;https://twitter.com/blebeau11&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://educate-r.org/2016/07/31/jsm2016.html&quot;&gt;http://educate-r.org/2016/07/31/jsm2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Sun, 31 Jul 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/07/31/jsm2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/07/31/jsm2016.html</guid>
			</item>
		
			<item>
				<title>Simulation and power analysis of generalized linear mixed models</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Simulation and power analysis of generalized linear mixed models&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Overview&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;(G)LMMs&lt;/li&gt;
&lt;li&gt;Power&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Demo Shiny App!
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linear Mixed Model (LMM)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/equations.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power is the ability to statistically detect a true effect (i.e. non-zero population effect).&lt;/li&gt;
&lt;li&gt;For simple models (e.g. t-tests, regression) there are closed form equations for generating power.

&lt;ul&gt;
&lt;li&gt;R has routines for these: &lt;code&gt;power.t.test, power.anova.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gpower3
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power Example&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;n &amp;lt;- seq(4, 1000, 2)
power &amp;lt;- sapply(seq_along(n), function(i) 
  power.t.test(n = n[i], delta = .15, sd = 1, type = &#39;two.sample&#39;)$power)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/power_plot-1.png&quot; alt=&quot;&quot; /&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power for (G)LMM&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Power for more complex models is not as straightforward;

&lt;ul&gt;
&lt;li&gt;particularly with messy real world data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There is software for the GLMM models to generate power:

&lt;ul&gt;
&lt;li&gt;Optimal Design: &lt;a href=&quot;http://hlmsoft.net/od/&quot;&gt;http://hlmsoft.net/od/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLPowSim: &lt;a href=&quot;http://www.bristol.ac.uk/cmm/software/mlpowsim/&quot;&gt;http://www.bristol.ac.uk/cmm/software/mlpowsim/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Snijders, &lt;em&gt;Power and Sample Size in Multilevel Linear Models&lt;/em&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Power is hard&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;In practice, power is hard.&lt;/li&gt;
&lt;li&gt;Need to make many assumptions on data that has not been collected.

&lt;ul&gt;
&lt;li&gt;Therefore, data assumptions made for power computations will likely differ from collected sample.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A power analysis needs to be flexible, exploratory, and well thought out.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;&lt;code&gt;simglm&lt;/code&gt; Overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;simglm&lt;/code&gt; aims to simulate (G)LMMs with up to three levels of nesting (aim to add more later).&lt;/li&gt;
&lt;li&gt;Flexible data generation allows:

&lt;ul&gt;
&lt;li&gt;any number of covariates and discrete covariates&lt;/li&gt;
&lt;li&gt;change random distribution&lt;/li&gt;
&lt;li&gt;unbalanced data&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;li&gt;serial correlation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Also has routines to generate power.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Demo Shiny App&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;shiny::runGitHub(&#39;simglm&#39;, username = &#39;lebebr01&#39;, subdir = &#39;inst/shiny_examples/demo&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;r&quot;&gt;devtools::install_github(&#39;lebebr01/simglm&#39;)
library(simglm)
run_shiny()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Must have following packages installed: &lt;code&gt;simglm, shiny, shinydashboard, ggplot2, lme4, DT&lt;/code&gt;.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/06/29/user2016.html&quot;&gt;http://educate-r.org/2016/06/29/user2016.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;http://github.com/lebebr01&quot;&gt;http://github.com/lebebr01&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Wed, 29 Jun 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/06/29/user2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/06/29/user2016.html</guid>
			</item>
		
			<item>
				<title>Assessing the validity of item response theory models when calibrating field test items</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Assessing the validity of item response theory models when calibrating field test items&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Validity for IRT Models&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Validity is important for any assessment and the argument should begin with psychometrics.&lt;/li&gt;
&lt;li&gt;How the psychometrics is performed directly impacts properties of the assessment that are assessed later for evidence of validity.

&lt;ul&gt;
&lt;li&gt;Are scores reported below chance level?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The validity of the psychometrics is particularly important for field test data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;IRT Model&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/irt.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Field Testing&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Field testing (FT) is essential to new assessment development or form building.

&lt;ul&gt;
&lt;li&gt;A way to gather information to make informed decisions about which items become operational.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Limitations:

&lt;ul&gt;
&lt;li&gt;Many items are tried that do not become operational.

&lt;ul&gt;
&lt;li&gt;This spreads a fixed pool of individuals (respondents) across many field test items.&lt;/li&gt;
&lt;li&gt;Ultimately, sample size can be significantly smaller compared to operational assessments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Issues with distractors.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Threats to Validity in FT&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Generalizeability

&lt;ul&gt;
&lt;li&gt;Is the FT sample representative of the desired population?&lt;/li&gt;
&lt;li&gt;Over-fitting with 3PL model?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Uncertainty in estimates

&lt;ul&gt;
&lt;li&gt;Sample size and lower asymptote estimation&lt;/li&gt;
&lt;li&gt;Interconnected parameter estimates
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Generalizeability&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;We assume respondents are randomly sampled from some population.

&lt;ul&gt;
&lt;li&gt;Are item responses truly randomly sampled from the population of interest?

&lt;ul&gt;
&lt;li&gt;Selection or Measurement bias&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If not, estimates are extremely sample dependent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3PL model may provide better fit, but is this at the cost of overfitting?

&lt;ul&gt;
&lt;li&gt;Fit should not be the only consideration when deciding on an IRT model for FT data.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Sample size (1000 commonly cited for 3PL model):

&lt;ul&gt;
&lt;li&gt;Tends to be smaller in field test designs.&lt;/li&gt;
&lt;li&gt;Even with small samples, can achieve convergence with 3PL model with help of priors, ridge, etc.

&lt;ul&gt;
&lt;li&gt;Are our estimates now biased?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Estimating Lower Asymptote (pseudo-guessing):

&lt;ul&gt;
&lt;li&gt;Difficulty in estimating this term ($c_{j}$) has direct impact on estimation of the other two terms.

&lt;ul&gt;
&lt;li&gt;This leads to a cascading vortex of problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The pseudo-guessing is commonly a nuisance parameter, why allow a nuisance parameter to drastically affect estimation of other terms?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Methodology&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Individual response strings were resampled in a two stage framework:

&lt;ul&gt;
&lt;li&gt;First, individuals who took the field test were resampled with replacement within each field test booklet.&lt;/li&gt;
&lt;li&gt;Second, individuals who only took operational items were resampled with replacement to fill out the remaining observations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After resampling, items were calibrated with Bilog-MG.&lt;/li&gt;
&lt;li&gt;This process was replicated 5000 times to generate bootstrapped item parameters.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math57.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC Math FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccgr3math572pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 3PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread653pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Example ICC ELA FT Item 2PL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/iccread652pl.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;ICC Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;For individual items, the variation in the ICCs for a 3PL model can be large.

&lt;ul&gt;
&lt;li&gt;This may lower usefulness of estimates in helping to select operational (best) items.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How can these 3PL curves be expected to generalize beyond this sample with so much variability?
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;b and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_bc_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and c est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ac_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;a and b est and SE&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/pairs_ab_ela.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Uncertainty Summary&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The pseudo-guessing estimates are:

&lt;ul&gt;
&lt;li&gt;negatively related to the estimates of the b and a.&lt;/li&gt;
&lt;li&gt;positively related to the uncertainty in the b parameter, likely the parameter of most interest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In turn, increasing the uncertainty in the b parameter:

&lt;ul&gt;
&lt;li&gt;further increases the uncertainty in the a parameter.&lt;/li&gt;
&lt;li&gt;is also negatively related to estimates of the a parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thus, creating the cascading vortex of problems.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Item parameters estimated from FT data should not be treated as truth.

&lt;ul&gt;
&lt;li&gt;Variation in these parameter estimates needs to be considered.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fit should not be the only concern when selecting an IRT model, uncertainty, generalizeability, and usefulness should also be considered.&lt;/li&gt;
&lt;li&gt;Estimates are much more stable when using the 2PL model.

&lt;ul&gt;
&lt;li&gt;Thus providing a stronger foundation with which to start the validity argument for an assessment.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/09/ncme2016.html&quot;&gt;http://educate-r.org/2016/04/09/ncme2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Sat, 09 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/09/ncme2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/09/ncme2016.html</guid>
			</item>
		
			<item>
				<title>Informative vs uninformative prior distributions with characteristic curve linking methods</title>
				<description>&lt;p&gt;&lt;section&gt;
    &lt;h1 class=&quot;title&quot;&gt;Informative vs uninformative prior distributions with characteristic curve linking methods&lt;/h1&gt;
    &lt;h2 class=&quot;author&quot;&gt;Brandon LeBeau, Keyu Chen, Wei Cheng Liu, and Aaron McVay&lt;/h2&gt;
    &lt;h3 class=&quot;date&quot;&gt;University of Iowa&lt;/h3&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking overview&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;With item response theory (IRT), the ability scale is arbitrarily defined (commonly mean of 0 and sd of 1).&lt;/li&gt;
&lt;li&gt;Linking is useful to help place individual ability and IRT item parameters on the same scale.

&lt;ul&gt;
&lt;li&gt;Particularly when two forms are administered to non-equivalent groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Four linking methods are common:

&lt;ul&gt;
&lt;li&gt;Mean/Mean&lt;/li&gt;
&lt;li&gt;Mean/Sigma&lt;/li&gt;
&lt;li&gt;Haebara&lt;/li&gt;
&lt;li&gt;Stocking Lord
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Transformation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/link.PNG&quot; alt=&quot;&quot; height = &quot;400&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Linking Designs&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Random Groups&lt;/li&gt;
&lt;li&gt;Single group with counterbalancing&lt;/li&gt;
&lt;li&gt;Common-item nonequivalent group design&lt;/li&gt;
&lt;li&gt;More details in Kolen &amp;amp; Brennan (2014).
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Common-item NEG Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/commonitem.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Prior Weights&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The proficiency points and weights can be specified to reflect the ability distribution of the original scale.&lt;/li&gt;
&lt;li&gt;In addition, proficiency points and weights can be specified to reflect the ability distribution of the new scale.&lt;/li&gt;
&lt;li&gt;More details are provided in Kim &amp;amp; Lee (2006).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;strong&gt;Research Questions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;To what extent does the prior distribution have an impact on the estimation of the transformation constants?&lt;/li&gt;
&lt;li&gt;To what extent does the relationship from #1 generalize across the simulation conditions?
&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/simulation_conditions.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Design 2&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The A and B transformation constants were also simulated as a part of the design.

&lt;ul&gt;
&lt;li&gt;This was done in an attempt to increase generalizeability of study results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both were simulated from a random uniform distribution.

&lt;ul&gt;
&lt;li&gt;A ranged from 0.5 to 1.5 rounded to nearest .05 (21 possibilities)&lt;/li&gt;
&lt;li&gt;B ranged from -2 to 2 rounded to nearest 0.10 (41 possibilities)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1000 replications
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation Procedures&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A population of 55 items were simulated as Form X from a normal ability distribution.&lt;/li&gt;
&lt;li&gt;Form Y consisted of common items from Form X (transformed based on A and B parameters).

&lt;ul&gt;
&lt;li&gt;Additional items were simulated to fill out Form Y.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Form Y was calibrated with Bilog-MG using a 3PL IRT model.&lt;/li&gt;
&lt;li&gt;Transformation constants were computed from calibrated Form Y item parameters and population Form X item parameters.

&lt;ul&gt;
&lt;li&gt;An R package, plink, was used.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Study Outcomes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Bias in the transformation constants (A and B) were explored descriptively and inferentially:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/bias.PNG&quot; alt=&quot;&quot; height = &quot;200&quot; width=&quot;800&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Simulation recovery&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/heatmap_b.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results&lt;/h1&gt;

&lt;table style=&quot;font-size: 26pt;&quot;&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;Variable&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta A&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Eta B&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.699&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.149&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.012&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.045&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.008&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.387&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Prior Dist:A Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.004&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Ability Dist:Prior Dist:B Pop&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results A Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/a_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Results B Constant&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;http://educate-r.org/figs/b_ab_bias_large.png&quot; alt=&quot;&quot; height = &quot;500&quot; width=&quot;1200&quot;/&gt;
&lt;/section&gt;&lt;/p&gt;

&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Prior distribution used for linking the two forms does not have a large impact on the estimation of the A and B constants.&lt;/li&gt;
&lt;li&gt;Even correctly specifying the shape of the ability distribution through the weights does not help with non-normal ability distributions.&lt;/li&gt;
&lt;li&gt;The ability distribution shape has the most impact on accurate estimation of the A and B constants.

&lt;ul&gt;
&lt;li&gt;Normalizing transformations of the ability distribution may be helpful to limit bias when estimating these linking constants.
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;section&gt;&lt;/p&gt;

&lt;h1&gt;Questions?&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Twitter: @blebeau11&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://educate-r.org&quot;&gt;http://educate-r.org&lt;/a&gt; &lt;br/&gt; &lt;a href=&quot;http://www2.education.uiowa.edu/directories/person?id=bleb&quot;&gt;http://www2.education.uiowa.edu/directories/person?id=bleb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href=&quot;http://educate-r.org/2016/04/08/aera2016.html&quot;&gt;http://educate-r.org/2016/04/08/aera2016.html&lt;/a&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Fri, 08 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/08/aera2016.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/08/aera2016.html</guid>
			</item>
		
			<item>
				<title>AERA Poster 2016 Monte Carlo</title>
				<description>&lt;p&gt;I have a poster session at AERA &lt;a href=&quot;http://www.aera.net/&quot;&gt;http://www.aera.net/&lt;/a&gt; on Monday, April 11. This paper explores design characteristics of Monte Carlo studies to include key simulation conditions as a part of the simulation design. The main advantage, it is argued, of this approach is a gain in generalizeability while still maintaining strong internal validity.&lt;/p&gt;

&lt;p&gt;A pdf of the final poster can be found here: &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=sanBSLasqc90VykOI%2fZhinG5hX%2b8HrkK7wnsL1a6hxw%3d&amp;amp;docid=08c154563ec1243359598b5a5ee3fee90&quot;&gt;Link to Poster&lt;/a&gt; and &lt;a href=&quot;https://iowa-my.sharepoint.com/personal/bleb_uiowa_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=70eHPGH0%2fiYPNo%2bA9aGxsDiE6pZ30PirRS5Gk7DgHeM%3d&amp;amp;docid=011ba7819f0c741d8ab0ee91ee6bf7449&quot;&gt;Initial Proposal&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Wed, 06 Apr 2016 00:00:00 -0500</pubDate>
				<link>http://educate-r.org//2016/04/06/aeraposter.html</link>
				<guid isPermaLink="true">http://educate-r.org//2016/04/06/aeraposter.html</guid>
			</item>
		
	</channel>
</rss>
